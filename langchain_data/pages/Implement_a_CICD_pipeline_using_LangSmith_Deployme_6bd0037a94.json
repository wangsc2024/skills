{
  "title": "Implement a CI/CD pipeline using LangSmith Deployment and Evaluation",
  "content": "Source: https://docs.langchain.com/langsmith/cicd-pipeline-example\n\nThis guide demonstrates how to implement a comprehensive CI/CD pipeline for AI agent applications deployed in LangSmith Deployment. In this example, you'll use the [LangGraph](/oss/python/langgraph/overview) open source framework for orchestrating and building the agent, [LangSmith](/langsmith/home) for observability and evaluations. This pipeline is based on the [cicd-pipeline-example repository](https://github.com/langchain-ai/cicd-pipeline-example).\n\nThe CI/CD pipeline provides:\n\n* <Icon icon=\"check-circle\" /> **Automated testing**: Unit, integration, and end-to-end tests.\n* <Icon icon=\"chart-line\" /> **Offline evaluations**: Performance assessment using [AgentEvals](https://github.com/langchain-ai/agentevals), [OpenEvals](https://github.com/langchain-ai/openevals) and [LangSmith](https://docs.langchain.com/langsmith/home).\n* <Icon icon=\"rocket\" /> **Preview and production deployments**: Automated staging and quality-gated production releases using the Control Plane API.\n* <Icon icon=\"eye\" /> **Monitoring**: Continuous evaluation and alerting.\n\n## Pipeline architecture\n\nThe CI/CD pipeline consists of several key components that work together to ensure code quality and reliable deployments:\n\nThere are multiple ways you can trigger this pipeline, either during development or if your application is already live. The pipeline can be triggered by:\n\n* <Icon icon=\"code-branch\" /> **Code changes**: Pushes to main/development branches where you can modify the LangGraph architecture, try different models, update agent logic, or make any code improvements.\n* <Icon icon=\"edit\" /> **PromptHub updates**: Changes to prompt templates stored in LangSmith PromptHub—whenever there's a new prompt commit, the system triggers a webhook to run the pipeline.\n* <Icon icon=\"exclamation-triangle\" /> **Online evaluation alerts**: Performance degradation notifications from live deployments\n* <Icon icon=\"webhook\" /> **LangSmith traces webhooks**: Automated triggers based on trace analysis and performance metrics.\n* <Icon icon=\"play\" /> **Manual trigger**: Manual initiation of the pipeline for testing or emergency deployments.\n\nCompared to traditional software, testing AI agent applications also requires assessing response quality, so it is important to test each part of the workflow. The pipeline implements multiple testing layers:\n\n1. <Icon icon=\"puzzle-piece\" /> **Unit tests**: Individual node and utility function testing.\n2. <Icon icon=\"link\" /> **Integration tests**: Component interaction testing.\n3. <Icon icon=\"route\" /> **End-to-end tests**: Full graph execution testing.\n4. <Icon icon=\"brain\" /> **Offline evaluations**: Performance assessment with real-world scenarios including end-to-end evaluations, single-step evaluations, agent trajectory analysis, and multi-turn simulations.\n5. <Icon icon=\"server\" /> **LangGraph dev server tests**: Use the [langgraph-cli](/langsmith/cli) tool for spinning up (inside the GitHub Action) a local server to run the LangGraph agent. This polls the `/ok` server API endpoint until it is available and for 30 seconds, after that it throws an error.\n\n## GitHub Actions workflow\n\nThe CI/CD pipeline uses GitHub Actions with the [Control Plane API](/langsmith/api-ref-control-plane) and [LangSmith API](https://api.smith.langchain.com/redoc) to automate deployment. A helper script manages API interactions and deployments: [https://github.com/langchain-ai/cicd-pipeline-example/blob/main/.github/scripts/langgraph\\_api.py](https://github.com/langchain-ai/cicd-pipeline-example/blob/main/.github/scripts/langgraph_api.py).\n\nThe workflow includes:\n\n* **New agent deployment**: When a new PR is opened and tests pass, a new preview deployment is created in LangSmith Deployment using the [Control Plane API](/langsmith/api-ref-control-plane). This allows you to test the agent in a staging environment before promoting to production.\n\n* **Agent deployment revision**: A revision happens when an existing deployment with the same ID is found, or when the PR is merged into main. In the case of merging to main, the preview deployment is deleted and a production deployment is created. This ensures that any updates to the agent are properly deployed and integrated into the production infrastructure.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=3ef7d51a322b8b5e2f9c2c70579fcc97\" alt=\"Agent Deployment Revision Workflow\" data-og-width=\"1022\" width=\"1022\" data-og-height=\"196\" height=\"196\" data-path=\"langsmith/images/cicd-new-lgp-revision.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=280&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=a3d06c339e84a1af99450d23e8bd617f 280w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=560&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=30589c8727af3ecb1d97881fd6692554 560w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=840&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=c05ab515ea0901fb2d076dee256ad108 840w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=1100&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=b939ad6842110227f70cc0526468d21d 1100w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=1650&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=0559d5b2a85414e954a72377b2eed9ec 1650w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=2500&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=b8b96047a8b37f31b78d793cd7d18f45 2500w\" />\n\n* **Testing and evaluation workflow**: In addition to the more traditional testing phases (unit tests, integration tests, end-to-end tests, etc.), the pipeline includes [offline evaluations](/langsmith/evaluation-concepts#offline-evaluation) and [Agent dev server testing](/langsmith/local-server) because you want to test the quality of your agent. These evaluations provide comprehensive assessment of the agent's performance using real-world scenarios and data.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=477c3f5ec3d9bb9dfc354b9a57860636\" alt=\"Test with Results Workflow\" data-og-width=\"2050\" width=\"2050\" data-og-height=\"996\" height=\"996\" data-path=\"langsmith/images/cicd-test-with-results.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=280&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=7c5885b5f85c1c408fda449c5a0c706a 280w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=560&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=3b9a25332a9f6b56edfc9fbbfec248c1 560w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=840&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=380cb346fffbaf13365b37c6fa955c05 840w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=1100&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=8994d1e816e725865f90a2ac6601f7a4 1100w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=1650&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=42b752f1e5f0043dd6998ae372e83874 1650w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=2500&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=043be8ed1ef59cea171f30146790a877 2500w\" />\n\n<AccordionGroup>\n    <Accordion title=\"Final Response Evaluation\" icon=\"check-circle\">\n      Evaluates the final output of your agent against expected results. This is the most common type of evaluation that checks if the agent's final response meets quality standards and answers the user's question correctly.\n    </Accordion>\n\n<Accordion title=\"Single Step Evaluation\" icon=\"step-forward\">\n      Tests individual steps or nodes within your LangGraph workflow. This allows you to validate specific components of your agent's logic in isolation, ensuring each step functions correctly before testing the full pipeline.\n    </Accordion>\n\n<Accordion title=\"Agent Trajectory Evaluation\" icon=\"route\">\n      Analyzes the complete path your agent takes through the graph, including all intermediate steps and decision points. This helps identify bottlenecks, unnecessary steps, or suboptimal routing in your agent's workflow. It also evaluates whether your agent invoked the right tools in the right order or at the right time.\n    </Accordion>\n\n<Accordion title=\"Multi-Turn Evaluation\" icon=\"comments\">\n      Tests conversational flows where the agent maintains context across multiple interactions. This is crucial for agents that handle follow-up questions, clarifications, or extended dialogues with users.\n    </Accordion>\n  </AccordionGroup>\n\nSee the [LangGraph testing documentation](/oss/python/langgraph/test) for specific testing approaches and the [evaluation approaches guide](/langsmith/evaluation-approaches) for a comprehensive overview of offline evaluations.\n\nBefore setting up the CI/CD pipeline, ensure you have:\n\n* <Icon icon=\"robot\" /> An AI agent application (in this case built using [LangGraph](/oss/python/langgraph/overview))\n* <Icon icon=\"user\" /> A [LangSmith account](https://smith.langchain.com/)\n* <Icon icon=\"key\" /> A [LangSmith API key](/langsmith/create-account-api-key) needed to deploy agents and retrieve experiment results\n* <Icon icon=\"cog\" /> Project-specific environment variables configured in your repository secrets (e.g., LLM model API keys, vector store credentials, database connections)\n\n<Note>\n  While this example uses GitHub, the CI/CD pipeline works with other Git hosting platforms including GitLab, Bitbucket, and others.\n</Note>\n\n## Deployment options\n\nLangSmith supports multiple deployment methods, depending on how your [LangSmith instance is hosted](/langsmith/platform-setup):\n\n* <Icon icon=\"cloud\" /> **Cloud LangSmith**: Direct GitHub integration.\n* <Icon icon=\"server\" /> **Self-Hosted/Hybrid**: Container registry-based deployments.\n\nThe deployment flow starts by modifying your agent implementation. At minimum, you must have a [`langgraph.json`](/langsmith/application-structure) and dependency file in your project (`requirements.txt` or `pyproject.toml`). Use the `langgraph dev` CLI tool to check for errors—fix any errors; otherwise, the deployment will succeed when deployed to LangSmith Deployment.\n\n### Prerequisites for manual deployment\n\nBefore deploying your agent, ensure you have:\n\n1. <Icon icon=\"project-diagram\" /> **LangGraph graph**: Your agent implementation (e.g., `./agents/simple_text2sql.py:agent`).\n2. <Icon icon=\"box\" /> **Dependencies**: Either `requirements.txt` or `pyproject.toml` with all required packages.\n3. <Icon icon=\"cog\" /> **Configuration**: `langgraph.json` file specifying:\n   * Path to your agent graph\n   * Dependencies location\n   * Environment variables\n   * Python version\n\nExample `langgraph.json`:\n\n### Local development and testing\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=425460d3401221ab441e21fc706c9cf1\" alt=\"Studio CLI Interface\" data-og-width=\"2972\" width=\"2972\" data-og-height=\"1354\" height=\"1354\" data-path=\"langsmith/images/cicd-studio-cli.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=280&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=35e64359dba47f4db4962148073cfadb 280w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=560&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=c12eb479d5c46921633c56bdead978bc 560w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=840&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=b36efc12f81027b7364cea82a4600fc3 840w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=1100&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=131c3fa2e989fbb8ebc4748a5790dc36 1100w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=1650&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=afa56b4e5ca02495ef5e7cb69d8e1329 1650w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=2500&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=774ec3dcf76a4b0e61989cd12e41e0c3 2500w\" />\n\nFirst, test your agent locally using [Studio](/langsmith/studio):\n\n```bash  theme={null}",
  "code_samples": [
    {
      "code": "### Trigger sources\n\nThere are multiple ways you can trigger this pipeline, either during development or if your application is already live. The pipeline can be triggered by:\n\n* <Icon icon=\"code-branch\" /> **Code changes**: Pushes to main/development branches where you can modify the LangGraph architecture, try different models, update agent logic, or make any code improvements.\n* <Icon icon=\"edit\" /> **PromptHub updates**: Changes to prompt templates stored in LangSmith PromptHub—whenever there's a new prompt commit, the system triggers a webhook to run the pipeline.\n* <Icon icon=\"exclamation-triangle\" /> **Online evaluation alerts**: Performance degradation notifications from live deployments\n* <Icon icon=\"webhook\" /> **LangSmith traces webhooks**: Automated triggers based on trace analysis and performance metrics.\n* <Icon icon=\"play\" /> **Manual trigger**: Manual initiation of the pipeline for testing or emergency deployments.\n\n### Testing layers\n\nCompared to traditional software, testing AI agent applications also requires assessing response quality, so it is important to test each part of the workflow. The pipeline implements multiple testing layers:\n\n1. <Icon icon=\"puzzle-piece\" /> **Unit tests**: Individual node and utility function testing.\n2. <Icon icon=\"link\" /> **Integration tests**: Component interaction testing.\n3. <Icon icon=\"route\" /> **End-to-end tests**: Full graph execution testing.\n4. <Icon icon=\"brain\" /> **Offline evaluations**: Performance assessment with real-world scenarios including end-to-end evaluations, single-step evaluations, agent trajectory analysis, and multi-turn simulations.\n5. <Icon icon=\"server\" /> **LangGraph dev server tests**: Use the [langgraph-cli](/langsmith/cli) tool for spinning up (inside the GitHub Action) a local server to run the LangGraph agent. This polls the `/ok` server API endpoint until it is available and for 30 seconds, after that it throws an error.\n\n## GitHub Actions workflow\n\nThe CI/CD pipeline uses GitHub Actions with the [Control Plane API](/langsmith/api-ref-control-plane) and [LangSmith API](https://api.smith.langchain.com/redoc) to automate deployment. A helper script manages API interactions and deployments: [https://github.com/langchain-ai/cicd-pipeline-example/blob/main/.github/scripts/langgraph\\_api.py](https://github.com/langchain-ai/cicd-pipeline-example/blob/main/.github/scripts/langgraph_api.py).\n\nThe workflow includes:\n\n* **New agent deployment**: When a new PR is opened and tests pass, a new preview deployment is created in LangSmith Deployment using the [Control Plane API](/langsmith/api-ref-control-plane). This allows you to test the agent in a staging environment before promoting to production.\n\n* **Agent deployment revision**: A revision happens when an existing deployment with the same ID is found, or when the PR is merged into main. In the case of merging to main, the preview deployment is deleted and a production deployment is created. This ensures that any updates to the agent are properly deployed and integrated into the production infrastructure.\n\n  <img src=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=3ef7d51a322b8b5e2f9c2c70579fcc97\" alt=\"Agent Deployment Revision Workflow\" data-og-width=\"1022\" width=\"1022\" data-og-height=\"196\" height=\"196\" data-path=\"langsmith/images/cicd-new-lgp-revision.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=280&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=a3d06c339e84a1af99450d23e8bd617f 280w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=560&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=30589c8727af3ecb1d97881fd6692554 560w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=840&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=c05ab515ea0901fb2d076dee256ad108 840w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=1100&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=b939ad6842110227f70cc0526468d21d 1100w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=1650&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=0559d5b2a85414e954a72377b2eed9ec 1650w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-new-lgp-revision.png?w=2500&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=b8b96047a8b37f31b78d793cd7d18f45 2500w\" />\n\n* **Testing and evaluation workflow**: In addition to the more traditional testing phases (unit tests, integration tests, end-to-end tests, etc.), the pipeline includes [offline evaluations](/langsmith/evaluation-concepts#offline-evaluation) and [Agent dev server testing](/langsmith/local-server) because you want to test the quality of your agent. These evaluations provide comprehensive assessment of the agent's performance using real-world scenarios and data.\n\n  <img src=\"https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=477c3f5ec3d9bb9dfc354b9a57860636\" alt=\"Test with Results Workflow\" data-og-width=\"2050\" width=\"2050\" data-og-height=\"996\" height=\"996\" data-path=\"langsmith/images/cicd-test-with-results.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=280&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=7c5885b5f85c1c408fda449c5a0c706a 280w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=560&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=3b9a25332a9f6b56edfc9fbbfec248c1 560w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=840&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=380cb346fffbaf13365b37c6fa955c05 840w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=1100&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=8994d1e816e725865f90a2ac6601f7a4 1100w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=1650&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=42b752f1e5f0043dd6998ae372e83874 1650w, https://mintcdn.com/langchain-5e9cc07a/MrTet_AXQVddxOlO/langsmith/images/cicd-test-with-results.png?w=2500&fit=max&auto=format&n=MrTet_AXQVddxOlO&q=85&s=043be8ed1ef59cea171f30146790a877 2500w\" />\n\n  <AccordionGroup>\n    <Accordion title=\"Final Response Evaluation\" icon=\"check-circle\">\n      Evaluates the final output of your agent against expected results. This is the most common type of evaluation that checks if the agent's final response meets quality standards and answers the user's question correctly.\n    </Accordion>\n\n    <Accordion title=\"Single Step Evaluation\" icon=\"step-forward\">\n      Tests individual steps or nodes within your LangGraph workflow. This allows you to validate specific components of your agent's logic in isolation, ensuring each step functions correctly before testing the full pipeline.\n    </Accordion>\n\n    <Accordion title=\"Agent Trajectory Evaluation\" icon=\"route\">\n      Analyzes the complete path your agent takes through the graph, including all intermediate steps and decision points. This helps identify bottlenecks, unnecessary steps, or suboptimal routing in your agent's workflow. It also evaluates whether your agent invoked the right tools in the right order or at the right time.\n    </Accordion>\n\n    <Accordion title=\"Multi-Turn Evaluation\" icon=\"comments\">\n      Tests conversational flows where the agent maintains context across multiple interactions. This is crucial for agents that handle follow-up questions, clarifications, or extended dialogues with users.\n    </Accordion>\n  </AccordionGroup>\n\n  See the [LangGraph testing documentation](/oss/python/langgraph/test) for specific testing approaches and the [evaluation approaches guide](/langsmith/evaluation-approaches) for a comprehensive overview of offline evaluations.\n\n### Prerequisites\n\nBefore setting up the CI/CD pipeline, ensure you have:\n\n* <Icon icon=\"robot\" /> An AI agent application (in this case built using [LangGraph](/oss/python/langgraph/overview))\n* <Icon icon=\"user\" /> A [LangSmith account](https://smith.langchain.com/)\n* <Icon icon=\"key\" /> A [LangSmith API key](/langsmith/create-account-api-key) needed to deploy agents and retrieve experiment results\n* <Icon icon=\"cog\" /> Project-specific environment variables configured in your repository secrets (e.g., LLM model API keys, vector store credentials, database connections)\n\n<Note>\n  While this example uses GitHub, the CI/CD pipeline works with other Git hosting platforms including GitLab, Bitbucket, and others.\n</Note>\n\n## Deployment options\n\nLangSmith supports multiple deployment methods, depending on how your [LangSmith instance is hosted](/langsmith/platform-setup):\n\n* <Icon icon=\"cloud\" /> **Cloud LangSmith**: Direct GitHub integration.\n* <Icon icon=\"server\" /> **Self-Hosted/Hybrid**: Container registry-based deployments.\n\nThe deployment flow starts by modifying your agent implementation. At minimum, you must have a [`langgraph.json`](/langsmith/application-structure) and dependency file in your project (`requirements.txt` or `pyproject.toml`). Use the `langgraph dev` CLI tool to check for errors—fix any errors; otherwise, the deployment will succeed when deployed to LangSmith Deployment.",
      "language": "unknown"
    },
    {
      "code": "### Prerequisites for manual deployment\n\nBefore deploying your agent, ensure you have:\n\n1. <Icon icon=\"project-diagram\" /> **LangGraph graph**: Your agent implementation (e.g., `./agents/simple_text2sql.py:agent`).\n2. <Icon icon=\"box\" /> **Dependencies**: Either `requirements.txt` or `pyproject.toml` with all required packages.\n3. <Icon icon=\"cog\" /> **Configuration**: `langgraph.json` file specifying:\n   * Path to your agent graph\n   * Dependencies location\n   * Environment variables\n   * Python version\n\nExample `langgraph.json`:",
      "language": "unknown"
    },
    {
      "code": "### Local development and testing\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=425460d3401221ab441e21fc706c9cf1\" alt=\"Studio CLI Interface\" data-og-width=\"2972\" width=\"2972\" data-og-height=\"1354\" height=\"1354\" data-path=\"langsmith/images/cicd-studio-cli.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=280&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=35e64359dba47f4db4962148073cfadb 280w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=560&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=c12eb479d5c46921633c56bdead978bc 560w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=840&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=b36efc12f81027b7364cea82a4600fc3 840w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=1100&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=131c3fa2e989fbb8ebc4748a5790dc36 1100w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=1650&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=afa56b4e5ca02495ef5e7cb69d8e1329 1650w, https://mintcdn.com/langchain-5e9cc07a/-UAx6PdOIJpPyTy2/langsmith/images/cicd-studio-cli.png?w=2500&fit=max&auto=format&n=-UAx6PdOIJpPyTy2&q=85&s=774ec3dcf76a4b0e61989cd12e41e0c3 2500w\" />\n\nFirst, test your agent locally using [Studio](/langsmith/studio):",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h2",
      "text": "Pipeline architecture",
      "id": "pipeline-architecture"
    },
    {
      "level": "h3",
      "text": "Trigger sources",
      "id": "trigger-sources"
    },
    {
      "level": "h3",
      "text": "Testing layers",
      "id": "testing-layers"
    },
    {
      "level": "h2",
      "text": "GitHub Actions workflow",
      "id": "github-actions-workflow"
    },
    {
      "level": "h3",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Deployment options",
      "id": "deployment-options"
    },
    {
      "level": "h3",
      "text": "Prerequisites for manual deployment",
      "id": "prerequisites-for-manual-deployment"
    },
    {
      "level": "h3",
      "text": "Local development and testing",
      "id": "local-development-and-testing"
    }
  ],
  "url": "llms-txt#implement-a-ci/cd-pipeline-using-langsmith-deployment-and-evaluation",
  "links": []
}