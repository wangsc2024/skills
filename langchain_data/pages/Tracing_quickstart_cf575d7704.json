{
  "title": "Tracing quickstart",
  "content": "Source: https://docs.langchain.com/langsmith/observability-quickstart\n\n[*Observability*](/langsmith/observability-concepts) is a critical requirement for applications built with Large Language Models (LLMs). LLMs are non-deterministic, which means that the same prompt can produce different responses. This behavior makes debugging and monitoring more challenging than with traditional software.\n\nLangSmith addresses this by providing end-to-end visibility into how your application handles a request. Each request generates a [*trace*](/langsmith/observability-concepts#traces), which captures the full record of what happened. Within a trace are individual [*runs*](/langsmith/observability-concepts#runs), the specific operations your application performed, such as an LLM call or a retrieval step. Tracing runs allows you to inspect, debug, and validate your application’s behavior.\n\nIn this quickstart, you will set up a minimal [*Retrieval Augmented Generation (RAG)*](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-retrieval-augmented-generation-rag) application and add tracing with LangSmith. You will:\n\n1. Configure your environment.\n2. Create an application that retrieves context and calls an LLM.\n3. Enable tracing to capture both the retrieval step and the LLM call.\n4. View the resulting traces in the LangSmith UI.\n\n<Tip>\n  If you prefer to watch a video on getting started with tracing, refer to the quickstart [Video guide](#video-guide).\n</Tip>\n\nBefore you begin, make sure you have:\n\n* **A LangSmith account**: Sign up or log in at [smith.langchain.com](https://smith.langchain.com).\n* **A LangSmith API key**: Follow the [Create an API key](/langsmith/create-account-api-key#create-an-api-key) guide.\n* **An OpenAI API key**: Generate this from the [OpenAI dashboard](https://platform.openai.com/account/api-keys).\n\nThe example app in this quickstart will use OpenAI as the LLM provider. You can adapt the example for your app's LLM provider.\n\n<Tip>\n  If you're building an application with [LangChain](https://python.langchain.com/docs/introduction/) or [LangGraph](https://langchain-ai.github.io/langgraph/), you can enable LangSmith tracing with a single environment variable. Get started by reading the guides for tracing with [LangChain](/langsmith/trace-with-langchain) or tracing with [LangGraph](/langsmith/trace-with-langgraph).\n</Tip>\n\n## 1. Create a directory and install dependencies\n\nIn your terminal, create a directory for your project and install the dependencies in your environment:\n\n## 2. Set up environment variables\n\nSet the following environment variables:\n\n* `LANGSMITH_TRACING`\n* `LANGSMITH_API_KEY`\n* `OPENAI_API_KEY` (or your LLM provider's API key)\n* (optional) `LANGSMITH_WORKSPACE_ID`: If your LangSmith API key is linked to multiple workspaces, set this variable to specify which workspace to use.\n\nIf you're using Anthropic, use the [Anthropic wrapper](/langsmith/annotate-code#wrap-the-anthropic-client-python-only) to trace your calls. For other providers, use [the traceable wrapper](/langsmith/annotate-code#use-%40traceable-%2F-traceable).\n\n## 3. Define your application\n\nYou can use the example app code outlined in this step to instrument a RAG application. Or, you can use your own application code that includes an LLM call.\n\nThis is a minimal RAG app that uses the OpenAI SDK directly without any LangSmith tracing added yet. It has three main parts:\n\n* **Retriever function**: Simulates document retrieval that always returns the same string.\n* **OpenAI client**: Instantiates a plain OpenAI client to send a chat completion request.\n* **RAG function**: Combines the retrieved documents with the user’s question to form a system prompt, calls the `chat.completions.create()` endpoint with `gpt-4o-mini`, and returns the assistant’s response.\n\nAdd the following code into your app file (e.g., `app.py` or `app.ts`):\n\n## 4. Trace LLM calls\n\nTo start, you’ll trace all your OpenAI calls. LangSmith provides wrappers:\n\n* Python: [`wrap_openai`](https://docs.smith.langchain.com/reference/python/wrappers/langsmith.wrappers._openai.wrap_openai)\n* TypeScript: [`wrapOpenAI`](https://docs.smith.langchain.com/reference/js/functions/wrappers_openai.wrapOpenAI)\n\nThis snippet wraps the OpenAI client so that every subsequent model call is logged automatically as a traced child run in LangSmith.\n\n1. Include the highlighted lines in your app file:\n\n2. Call your application:\n\nYou'll receive the following output:\n\n3. In the [LangSmith UI](https://smith.langchain.com), navigate to the **default** Tracing Project for your workspace (or the workspace you specified in [Step 2](#2-set-up-environment-variables)). You'll see the OpenAI call you just instrumented.\n\n<div style={{ textAlign: 'center' }}>\n  <img className=\"block dark:hidden\" src=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=ba8074e55cc17ec7bbf0f6987ce15b8d\" alt=\"LangSmith UI showing an LLM call trace called ChatOpenAI with a system and human input followed by an AI Output.\" data-og-width=\"750\" width=\"750\" data-og-height=\"573\" height=\"573\" data-path=\"langsmith/images/trace-quickstart-llm-call.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=280&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=b94da918edfd11078bc637fdfc7fcc44 280w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=560&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=7f5f480bee06c54f0e5ad7ce122f722c 560w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=840&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=5e4e621619664b26cbe2d54719667ded 840w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=1100&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=c63599fdd8f12bc1abc80982af376053 1100w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=1650&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=69730a230b5d2cff4d737fab7d965c9f 1650w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=2500&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=d5e73432bdd2f3788f7600364f84c96f 2500w\" />\n\n<img className=\"hidden dark:block\" src=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=a00c55450b4a9937b8e557ef483a4bd6\" alt=\"LangSmith UI showing an LLM call trace called ChatOpenAI with a system and human input followed by an AI Output.\" data-og-width=\"728\" width=\"728\" data-og-height=\"549\" height=\"549\" data-path=\"langsmith/images/trace-quickstart-llm-call-dark.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=280&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=9b67fab1c4d3d0e2e45d4a38caa1aa82 280w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=560&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=3090d984d38ebac8d83272d235a11662 560w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=840&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=e515ea96b0e90b2c8dc639bccb7d81b2 840w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=1100&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=85584b64773a98555f22cad5c85ba46e 1100w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=1650&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=bc6e44054bb139c9ed00eeb375eb0f4f 1650w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=2500&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=e2cb7aa22421bc4a7d355658a6371d14 2500w\" />\n</div>\n\n## 5. Trace an entire application\n\nYou can also use the `traceable` decorator for [Python](https://docs.smith.langchain.com/reference/python/run_helpers/langsmith.run_helpers.traceable) or [TypeScript](https://langsmith-docs-bdk0fivr6-langchain.vercel.app/reference/js/functions/traceable.traceable) to trace your entire application instead of just the LLM calls.\n\n1. Include the highlighted code in your app file:\n\n2. Call the application again to create a run:\n\n3. Return to the [LangSmith UI](https://smith.langchain.com), navigate to the **default** Tracing Project for your workspace (or the workspace you specified in [Step 2](#2-set-up-environment-variables)). You'll find a trace of the entire app pipeline with the **rag** step and the **ChatOpenAI** LLM call.\n\n<div style={{ textAlign: 'center' }}>\n  <img className=\"block dark:hidden\" src=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=204edddb78b671c11a48de751c2e8e19\" alt=\"LangSmith UI showing a trace of the entire application called rag with an input followed by an output.\" data-og-width=\"750\" width=\"750\" data-og-height=\"425\" height=\"425\" data-path=\"langsmith/images/trace-quickstart-app.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?w=280&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=d5ad99d3c107fe3ccb63487f43bf912e 280w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?w=560&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=9f3cdb47af6471d1e508f1fa76883900 560w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?w=840&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=d1a496530ed1f98ccabbda138ef10b68 840w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?w=1100&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=d165f3f228f5ffaeb68b0bacc00a0f6e 1100w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?w=1650&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=ccc05e2cdbaf9bd71a6bcb8536997f2e 1650w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app.png?w=2500&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=2ebc113e6930abffa89644ccfd871404 2500w\" />\n\n<img className=\"hidden dark:block\" src=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=2392204346d412554fbda817e082bdcd\" alt=\"LangSmith UI showing a trace of the entire application called rag with an input followed by an output.\" data-og-width=\"738\" width=\"738\" data-og-height=\"394\" height=\"394\" data-path=\"langsmith/images/trace-quickstart-app-dark.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?w=280&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=7987f9046d36d015624c91f06d38efb2 280w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?w=560&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=4cf9bef39d55a3aa9a31e3911fe7bdba 560w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?w=840&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=0f0dc65c6705b4239afc33777e214cb7 840w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?w=1100&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=d2ccb5a3e2e91e45757f57f43b261861 1100w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?w=1650&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=2aec3b239854f4fd4f38807b991e5812 1650w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-app-dark.png?w=2500&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=b6ee98094ed25e6f2d61fed7241d648e 2500w\" />\n</div>\n\nHere are some topics you might want to explore next:\n\n* [Tracing integrations](/langsmith/trace-with-langchain) provide support for various LLM providers and agent frameworks.\n* [Filtering traces](/langsmith/filter-traces-in-application) can help you effectively navigate and analyze data in tracing projects that contain a significant amount of data.\n* [Trace a RAG application](/langsmith/observability-llm-tutorial) is a full tutorial, which adds observability to an application from development through to production.\n* [Sending traces to a specific project](/langsmith/log-traces-to-project) changes the destination project of your traces.\n\n<Callout type=\"info\" icon=\"bird\">\n  After logging traces, use **[Polly](/langsmith/polly)** to analyze them and get AI-powered insights into your application's performance.\n</Callout>\n\n<iframe className=\"w-full aspect-video rounded-xl\" src=\"https://www.youtube.com/embed/fA9b4D8IsPQ?si=0eBb1vzw5AxUtplS\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen />\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/observability-quickstart.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n## 2. Set up environment variables\n\nSet the following environment variables:\n\n* `LANGSMITH_TRACING`\n* `LANGSMITH_API_KEY`\n* `OPENAI_API_KEY` (or your LLM provider's API key)\n* (optional) `LANGSMITH_WORKSPACE_ID`: If your LangSmith API key is linked to multiple workspaces, set this variable to specify which workspace to use.",
      "language": "unknown"
    },
    {
      "code": "If you're using Anthropic, use the [Anthropic wrapper](/langsmith/annotate-code#wrap-the-anthropic-client-python-only) to trace your calls. For other providers, use [the traceable wrapper](/langsmith/annotate-code#use-%40traceable-%2F-traceable).\n\n## 3. Define your application\n\nYou can use the example app code outlined in this step to instrument a RAG application. Or, you can use your own application code that includes an LLM call.\n\nThis is a minimal RAG app that uses the OpenAI SDK directly without any LangSmith tracing added yet. It has three main parts:\n\n* **Retriever function**: Simulates document retrieval that always returns the same string.\n* **OpenAI client**: Instantiates a plain OpenAI client to send a chat completion request.\n* **RAG function**: Combines the retrieved documents with the user’s question to form a system prompt, calls the `chat.completions.create()` endpoint with `gpt-4o-mini`, and returns the assistant’s response.\n\nAdd the following code into your app file (e.g., `app.py` or `app.ts`):\n\n<CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n## 4. Trace LLM calls\n\nTo start, you’ll trace all your OpenAI calls. LangSmith provides wrappers:\n\n* Python: [`wrap_openai`](https://docs.smith.langchain.com/reference/python/wrappers/langsmith.wrappers._openai.wrap_openai)\n* TypeScript: [`wrapOpenAI`](https://docs.smith.langchain.com/reference/js/functions/wrappers_openai.wrapOpenAI)\n\nThis snippet wraps the OpenAI client so that every subsequent model call is logged automatically as a traced child run in LangSmith.\n\n1. Include the highlighted lines in your app file:\n\n   <CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n2. Call your application:\n\n   <CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n   You'll receive the following output:",
      "language": "unknown"
    },
    {
      "code": "3. In the [LangSmith UI](https://smith.langchain.com), navigate to the **default** Tracing Project for your workspace (or the workspace you specified in [Step 2](#2-set-up-environment-variables)). You'll see the OpenAI call you just instrumented.\n\n<div style={{ textAlign: 'center' }}>\n  <img className=\"block dark:hidden\" src=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=ba8074e55cc17ec7bbf0f6987ce15b8d\" alt=\"LangSmith UI showing an LLM call trace called ChatOpenAI with a system and human input followed by an AI Output.\" data-og-width=\"750\" width=\"750\" data-og-height=\"573\" height=\"573\" data-path=\"langsmith/images/trace-quickstart-llm-call.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=280&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=b94da918edfd11078bc637fdfc7fcc44 280w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=560&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=7f5f480bee06c54f0e5ad7ce122f722c 560w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=840&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=5e4e621619664b26cbe2d54719667ded 840w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=1100&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=c63599fdd8f12bc1abc80982af376053 1100w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=1650&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=69730a230b5d2cff4d737fab7d965c9f 1650w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call.png?w=2500&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=d5e73432bdd2f3788f7600364f84c96f 2500w\" />\n\n  <img className=\"hidden dark:block\" src=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=a00c55450b4a9937b8e557ef483a4bd6\" alt=\"LangSmith UI showing an LLM call trace called ChatOpenAI with a system and human input followed by an AI Output.\" data-og-width=\"728\" width=\"728\" data-og-height=\"549\" height=\"549\" data-path=\"langsmith/images/trace-quickstart-llm-call-dark.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=280&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=9b67fab1c4d3d0e2e45d4a38caa1aa82 280w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=560&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=3090d984d38ebac8d83272d235a11662 560w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=840&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=e515ea96b0e90b2c8dc639bccb7d81b2 840w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=1100&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=85584b64773a98555f22cad5c85ba46e 1100w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=1650&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=bc6e44054bb139c9ed00eeb375eb0f4f 1650w, https://mintcdn.com/langchain-5e9cc07a/C5sS0isXOt0-nMfw/langsmith/images/trace-quickstart-llm-call-dark.png?w=2500&fit=max&auto=format&n=C5sS0isXOt0-nMfw&q=85&s=e2cb7aa22421bc4a7d355658a6371d14 2500w\" />\n</div>\n\n## 5. Trace an entire application\n\nYou can also use the `traceable` decorator for [Python](https://docs.smith.langchain.com/reference/python/run_helpers/langsmith.run_helpers.traceable) or [TypeScript](https://langsmith-docs-bdk0fivr6-langchain.vercel.app/reference/js/functions/traceable.traceable) to trace your entire application instead of just the LLM calls.\n\n1. Include the highlighted code in your app file:\n\n   <CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n2. Call the application again to create a run:\n\n   <CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create a directory and install dependencies",
      "id": "1.-create-a-directory-and-install-dependencies"
    },
    {
      "level": "h2",
      "text": "2. Set up environment variables",
      "id": "2.-set-up-environment-variables"
    },
    {
      "level": "h2",
      "text": "3. Define your application",
      "id": "3.-define-your-application"
    },
    {
      "level": "h2",
      "text": "4. Trace LLM calls",
      "id": "4.-trace-llm-calls"
    },
    {
      "level": "h2",
      "text": "5. Trace an entire application",
      "id": "5.-trace-an-entire-application"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Video guide",
      "id": "video-guide"
    }
  ],
  "url": "llms-txt#tracing-quickstart",
  "links": []
}