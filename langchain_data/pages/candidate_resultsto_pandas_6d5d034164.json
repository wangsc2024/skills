{
  "title": "candidate_results.to_pandas()",
  "content": "## Comparing the results\n\nAfter running both experiments, you can view them in your dataset:\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=1c5d4f1cf212e2c38917319c7bbf7f99\" alt=\"Dataset page\" data-og-width=\"3022\" width=\"3022\" data-og-height=\"1536\" height=\"1536\" data-path=\"langsmith/images/dataset-page.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?w=280&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=01ebc5373bb6428b614eeade16aeb606 280w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?w=560&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=b2308ef5ed76bb80f111a89000457424 560w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?w=840&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=f2c76f9b1194a1a56efaa97d88b885f0 840w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?w=1100&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=beb69429d2a2e208b75924593a9a10c1 1100w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?w=1650&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=0fa47df443b9695d1e6863a57ca3a016 1650w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/dataset-page.png?w=2500&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=d257f3444d8357fb0b0340d09c16e127 2500w\" />\n\nThe results reveal an interesting tradeoff between the two models:\n\n1. GPT-4o shows improved performance in following formatting rules, consistently including the requested number of emojis\n2. However, GPT-4o is less reliable at staying grounded in the provided search results\n\nTo illustrate the grounding issue: in [this example run](https://smith.langchain.com/public/be060e19-0bc0-4798-94f5-c3d35719a5f6/r/07d43e7a-8632-479d-ae28-c7eac6e54da4), GPT-4o included facts about Ab큰 Bakr Muhammad ibn Zakariyy훮 al-R훮z카's medical contributions that weren't present in the search results. This demonstrates how it's pulling from its internal knowledge rather than strictly using the provided information.\n\nThis backtesting exercise revealed that while GPT-4o is generally considered a more capable model, simply upgrading to it wouldn't improve our tweet-writer. To effectively use GPT-4o, we would need to:\n\n* Refine our prompts to more strongly emphasize using only provided information\n* Or modify our system architecture to better constrain the model's outputs\n\nThis insight demonstrates the value of backtesting - it helped us identify potential issues before deployment.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=a8ab311399f3d0e69554a62f939fd475\" alt=\"Tutorial comparison view\" data-og-width=\"3018\" width=\"3018\" data-og-height=\"1532\" height=\"1532\" data-path=\"langsmith/images/tutorial-comparison-view.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?w=280&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=92dca1af013a79d9ce2ee944a17e23a9 280w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?w=560&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=16ac3bc225307b5408a49c225646a99e 560w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?w=840&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=517037b9b2a372dd5d4b2dc4e41eac6a 840w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?w=1100&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=d1b1d90b0838a53d1c693617fad61eb4 1100w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?w=1650&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=ecbe835c06c9451cac57d7cf0a16d0b9 1650w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/tutorial-comparison-view.png?w=2500&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=77d1da832c66587699653956fc15ccb6 2500w\" />\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/run-backtests-new-agent.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Comparing the results",
      "id": "comparing-the-results"
    }
  ],
  "url": "llms-txt#candidate_results.to_pandas()",
  "links": []
}