{
  "title": "How to improve your evaluator with few-shot examples",
  "content": "Source: https://docs.langchain.com/langsmith/create-few-shot-evaluators\n\nUsing LLM-as-a-judge evaluators can be very helpful when you can't evaluate your system programmatically. However, their effectiveness depends on their quality and how well they align with human reviewer feedback. LangSmith provides the ability to improve the alignment of LLM-as-a-judge evaluator to human preferences using few-shot examples.\n\nHuman corrections are automatically inserted into your evaluator prompt using few-shot examples. Few-shot examples is a technique inspired by [few-shot prompting](https://www.promptingguide.ai/techniques/fewshot) that guides the models output with a few high-quality examples.\n\nThis guide covers how to set up few-shot examples as part of your LLM-as-a-judge evaluator and apply corrections to feedback scores.\n\n## How few-shot examples work\n\n* Few-shot examples are added to your evaluator prompt using the `{{Few-shot examples}}` variable\n* Creating an evaluator with few-shot examples, will automatically create a dataset for you, which will be auto-populated with few-shot examples once you start making corrections\n* At runtime, these examples will inserted into the evaluator to serve as a guide for its outputs - this will help the evaluator to better align with human preferences\n\n## Configure your evaluator\n\n<Note>\n  Few-shot examples are not currently supported in LLM-as-a-judge evaluators that use the prompt hub and are only compatible with prompts that use mustache formatting.\n</Note>\n\nBefore enabling few-shot examples, set up your LLM-as-a-judge evaluator. If you haven't done this yet, follow the steps in the [LLM-as-a-judge evaluator guide](/langsmith/llm-as-judge).\n\n### 1. Configure variable mapping\n\nEach few-shot example is formatted according to the variable mapping specified in the configuration. The variable mapping for few-shot examples, should contain the same variables as your main prompt, plus a `few_shot_explanation` and a `score` variable which should have the same name as your feedback key.\n\nFor example, if your main prompt has variables `question` and `response`, and your evaluator outputs a `correctness` score, then your few-shot prompt should have the vartiables `question`, `response`, `few_shot_explanation`, and `correctness`.\n\n### 2. Specify the number of few-shot examples to use\n\nYou may also specify the number of few-shot examples to use. The default is 5. If your examples are very long, you may want to set this number lower to save tokens - whereas if your examples tend to be short, you can set a higher number in order to give your evaluator more examples to learn from. If you have more examples in your dataset than this number, we will randomly choose them for you.\n\n<Info>\n  [Audit evaluator scores](/langsmith/audit-evaluator-scores)\n</Info>\n\nAs you start logging traces or running experiments, you will likely disagree with some of the scores that your evaluator has given. When you [make corrections to these scores](/langsmith/audit-evaluator-scores), you will begin seeing examples populated inside your corrections dataset. As you make corrections, make sure to attach explanations - these will get populated into your evaluator prompt in place of the `few_shot_explanation` variable.\n\nThe inputs to the few-shot examples will be the relevant fields from the inputs, outputs, and reference (if this an offline evaluator) of your chain/dataset. The outputs will be the corrected evaluator score and the explanations that you created when you left the corrections. Feel free to edit these to your liking. Here is an example of a few-shot example in a corrections dataset:\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=8c7bfcc6cc4ab86c18240c3cbf2ea44c\" alt=\"Few-shot example\" data-og-width=\"1572\" width=\"1572\" data-og-height=\"790\" height=\"790\" data-path=\"langsmith/images/few-shot-example.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?w=280&fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=91f4e17fd853ba23c1b04934144dfa77 280w, https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?w=560&fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=e0a5e2a026e4166c341900dd49316f35 560w, https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?w=840&fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=88aec2ef5c37c16c67e0eefecd3fbc0a 840w, https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?w=1100&fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=bfbbd35cf503ce2f3dbf743fab8fb75b 1100w, https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?w=1650&fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=bf0765bfeabc8d34ef49626dca0135ae 1650w, https://mintcdn.com/langchain-5e9cc07a/0B2PFrFBMRWNccee/langsmith/images/few-shot-example.png?w=2500&fit=max&auto=format&n=0B2PFrFBMRWNccee&q=85&s=f9d2cf9437ee0e160a511903bd88238a 2500w\" />\n\nNote that the corrections may take a minute or two to be populated into your few-shot dataset. Once they are there, future runs of your evaluator will include them in the prompt!\n\n## View your corrections dataset\n\nIn order to view your corrections dataset:\n\n* **Online evaluators**: Select your run rule and click **Edit Rule**\n* **Offline evaluators**: Select your evaluator and click **Edit Evaluator**\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=03453ef08f1c272d5d9aaf71d1fb7301\" alt=\"Edit Evaluator\" data-og-width=\"800\" width=\"800\" data-og-height=\"284\" height=\"284\" data-path=\"langsmith/images/edit-evaluator.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?w=280&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=d495c791e6c8ae9d241085795d4b67b5 280w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?w=560&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=b1ddde8054744862494e4d3f02a460b0 560w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?w=840&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=9838e073d1d7e61c6b79d8f35ba1a1b3 840w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?w=1100&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=67322be4166f4479a466427a9b270ca1 1100w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?w=1650&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=4cd490404d1616498fed810b3ce75a21 1650w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/edit-evaluator.png?w=2500&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=4c8a87ad332661a0b8b472dd34f1f4ab 2500w\" />\n\nHead to your dataset of corrections linked in the the **Improve evaluator accuracy using few-shot examples** section. You can view and update your few-shot examples in the dataset.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=3215f3f24a08186fd76c6dbad18a3cf5\" alt=\"View few-shot dataset\" data-og-width=\"1470\" width=\"1470\" data-og-height=\"478\" height=\"478\" data-path=\"langsmith/images/view-few-shot-ds.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?w=280&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=ad702a532a8f083c71056baff4370f30 280w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?w=560&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=d45ebd4263adc9c10598fad633167ca3 560w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?w=840&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=fe060c8d000a41566949ff35d6c62135 840w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?w=1100&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=f735943da46a1e57328b86246f5da25f 1100w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?w=1650&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=9861b9651d5d63a07662e7aa1bc68491 1650w, https://mintcdn.com/langchain-5e9cc07a/1RIJxfRpkszanJLL/langsmith/images/view-few-shot-ds.png?w=2500&fit=max&auto=format&n=1RIJxfRpkszanJLL&q=85&s=6084c3697ffd582e30301540906a5698 2500w\" />\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/create-few-shot-evaluators.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "How few-shot examples work",
      "id": "how-few-shot-examples-work"
    },
    {
      "level": "h2",
      "text": "Configure your evaluator",
      "id": "configure-your-evaluator"
    },
    {
      "level": "h3",
      "text": "1. Configure variable mapping",
      "id": "1.-configure-variable-mapping"
    },
    {
      "level": "h3",
      "text": "2. Specify the number of few-shot examples to use",
      "id": "2.-specify-the-number-of-few-shot-examples-to-use"
    },
    {
      "level": "h2",
      "text": "Make corrections",
      "id": "make-corrections"
    },
    {
      "level": "h2",
      "text": "View your corrections dataset",
      "id": "view-your-corrections-dataset"
    }
  ],
  "url": "llms-txt#how-to-improve-your-evaluator-with-few-shot-examples",
  "links": []
}