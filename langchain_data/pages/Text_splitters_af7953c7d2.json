{
  "title": "Text splitters",
  "content": "Source: https://docs.langchain.com/oss/python/integrations/splitters/index\n\n**Text splitters** break large docs into smaller chunks that will be retrievable individually and fit within model context window limit.\n\nThere are several strategies for splitting documents, each with its own advantages.\n\n<Tip>\n  For most use cases, start with the [`RecursiveCharacterTextSplitter`](/oss/python/integrations/splitters/recursive_text_splitter). It provides a solid balance between keeping context intact and managing chunk size. This default strategy works well out of the box, and you should only consider adjusting it if you need to fine-tune performance for your specific application.\n</Tip>\n\n## Text structure-based\n\nText is naturally organized into hierarchical units such as paragraphs, sentences, and words. We can leverage this inherent structure to inform our splitting strategy, creating split that maintain natural language flow, maintain semantic coherence within split, and adapts to varying levels of text granularity. LangChain's `RecursiveCharacterTextSplitter` implements this concept:\n\n* The [`RecursiveCharacterTextSplitter`](/oss/python/integrations/splitters/recursive_text_splitter) attempts to keep larger units (e.g., paragraphs) intact.\n* If a unit exceeds the chunk size, it moves to the next level (e.g., sentences).\n* This process continues down to the word level if necessary.\n\n**Available text splitters**:\n\n* [Recursively split text](/oss/python/integrations/splitters/recursive_text_splitter)\n\nAn intuitive strategy is to split documents based on their length. This simple yet effective approach ensures that each chunk doesn't exceed a specified size limit. Key benefits of length-based splitting:\n\n* Straightforward implementation\n* Consistent chunk sizes\n* Easily adaptable to different model requirements\n\nTypes of length-based splitting:\n\n* Token-based: Splits text based on the number of tokens, which is useful when working with language models.\n* Character-based: Splits text based on the number of characters, which can be more consistent across different types of text.\n\nExample implementation using LangChain's `CharacterTextSplitter` with token-based splitting:\n\n**Available text splitters**:\n\n* [Split by tokens](/oss/python/integrations/splitters/split_by_token)\n* [Split by characters](/oss/python/integrations/splitters/character_text_splitter)\n\n## Document structure-based\n\nSome documents have an inherent structure, such as HTML, Markdown, or JSON files. In these cases, it's beneficial to split the document based on its structure, as it often naturally groups semantically related text. Key benefits of structure-based splitting:\n\n* Preserves the logical organization of the document\n* Maintains context within each chunk\n* Can be more effective for downstream tasks like retrieval or summarization\n\nExamples of structure-based splitting:\n\n* Markdown: Split based on headers (e.g., `#`, `##`, `###`)\n* HTML: Split using tags\n* JSON: Split by object or array elements\n* Code: Split by functions, classes, or logical blocks\n\n**Available text splitters**:\n\n* [Split Markdown](/oss/python/integrations/splitters/markdown_header_metadata_splitter)\n* [Split JSON](/oss/python/integrations/splitters/recursive_json_splitter)\n* [Split code](/oss/python/integrations/splitters/code_splitter)\n* [Split HTML](/oss/python/integrations/splitters/split_html)\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/integrations/splitters/index.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n**Text splitters** break large docs into smaller chunks that will be retrievable individually and fit within model context window limit.\n\nThere are several strategies for splitting documents, each with its own advantages.\n\n<Tip>\n  For most use cases, start with the [`RecursiveCharacterTextSplitter`](/oss/python/integrations/splitters/recursive_text_splitter). It provides a solid balance between keeping context intact and managing chunk size. This default strategy works well out of the box, and you should only consider adjusting it if you need to fine-tune performance for your specific application.\n</Tip>\n\n## Text structure-based\n\nText is naturally organized into hierarchical units such as paragraphs, sentences, and words. We can leverage this inherent structure to inform our splitting strategy, creating split that maintain natural language flow, maintain semantic coherence within split, and adapts to varying levels of text granularity. LangChain's `RecursiveCharacterTextSplitter` implements this concept:\n\n* The [`RecursiveCharacterTextSplitter`](/oss/python/integrations/splitters/recursive_text_splitter) attempts to keep larger units (e.g., paragraphs) intact.\n* If a unit exceeds the chunk size, it moves to the next level (e.g., sentences).\n* This process continues down to the word level if necessary.\n\nExample usage:",
      "language": "unknown"
    },
    {
      "code": "**Available text splitters**:\n\n* [Recursively split text](/oss/python/integrations/splitters/recursive_text_splitter)\n\n## Length-based\n\nAn intuitive strategy is to split documents based on their length. This simple yet effective approach ensures that each chunk doesn't exceed a specified size limit. Key benefits of length-based splitting:\n\n* Straightforward implementation\n* Consistent chunk sizes\n* Easily adaptable to different model requirements\n\nTypes of length-based splitting:\n\n* Token-based: Splits text based on the number of tokens, which is useful when working with language models.\n* Character-based: Splits text based on the number of characters, which can be more consistent across different types of text.\n\nExample implementation using LangChain's `CharacterTextSplitter` with token-based splitting:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Text structure-based",
      "id": "text-structure-based"
    },
    {
      "level": "h2",
      "text": "Length-based",
      "id": "length-based"
    },
    {
      "level": "h2",
      "text": "Document structure-based",
      "id": "document-structure-based"
    }
  ],
  "url": "llms-txt#text-splitters",
  "links": []
}