{
  "title": "> User is John Smith.",
  "content": "python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain.messages import ToolMessage\nfrom langchain.agents import create_agent, AgentState\nfrom langgraph.types import Command\nfrom pydantic import BaseModel\n\nclass CustomState(AgentState):  # [!code highlight]\n    user_name: str\n\nclass CustomContext(BaseModel):\n    user_id: str\n\n@tool\ndef update_user_info(\n    runtime: ToolRuntime[CustomContext, CustomState],\n) -> Command:\n    \"\"\"Look up and update user info.\"\"\"\n    user_id = runtime.context.user_id\n    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n    return Command(update={  # [!code highlight]\n        \"user_name\": name,\n        # update the message history\n        \"messages\": [\n            ToolMessage(\n                \"Successfully looked up user information\",\n                tool_call_id=runtime.tool_call_id\n            )\n        ]\n    })\n\n@tool\ndef greet(\n    runtime: ToolRuntime[CustomContext, CustomState]\n) -> str | Command:\n    \"\"\"Use this to greet the user once you found their info.\"\"\"\n    user_name = runtime.state.get(\"user_name\", None)\n    if user_name is None:\n       return Command(update={\n            \"messages\": [\n                ToolMessage(\n                    \"Please call the 'update_user_info' tool it will get and update the user's name.\",\n                    tool_call_id=runtime.tool_call_id\n                )\n            ]\n        })\n    return f\"Hello {user_name}!\"\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[update_user_info, greet],\n    state_schema=CustomState, # [!code highlight]\n    context_schema=CustomContext,\n)\n\nagent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n    context=CustomContext(user_id=\"user_123\"),\n)\npython  theme={null}\nfrom langchain.agents import create_agent\nfrom typing import TypedDict\nfrom langchain.agents.middleware import dynamic_prompt, ModelRequest\n\nclass CustomContext(TypedDict):\n    user_name: str\n\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather in a city.\"\"\"\n    return f\"The weather in {city} is always sunny!\"\n\n@dynamic_prompt\ndef dynamic_system_prompt(request: ModelRequest) -> str:\n    user_name = request.runtime.context[\"user_name\"]\n    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n    return system_prompt\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_weather],\n    middleware=[dynamic_system_prompt],\n    context_schema=CustomContext,\n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n    context=CustomContext(user_name=\"John Smith\"),\n)\nfor msg in result[\"messages\"]:\n    msg.pretty_print()\n\nshell title=\"Output\" theme={null}\n================================ Human Message =================================\n\nWhat is the weather in SF?\n================================== Ai Message ==================================\nTool Calls:\n  get_weather (call_WFQlOGn4b2yoJrv7cih342FG)\n Call ID: call_WFQlOGn4b2yoJrv7cih342FG\n  Args:\n    city: San Francisco\n================================= Tool Message =================================\nName: get_weather\n\nThe weather in San Francisco is always sunny!\n================================== Ai Message ==================================\n\nHi John Smith, the weather in San Francisco is always sunny!\nmermaid  theme={null}\n%%{\n    init: {\n        \"fontFamily\": \"monospace\",\n        \"flowchart\": {\n        \"curve\": \"basis\"\n        },\n        \"themeVariables\": {\"edgeLabelBackground\": \"transparent\"}\n    }\n}%%\ngraph TD\n    S([\"\\_\\_start\\_\\_\"])\n    PRE(before_model)\n    MODEL(model)\n    TOOLS(tools)\n    END([\"\\_\\_end\\_\\_\"])\n    S --> PRE\n    PRE --> MODEL\n    MODEL -.-> TOOLS\n    MODEL -.-> END\n    TOOLS --> PRE\n    classDef blueHighlight fill:#0a1c25,stroke:#0a455f,color:#bae6fd;\n    class S blueHighlight;\n    class END blueHighlight;\npython  theme={null}\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model\nfrom langchain_core.runnables import RunnableConfig\nfrom langgraph.runtime import Runtime\nfrom typing import Any\n\n@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\nif len(messages) <= 3:\n        return None  # No changes needed\n\nfirst_msg = messages[0]\n    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n    new_messages = [first_msg] + recent_messages\n\nreturn {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *new_messages\n        ]\n    }\n\nagent = create_agent(\n    \"gpt-5-nano\",\n    tools=[],\n    middleware=[trim_messages],\n    checkpointer=InMemorySaver()\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nagent.invoke({\"messages\": \"hi, my name is bob\"}, config)\nagent.invoke({\"messages\": \"write a short poem about cats\"}, config)\nagent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n\"\"\"\n================================== Ai Message ==================================\n\nYour name is Bob. You told me that earlier.\nIf you'd like me to call you a nickname or use a different name, just say the word.\n\"\"\"\nmermaid  theme={null}\n%%{\n    init: {\n        \"fontFamily\": \"monospace\",\n        \"flowchart\": {\n        \"curve\": \"basis\"\n        },\n        \"themeVariables\": {\"edgeLabelBackground\": \"transparent\"}\n    }\n}%%\ngraph TD\n    S([\"\\_\\_start\\_\\_\"])\n    MODEL(model)\n    POST(after_model)\n    TOOLS(tools)\n    END([\"\\_\\_end\\_\\_\"])\n    S --> MODEL\n    MODEL --> POST\n    POST -.-> END\n    POST -.-> TOOLS\n    TOOLS --> MODEL\n    classDef blueHighlight fill:#0a1c25,stroke:#0a455f,color:#bae6fd;\n    class S blueHighlight;\n    class END blueHighlight;\n    class POST greenHighlight;\npython  theme={null}\nfrom langchain.messages import RemoveMessage\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import after_model\nfrom langgraph.runtime import Runtime\n\n@after_model\ndef validate_response(state: AgentState, runtime: Runtime) -> dict | None:\n    \"\"\"Remove messages containing sensitive words.\"\"\"\n    STOP_WORDS = [\"password\", \"secret\"]\n    last_message = state[\"messages\"][-1]\n    if any(word in last_message.content for word in STOP_WORDS):\n        return {\"messages\": [RemoveMessage(id=last_message.id)]}\n    return None\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[],\n    middleware=[validate_response],\n    checkpointer=InMemorySaver(),\n)\n```\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/short-term-memory.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "#### Write short-term memory from tools\n\nTo modify the agent's short-term memory (state) during execution, you can return state updates directly from the tools.\n\nThis is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.",
      "language": "unknown"
    },
    {
      "code": "### Prompt\n\nAccess short term memory (state) in middleware to create dynamic prompts based on conversation history or custom state fields.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Before model\n\nAccess short term memory (state) in [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware to process messages before model calls.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### After model\n\nAccess short term memory (state) in [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) middleware to process messages after model calls.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "Prompt",
      "id": "prompt"
    },
    {
      "level": "h3",
      "text": "Before model",
      "id": "before-model"
    },
    {
      "level": "h3",
      "text": "After model",
      "id": "after-model"
    }
  ],
  "url": "llms-txt#>-user-is-john-smith.",
  "links": []
}