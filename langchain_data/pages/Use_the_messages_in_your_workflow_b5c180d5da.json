{
  "title": "Use the messages in your workflow",
  "content": "for message in messages:\n    print(f\"{message.type}: {message.content}\")\npython  theme={null}\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langchain_mcp_adapters.prompts import load_mcp_prompt\n\nclient = MultiServerMCPClient({...})\n\nasync with client.session(\"server_name\") as session:\n    # Load a prompt by name\n    messages = await load_mcp_prompt(session, \"summarize\")\n\n# Load a prompt with arguments\n    messages = await load_mcp_prompt(\n        session,\n        \"code_review\",\n        arguments={\"language\": \"python\", \"focus\": \"security\"}\n    )\npython Inject user context into MCP tool calls theme={null}\n    from dataclasses import dataclass\n    from langchain_mcp_adapters.client import MultiServerMCPClient\n    from langchain_mcp_adapters.interceptors import MCPToolCallRequest\n    from langchain.agents import create_agent\n\n@dataclass\n    class Context:\n        user_id: str\n        api_key: str\n\nasync def inject_user_context(\n        request: MCPToolCallRequest,\n        handler,\n    ):\n        \"\"\"Inject user credentials into MCP tool calls.\"\"\"\n        runtime = request.runtime\n        user_id = runtime.context.user_id  # [!code highlight]\n        api_key = runtime.context.api_key  # [!code highlight]\n\n# Add user context to tool arguments\n        modified_request = request.override(\n            args={**request.args, \"user_id\": user_id}\n        )\n        return await handler(modified_request)\n\nclient = MultiServerMCPClient(\n        {...},\n        tool_interceptors=[inject_user_context],\n    )\n    tools = await client.get_tools()\n    agent = create_agent(\"gpt-4o\", tools, context_schema=Context)\n\n# Invoke with user context\n    result = await agent.ainvoke(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"Search my orders\"}]},\n        context={\"user_id\": \"user_123\", \"api_key\": \"sk-...\"}\n    )\n    python Access user preferences from store theme={null}\n    from dataclasses import dataclass\n    from langchain_mcp_adapters.client import MultiServerMCPClient\n    from langchain_mcp_adapters.interceptors import MCPToolCallRequest\n    from langchain.agents import create_agent\n    from langgraph.store.memory import InMemoryStore\n\n@dataclass\n    class Context:\n        user_id: str\n\nasync def personalize_search(\n        request: MCPToolCallRequest,\n        handler,\n    ):\n        \"\"\"Personalize MCP tool calls using stored preferences.\"\"\"\n        runtime = request.runtime\n        user_id = runtime.context.user_id\n        store = runtime.store  # [!code highlight]\n\n# Read user preferences from store\n        prefs = store.get((\"preferences\",), user_id)  # [!code highlight]\n\nif prefs and request.name == \"search\":\n            # Apply user's preferred language and result limit\n            modified_args = {\n                **request.args,\n                \"language\": prefs.value.get(\"language\", \"en\"),\n                \"limit\": prefs.value.get(\"result_limit\", 10),\n            }\n            request = request.override(args=modified_args)\n\nreturn await handler(request)\n\nclient = MultiServerMCPClient(\n        {...},\n        tool_interceptors=[personalize_search],\n    )\n    tools = await client.get_tools()\n    agent = create_agent(\n        \"gpt-4o\",\n        tools,\n        context_schema=Context,\n        store=InMemoryStore()\n    )\n    python Filter tools based on authentication state theme={null}\n    from langchain_mcp_adapters.client import MultiServerMCPClient\n    from langchain_mcp_adapters.interceptors import MCPToolCallRequest\n    from langchain.messages import ToolMessage\n\nasync def require_authentication(\n        request: MCPToolCallRequest,\n        handler,\n    ):\n        \"\"\"Block sensitive MCP tools if user is not authenticated.\"\"\"\n        runtime = request.runtime\n        state = runtime.state  # [!code highlight]\n        is_authenticated = state.get(\"authenticated\", False)  # [!code highlight]\n\nsensitive_tools = [\"delete_file\", \"update_settings\", \"export_data\"]\n\nif request.name in sensitive_tools and not is_authenticated:\n            # Return error instead of calling tool\n            return ToolMessage(\n                content=\"Authentication required. Please log in first.\",\n                tool_call_id=runtime.tool_call_id,\n            )\n\nreturn await handler(request)\n\nclient = MultiServerMCPClient(\n        {...},\n        tool_interceptors=[require_authentication],\n    )\n    python Return custom responses with tool call ID theme={null}\n    from langchain_mcp_adapters.client import MultiServerMCPClient\n    from langchain_mcp_adapters.interceptors import MCPToolCallRequest\n    from langchain.messages import ToolMessage\n\nasync def rate_limit_interceptor(\n        request: MCPToolCallRequest,\n        handler,\n    ):\n        \"\"\"Rate limit expensive MCP tool calls.\"\"\"\n        runtime = request.runtime\n        tool_call_id = runtime.tool_call_id  # [!code highlight]\n\n# Check rate limit (simplified example)\n        if is_rate_limited(request.name):\n            return ToolMessage(\n                content=\"Rate limit exceeded. Please try again later.\",\n                tool_call_id=tool_call_id,  # [!code highlight]\n            )\n\nresult = await handler(request)\n\n# Log successful tool call\n        log_tool_execution(tool_call_id, request.name, success=True)\n\nclient = MultiServerMCPClient(\n        {...},\n        tool_interceptors=[rate_limit_interceptor],\n    )\n    python Mark task complete and switch agents theme={null}\nfrom langchain.agents import AgentState, create_agent\nfrom langchain_mcp_adapters.interceptors import MCPToolCallRequest\nfrom langchain.messages import ToolMessage\nfrom langgraph.types import Command\n\nasync def handle_task_completion(\n    request: MCPToolCallRequest,\n    handler,\n):\n    \"\"\"Mark task complete and hand off to summary agent.\"\"\"\n    result = await handler(request)\n\nif request.name == \"submit_order\":\n        return Command(\n            update={\n                \"messages\": [result] if isinstance(result, ToolMessage) else [],\n                \"task_status\": \"completed\",  # [!code highlight]\n            },\n            goto=\"summary_agent\",  # [!code highlight]\n        )\n\nreturn result\npython End agent run on completion theme={null}\nasync def end_on_success(\n    request: MCPToolCallRequest,\n    handler,\n):\n    \"\"\"End agent run when task is marked complete.\"\"\"\n    result = await handler(request)\n\nif request.name == \"mark_complete\":\n        return Command(\n            update={\"messages\": [result], \"status\": \"done\"},\n            goto=\"__end__\",  # [!code highlight]\n        )\n\nreturn result\npython Basic interceptor pattern theme={null}\nfrom langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langchain_mcp_adapters.interceptors import MCPToolCallRequest\n\nasync def logging_interceptor(\n    request: MCPToolCallRequest,\n    handler,\n):\n    \"\"\"Log tool calls before and after execution.\"\"\"\n    print(f\"Calling tool: {request.name} with args: {request.args}\")\n    result = await handler(request)\n    print(f\"Tool {request.name} returned: {result}\")\n    return result\n\nclient = MultiServerMCPClient(\n    {\"math\": {\"transport\": \"stdio\", \"command\": \"python\", \"args\": [\"/path/to/server.py\"]}},\n    tool_interceptors=[logging_interceptor],  # [!code highlight]\n)\npython Modifying tool arguments theme={null}\nasync def double_args_interceptor(\n    request: MCPToolCallRequest,\n    handler,\n):\n    \"\"\"Double all numeric arguments before execution.\"\"\"\n    modified_args = {k: v * 2 for k, v in request.args.items()}\n    modified_request = request.override(args=modified_args)  # [!code highlight]\n    return await handler(modified_request)",
  "code_samples": [
    {
      "code": "You can also use [`load_mcp_prompt`](/docs/reference/langchain-mcp-adapters#load_mcp_prompt) directly with a session for more control:",
      "language": "unknown"
    },
    {
      "code": "## Advanced features\n\n### Tool Interceptors\n\nMCP servers run as separate processes—they can't access LangGraph runtime information like the [store](/oss/python/langgraph/persistence#memory-store), [context](/oss/python/langchain/context-engineering), or agent state. **Interceptors bridge this gap** by giving you access to this runtime context during MCP tool execution.\n\nInterceptors also provide middleware-like control over tool calls: you can modify requests, implement retries, add headers dynamically, or short-circuit execution entirely.\n\n| Section                                                   | Description                                                                 |\n| --------------------------------------------------------- | --------------------------------------------------------------------------- |\n| [Accessing runtime context](#accessing-runtime-context)   | Read user IDs, API keys, store data, and agent state                        |\n| [State updates and commands](#state-updates-and-commands) | Update agent state or control graph flow with `Command`                     |\n| [Writing interceptors](#writing-interceptors)             | Patterns for modifying requests, composing interceptors, and error handling |\n\n#### Accessing runtime context\n\nWhen MCP tools are used within a LangChain agent (via `create_agent`), interceptors receive access to the `ToolRuntime` context. This provides access to the tool call ID, state, config, and store—enabling powerful patterns for accessing user data, persisting information, and controlling agent behavior.\n\n<Tabs>\n  <Tab title=\"Runtime context\">\n    Access user-specific configuration like user IDs, API keys, or permissions that are passed at invocation time:",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Store\">\n    Access long-term memory to retrieve user preferences or persist data across conversations:",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"State\">\n    Access conversation state to make decisions based on the current session:",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Tool call ID\">\n    Access the tool call ID to return properly formatted responses or track tool executions:",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n</Tabs>\n\nFor more context engineering patterns, see [Context engineering](/oss/python/langchain/context-engineering) and [Tools](/oss/python/langchain/tools).\n\n#### State updates and commands\n\nInterceptors can return `Command` objects to update agent state or control graph execution flow. This is useful for tracking task progress, switching between agents, or ending execution early.",
      "language": "unknown"
    },
    {
      "code": "Use `Command` with `goto=\"__end__\"` to end execution early:",
      "language": "unknown"
    },
    {
      "code": "#### Custom interceptors\n\nInterceptors are async functions that wrap tool execution, enabling request/response modification, retry logic, and other cross-cutting concerns. They follow an \"onion\" pattern where the first interceptor in the list is the outermost layer.\n\n**Basic pattern**\n\nAn interceptor is an async function that receives a request and a handler. You can modify the request before calling the handler, modify the response after, or skip the handler entirely.",
      "language": "unknown"
    },
    {
      "code": "**Modifying requests**\n\nUse `request.override()` to create a modified request. This follows an immutable pattern, leaving the original request unchanged.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Advanced features",
      "id": "advanced-features"
    },
    {
      "level": "h3",
      "text": "Tool Interceptors",
      "id": "tool-interceptors"
    }
  ],
  "url": "llms-txt#use-the-messages-in-your-workflow",
  "links": []
}