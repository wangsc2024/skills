{
  "title": "Optional: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true",
  "content": "shell  theme={null}\nOTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://otlp.nr-data.net/v1/traces\nOTEL_EXPORTER_OTLP_ENDPOINT=https://otlp.nr-data.net\nOTEL_EXPORTER_OTLP_HEADERS=api-key=<YOUR_INGEST_LICENSE_KEY>\n```\n\n<Note>\n  OTel tracing was added in Agent Server version `0.5.32` and is currently in Alpha.\n</Note>\n\nSpecify `DD_API_KEY` (your [Datadog API Key](https://docs.datadoghq.com/account_management/api-app-keys/)) to automatically enable Datadog tracing for the deployment. Specify other [`DD_*` environment variables](https://ddtrace.readthedocs.io/en/stable/configuration.html) to configure the tracing instrumentation.\n\nIf `DD_API_KEY` is specified, the application process is wrapped in the [`ddtrace-run` command](https://ddtrace.readthedocs.io/en/stable/installation_quickstart.html). Other `DD_*` environment variables (e.g. `DD_SITE`, `DD_ENV`, `DD_SERVICE`, `DD_TRACE_ENABLED`) are typically needed to properly configure the tracing instrumentation. See [`DD_*` environment variables](https://ddtrace.readthedocs.io/en/stable/configuration.html) for more details. You can enable `DD_TRACE_DEBUG=true` and set `DD_LOG_LEVEL=debug` to troubleshoot.\n\n<Note>\n  Enabling `DD_API_KEY` (and thus `ddtrace-run`) can override or interfere with other auto-instrumentation solutions (such as OpenTelemetry) that you may have instrumented into your application code.\n</Note>\n\n## `LANGCHAIN_TRACING_SAMPLING_RATE`\n\nSampling rate for traces sent to LangSmith. Valid values: Any float between `0` and `1`.\n\nFor more details, refer to [Set a sampling rate for traces](/langsmith/sample-traces).\n\n## `LANGGRAPH_AUTH_TYPE`\n\nType of authentication for the Agent Server deployment. Valid values: `langsmith`, `noop`.\n\nFor deployments to LangSmith, this environment variable is set automatically. For local development or deployments where authentication is handled externally (e.g. self-hosted), set this environment variable to `noop`.\n\n## `LANGGRAPH_POSTGRES_POOL_MAX_SIZE`\n\nBeginning with langgraph-api version `0.2.12`, the maximum size of the Postgres connection pool (per replica) can be controlled using the `LANGGRAPH_POSTGRES_POOL_MAX_SIZE` environment variable. By setting this variable, you can determine the upper bound on the number of simultaneous connections the server will establish with the Postgres database.\n\nFor example, if a deployment is scaled up to 10 replicas and `LANGGRAPH_POSTGRES_POOL_MAX_SIZE` is configured to `150`, then up to `1500` connections to Postgres can be established. This is particularly useful for deployments where database resources are limited (or more available) or where you need to tune connection behavior for performance or scaling reasons.\n\nDefaults to `150` connections.\n\n## `LANGSMITH_API_KEY`\n\nFor deployments with [self-hosted LangSmith](/langsmith/self-hosted) only.\n\nTo send traces to a self-hosted LangSmith instance, set `LANGSMITH_API_KEY` to an API key created from the self-hosted instance.\n\n## `LANGSMITH_ENDPOINT`\n\nFor deployments with [self-hosted LangSmith](/langsmith/self-hosted) only.\n\nTo send traces to a self-hosted LangSmith instance, set `LANGSMITH_ENDPOINT` to the hostname of the self-hosted instance.\n\n## `LANGSMITH_TRACING`\n\nSet `LANGSMITH_TRACING` to `false` to disable tracing to LangSmith.\n\nThis is mainly relevant in the context of using the dev server via the `langgraph dev` command. Set `LOG_COLOR` to `true` to enable ANSI-colored console output when using the default console renderer. Disabling color output by setting this variable to `false` produces monochrome logs. Defaults to `true`.\n\nConfigure [log level](https://docs.python.org/3/library/logging.html#logging-levels). Defaults to `INFO`.\n\nSet `LOG_JSON` to `true` to render all log messages as JSON objects using the configured `JSONRenderer`. This produces structured logs that can be easily parsed or ingested by log management systems. Defaults to `false`.\n\n<Info>\n  **Only Allowed in Self-Hosted Deployments**\n  The `MOUNT_PREFIX` environment variable is only allowed in Self-Hosted Deployment models, LangSmith SaaS will not allow this environment variable.\n</Info>\n\nSet `MOUNT_PREFIX` to serve the Agent Server under a specific path prefix. This is useful for deployments where the server is behind a reverse proxy or load balancer that requires a specific path prefix.\n\nFor example, if the server is to be served under `https://example.com/langgraph`, set `MOUNT_PREFIX` to `/langgraph`.\n\n## `N_JOBS_PER_WORKER`\n\nNumber of jobs per worker for the Agent Server task queue. Defaults to `10`.\n\n## `POSTGRES_URI_CUSTOM`\n\n<Info>\n  **Only for Hybrid and Self-Hosted**\n  Custom Postgres instances are only available for [Hybrid](/langsmith/hybrid) and [Self-Hosted](/langsmith/self-hosted) deployments.\n</Info>\n\nSpecify `POSTGRES_URI_CUSTOM` to use a custom Postgres instance. The value of `POSTGRES_URI_CUSTOM` must be a valid [Postgres connection URI](https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING-URIS).\n\n* Version 15.8 or higher.\n* An initial database must be present and the connection URI must reference the database.\n\nControl Plane Functionality:\n\n* If `POSTGRES_URI_CUSTOM` is specified, the control plane will not provision a database for the server.\n* If `POSTGRES_URI_CUSTOM` is removed, the control plane will not provision a database for the server and will not delete the externally managed Postgres instance.\n* If `POSTGRES_URI_CUSTOM` is removed, deployment of the revision will not succeed. Once `POSTGRES_URI_CUSTOM` is specified, it must always be set for the lifecycle of the deployment.\n* If the deployment is deleted, the control plane will not delete the externally managed Postgres instance.\n* The value of `POSTGRES_URI_CUSTOM` can be updated. For example, a password in the URI can be updated.\n\nDatabase Connectivity:\n\n* The custom Postgres instance must be accessible by the Agent Server. The user is responsible for ensuring connectivity.\n\n<Warning>\n  This feature is in Alpha.\n</Warning>\n\n<Info>\n  **Only Allowed in Self-Hosted Deployments**\n  Redis Cluster mode is only available in Self-Hosted Deployment models, LangSmith SaaS will provision a redis instance for you by default.\n</Info>\n\nSet `REDIS_CLUSTER` to `True` to enable Redis Cluster mode. When enabled, the system will connect to Redis using cluster mode. This is useful when connecting to a Redis Cluster deployment.\n\n## `REDIS_KEY_PREFIX`\n\n<Info>\n  **Available in API Server version 0.1.9+**\n  This environment variable is supported in API Server version 0.1.9 and above.\n</Info>\n\nSpecify a prefix for Redis keys. This allows multiple Agent Server instances to share the same Redis instance by using different key prefixes.\n\n## `REDIS_URI_CUSTOM`\n\n<Info>\n  **Only for Hybrid and Self-Hosted**\n  Custom Redis instances are only available for [Hybrid](/langsmith/hybrid) and [Self-Hosted](/langsmith/self-hosted) deployments.\n</Info>\n\nSpecify `REDIS_URI_CUSTOM` to use a custom Redis instance. The value of `REDIS_URI_CUSTOM` must be a valid [Redis connection URI](https://redis-py.readthedocs.io/en/stable/connections.html#redis.Redis.from_url).\n\n## `REDIS_MAX_CONNECTIONS`\n\nThe maximum size of the Redis connection pool (per replica) can be controlled using the `REDIS_MAX_CONNECTIONS` environment variable. By setting this variable, you can determine the upper bound on the number of simultaneous connections the server will establish with the Redis instance.\n\nFor example, if a deployment is scaled up to 10 replicas and `REDIS_MAX_CONNECTIONS` is configured to `150`, then up to `1500` connections to Redis can be established.\n\n## `RESUMABLE_STREAM_TTL_SECONDS`\n\nTime-to-live in seconds for resumable stream data in Redis.\n\nWhen a run is created and the output is streamed, the stream can be configured to be resumable (e.g. `stream_resumable=True`). If a stream is resumable, output from the stream is temporarily stored in Redis. The TTL for this data can be configured by setting `RESUMABLE_STREAM_TTL_SECONDS`.\n\nSee the [Python](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.client.RunsClient.stream) and [JS/TS](https://langchain-ai.github.io/langgraphjs/reference/classes/sdk_client.RunsClient.html#stream) SDKs for more details on how to implement resumable streams.\n\nDefaults to `120` seconds.\n\n<Note>\n  Setting a very high value for `RESUMABLE_STREAM_TTL_SECONDS` can result in substantial Redis memory usage when there are many concurrent runs with large or frequent streaming output. Set this value to the minimum value to enable recovery during network interruptions and prefer checkpointing for long term durability and execution snapshotting.\n</Note>\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/env-var.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "For example, to submit OpenTelemetry traces to [New Relic's US region](https://docs.newrelic.com/docs/opentelemetry/best-practices/opentelemetry-otlp/), set the following:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "`DD_API_KEY`",
      "id": "`dd_api_key`"
    },
    {
      "level": "h2",
      "text": "`LANGCHAIN_TRACING_SAMPLING_RATE`",
      "id": "`langchain_tracing_sampling_rate`"
    },
    {
      "level": "h2",
      "text": "`LANGGRAPH_AUTH_TYPE`",
      "id": "`langgraph_auth_type`"
    },
    {
      "level": "h2",
      "text": "`LANGGRAPH_POSTGRES_POOL_MAX_SIZE`",
      "id": "`langgraph_postgres_pool_max_size`"
    },
    {
      "level": "h2",
      "text": "`LANGSMITH_API_KEY`",
      "id": "`langsmith_api_key`"
    },
    {
      "level": "h2",
      "text": "`LANGSMITH_ENDPOINT`",
      "id": "`langsmith_endpoint`"
    },
    {
      "level": "h2",
      "text": "`LANGSMITH_TRACING`",
      "id": "`langsmith_tracing`"
    },
    {
      "level": "h2",
      "text": "`LOG_COLOR`",
      "id": "`log_color`"
    },
    {
      "level": "h2",
      "text": "`LOG_LEVEL`",
      "id": "`log_level`"
    },
    {
      "level": "h2",
      "text": "`LOG_JSON`",
      "id": "`log_json`"
    },
    {
      "level": "h2",
      "text": "`MOUNT_PREFIX`",
      "id": "`mount_prefix`"
    },
    {
      "level": "h2",
      "text": "`N_JOBS_PER_WORKER`",
      "id": "`n_jobs_per_worker`"
    },
    {
      "level": "h2",
      "text": "`POSTGRES_URI_CUSTOM`",
      "id": "`postgres_uri_custom`"
    },
    {
      "level": "h2",
      "text": "`REDIS_CLUSTER`",
      "id": "`redis_cluster`"
    },
    {
      "level": "h2",
      "text": "`REDIS_KEY_PREFIX`",
      "id": "`redis_key_prefix`"
    },
    {
      "level": "h2",
      "text": "`REDIS_URI_CUSTOM`",
      "id": "`redis_uri_custom`"
    },
    {
      "level": "h2",
      "text": "`REDIS_MAX_CONNECTIONS`",
      "id": "`redis_max_connections`"
    },
    {
      "level": "h2",
      "text": "`RESUMABLE_STREAM_TTL_SECONDS`",
      "id": "`resumable_stream_ttl_seconds`"
    }
  ],
  "url": "llms-txt#optional:-otel_python_logging_auto_instrumentation_enabled=true",
  "links": []
}