{
  "title": "Assistants",
  "content": "Source: https://docs.langchain.com/langsmith/assistants\n\n*Assistants* allow you to manage configurations (e.g., prompts, LLM selection, tools) separately from your graph's core logic. This enables you to create multiple, specialized versions of the same graph architecture with different behavior at runtime. Through configuration variations (rather than structural graph changes), each assistant is optimized for a different [use case](#when-to-use-assistants).\n\nFor example, imagine a general-purpose writing agent built on a common graph architecture. While the structure remains the same, different writing styles—such as blog posts and tweets—require tailored configurations to optimize performance. To support these variations, you can create multiple assistants (e.g., one for blogs and another for tweets) that share the underlying graph but differ in model selection and system prompt.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=05402316c8fe86fead077ec774e873f0\" alt=\"assistant versions\" data-og-width=\"1824\" width=\"1824\" data-og-height=\"692\" height=\"692\" data-path=\"langsmith/images/assistants.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?w=280&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=3ac250197ee8463950b74dc5f6bcd37f 280w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?w=560&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=d6b01c6ae96bd96b580bf43228610224 560w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?w=840&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=6125bf9aed49385ec8422e27cb377dad 840w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?w=1100&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=c54cde5d8a052ceac26d67131407aa73 1100w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?w=1650&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=780c08f1695bc2e5ba0b6261febb1954 1650w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/assistants.png?w=2500&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=ed8fba40ce7c1b3455027df735f9bdba 2500w\" />\n\nThe Agent Server API provides several endpoints for creating and managing assistants and their versions. See the [API reference](/langsmith/server-api-ref) for more details.\n\n<Info>\n  Assistants are a [LangSmith Deployment](/langsmith/deployments) concept. They are not available in the open source LangGraph library.\n</Info>\n\n## When to use assistants\n\nAssistants are ideal when you need to deploy the same graph architecture with different configurations. Common use cases include:\n\n* **User-level personalization**\n  * Customize model selection, system prompts, or tool availability per user.\n  * Store user preferences and apply them automatically to each interaction.\n  * Enable users to choose between different AI personalities or expertise levels.\n\n* **Customer or organization-specific configurations**\n  * Maintain separate configurations for different customers or organizations.\n  * Customize behavior for each client without deploying separate infrastructure.\n  * Isolate configuration changes to specific customers.\n\n* **Environment-specific configurations**\n  * Use different models or settings for development, staging, and production.\n  * Test configuration changes in staging before promoting to production.\n  * Reduce costs in non-production environments with smaller models.\n\n* **A/B testing and experimentation**\n  * Compare different prompts, models, or parameter settings.\n  * Roll out configuration changes gradually to a subset of users.\n  * Measure performance differences between configuration variants.\n\n* **Specialized task variants**\n  * Create domain-specific versions of a general-purpose agent.\n  * Optimize configurations for different languages, regions, or industries.\n  * Maintain consistent graph logic while varying the execution details.\n\n## How assistants work with deployments\n\nWhen you deploy a graph with LangSmith Deployment, [Agent Server](/langsmith/agent-server) automatically creates a **default assistant** tied to that graph's default configuration. You can then create additional assistants for the same graph, each with its own configuration.\n\nIf your deployment defines multiple graphs in [`langgraph.json`](/langmsith/application-structure#configuration-file), each graph gets its own default assistant:\n\nThat is, there can be multiple default assistants—one for each graph defined in your deployment.\n\nAssistants have several key features:\n\n* **[Managed via API and UI](/langsmith/configuration-cloud)**: Create, list, update, version, and get assistants using the Agent Server/LangGraph SDKs or the [LangSmith UI](https://smith.langchain.com).\n* **One graph, multiple assistants**: A single deployed graph can support multiple assistants, each with different configurations (e.g., prompts, models, tools).\n* **[Versioned](#versioning) configurations**: Each assistant maintains its own configuration history through versioning. Editing an assistant creates a new version, and you can promote or roll back to any version.\n* **[Configuration](#configuration) updates without graph changes**: Update prompts, model selection, and other settings through assistant configurations, enabling rapid iteration without modifying or redeploying your graph code.\n\n<Note>\n  When invoking an assistant, you can specify either in [`langgraph.json`](/langsmith/application-structure#configuration-file):\n\n* A **graph ID** (e.g., `\"agent\"`): Uses the default assistant for that graph\n  * An **assistant ID** (UUID): Uses a specific assistant configuration\n\nThis flexibility allows you to quickly test with default settings or precisely control which configuration is used.\n</Note>\n\nAssistants build on the LangGraph open source concept of [configuration](/oss/python/langgraph/graph-api#runtime-context).\n\nWhile configuration is available in the open source LangGraph library, assistants are only present in [LangSmith Deployment](/langsmith/deployments) because they are tightly coupled to your deployed graph. Upon deployment, [Agent Server](/langsmith/agent-server) will automatically create a default assistant for each graph using the graph's default configuration settings.\n\nIn practice, an assistant is just an *instance* of a graph with a specific configuration. Therefore, multiple assistants can reference the same graph but can contain different configurations (e.g. prompts, models, tools). The LangSmith Deployment API provides several endpoints for creating and managing assistants. See the [API reference](/langsmith/server-api-ref) and [this how-to](/langsmith/configuration-cloud) for more details on how to create assistants.\n\nAssistants support versioning to track changes over time. Once you've created an assistant, subsequent edits will automatically create new versions.\n\n* Each update creates a new version of the assistant.\n* You can promote any version to be the active version.\n* Rolling back to a previous version is as simple as setting it as active.\n* All versions remain available for reference and rollback.\n\n<Warning>\n  When updating an assistant, you must provide the entire configuration payload. The update endpoint creates new versions from scratch and does not merge with previous versions. Make sure to include all configuration fields you want to retain.\n</Warning>\n\nFor more details on how to manage assistant versions, refer to the [Manage assistants guide](/langsmith/configuration-cloud#create-a-new-version-for-your-assistant).\n\nA *run* is an invocation of an assistant. When you execute a run, you specify which assistant to use (either by graph ID for the default assistant or by assistant ID for a specific configuration).\n\nThis diagram shows how a **run** combines an assistant with a thread to execute the graph:\n\n* **Graph** (blue): The deployed code containing your agent's logic\n* **Assistants** (light blue): Configuration options (model, prompts, tools)\n* **Threads** (orange): State containers for conversation history\n* **Runs** (green): Executions that pair an assistant + thread\n\n**Example combinations:**\n\n* **Run: A1 + T1**: Assistant 1 configuration applied to User A's conversation\n* **Run: A1 + T2**: Same assistant serving User B (different conversation)\n* **Run: A2 + T1**: Different assistant applied to User A's conversation (configuration switch)\n\nWhen executing a run:\n\n* Each run may have its own input, configuration overrides, and metadata.\n* Runs can be stateless (no thread) or stateful (executed on a [thread](/oss/python/langgraph/persistence#threads) for conversation persistence).\n* Multiple runs can use the same assistant configuration.\n* The assistant's configuration affects how the underlying graph executes.\n\nThe Agent Server API provides several endpoints for creating and managing runs. For more details, refer to the [API reference](/langsmith/server-api-ref)).\n\n<iframe className=\"w-full aspect-video rounded-xl\" src=\"https://www.youtube.com/embed/fMsQX6pwXkE?si=6Q28l0taGOynO7sU\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen />\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/assistants.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "* **Environment-specific configurations**\n  * Use different models or settings for development, staging, and production.\n  * Test configuration changes in staging before promoting to production.\n  * Reduce costs in non-production environments with smaller models.\n\n* **A/B testing and experimentation**\n  * Compare different prompts, models, or parameter settings.\n  * Roll out configuration changes gradually to a subset of users.\n  * Measure performance differences between configuration variants.\n\n* **Specialized task variants**\n  * Create domain-specific versions of a general-purpose agent.\n  * Optimize configurations for different languages, regions, or industries.\n  * Maintain consistent graph logic while varying the execution details.",
      "language": "unknown"
    },
    {
      "code": "## How assistants work with deployments\n\nWhen you deploy a graph with LangSmith Deployment, [Agent Server](/langsmith/agent-server) automatically creates a **default assistant** tied to that graph's default configuration. You can then create additional assistants for the same graph, each with its own configuration.\n\nIf your deployment defines multiple graphs in [`langgraph.json`](/langmsith/application-structure#configuration-file), each graph gets its own default assistant:",
      "language": "unknown"
    },
    {
      "code": "That is, there can be multiple default assistants—one for each graph defined in your deployment.\n\nAssistants have several key features:\n\n* **[Managed via API and UI](/langsmith/configuration-cloud)**: Create, list, update, version, and get assistants using the Agent Server/LangGraph SDKs or the [LangSmith UI](https://smith.langchain.com).\n* **One graph, multiple assistants**: A single deployed graph can support multiple assistants, each with different configurations (e.g., prompts, models, tools).\n* **[Versioned](#versioning) configurations**: Each assistant maintains its own configuration history through versioning. Editing an assistant creates a new version, and you can promote or roll back to any version.\n* **[Configuration](#configuration) updates without graph changes**: Update prompts, model selection, and other settings through assistant configurations, enabling rapid iteration without modifying or redeploying your graph code.\n\n<Note>\n  When invoking an assistant, you can specify either in [`langgraph.json`](/langsmith/application-structure#configuration-file):\n\n  * A **graph ID** (e.g., `\"agent\"`): Uses the default assistant for that graph\n  * An **assistant ID** (UUID): Uses a specific assistant configuration\n\n  This flexibility allows you to quickly test with default settings or precisely control which configuration is used.\n</Note>\n\n### Configuration\n\nAssistants build on the LangGraph open source concept of [configuration](/oss/python/langgraph/graph-api#runtime-context).\n\nWhile configuration is available in the open source LangGraph library, assistants are only present in [LangSmith Deployment](/langsmith/deployments) because they are tightly coupled to your deployed graph. Upon deployment, [Agent Server](/langsmith/agent-server) will automatically create a default assistant for each graph using the graph's default configuration settings.\n\nIn practice, an assistant is just an *instance* of a graph with a specific configuration. Therefore, multiple assistants can reference the same graph but can contain different configurations (e.g. prompts, models, tools). The LangSmith Deployment API provides several endpoints for creating and managing assistants. See the [API reference](/langsmith/server-api-ref) and [this how-to](/langsmith/configuration-cloud) for more details on how to create assistants.\n\n### Versioning\n\nAssistants support versioning to track changes over time. Once you've created an assistant, subsequent edits will automatically create new versions.\n\n* Each update creates a new version of the assistant.\n* You can promote any version to be the active version.\n* Rolling back to a previous version is as simple as setting it as active.\n* All versions remain available for reference and rollback.\n\n<Warning>\n  When updating an assistant, you must provide the entire configuration payload. The update endpoint creates new versions from scratch and does not merge with previous versions. Make sure to include all configuration fields you want to retain.\n</Warning>\n\nFor more details on how to manage assistant versions, refer to the [Manage assistants guide](/langsmith/configuration-cloud#create-a-new-version-for-your-assistant).\n\n### Execution\n\nA *run* is an invocation of an assistant. When you execute a run, you specify which assistant to use (either by graph ID for the default assistant or by assistant ID for a specific configuration).",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "When to use assistants",
      "id": "when-to-use-assistants"
    },
    {
      "level": "h2",
      "text": "How assistants work with deployments",
      "id": "how-assistants-work-with-deployments"
    },
    {
      "level": "h3",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h3",
      "text": "Versioning",
      "id": "versioning"
    },
    {
      "level": "h3",
      "text": "Execution",
      "id": "execution"
    },
    {
      "level": "h2",
      "text": "Video guide",
      "id": "video-guide"
    }
  ],
  "url": "llms-txt#assistants",
  "links": []
}