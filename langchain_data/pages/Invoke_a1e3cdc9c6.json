{
  "title": "Invoke",
  "content": "state = orchestrator_worker.invoke({\"topic\": \"Create a report on LLM scaling laws\"})\n\nfrom IPython.display import Markdown\nMarkdown(state[\"final_report\"])\npython Graph API theme={null}\n  # Graph state\n  class State(TypedDict):\n      joke: str\n      topic: str\n      feedback: str\n      funny_or_not: str\n\n# Schema for structured output to use in evaluation\n  class Feedback(BaseModel):\n      grade: Literal[\"funny\", \"not funny\"] = Field(\n          description=\"Decide if the joke is funny or not.\",\n      )\n      feedback: str = Field(\n          description=\"If the joke is not funny, provide feedback on how to improve it.\",\n      )\n\n# Augment the LLM with schema for structured output\n  evaluator = llm.with_structured_output(Feedback)\n\n# Nodes\n  def llm_call_generator(state: State):\n      \"\"\"LLM generates a joke\"\"\"\n\nif state.get(\"feedback\"):\n          msg = llm.invoke(\n              f\"Write a joke about {state['topic']} but take into account the feedback: {state['feedback']}\"\n          )\n      else:\n          msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n      return {\"joke\": msg.content}\n\ndef llm_call_evaluator(state: State):\n      \"\"\"LLM evaluates the joke\"\"\"\n\ngrade = evaluator.invoke(f\"Grade the joke {state['joke']}\")\n      return {\"funny_or_not\": grade.grade, \"feedback\": grade.feedback}\n\n# Conditional edge function to route back to joke generator or end based upon feedback from the evaluator\n  def route_joke(state: State):\n      \"\"\"Route back to joke generator or end based upon feedback from the evaluator\"\"\"\n\nif state[\"funny_or_not\"] == \"funny\":\n          return \"Accepted\"\n      elif state[\"funny_or_not\"] == \"not funny\":\n          return \"Rejected + Feedback\"\n\n# Build workflow\n  optimizer_builder = StateGraph(State)\n\n# Add the nodes\n  optimizer_builder.add_node(\"llm_call_generator\", llm_call_generator)\n  optimizer_builder.add_node(\"llm_call_evaluator\", llm_call_evaluator)\n\n# Add edges to connect nodes\n  optimizer_builder.add_edge(START, \"llm_call_generator\")\n  optimizer_builder.add_edge(\"llm_call_generator\", \"llm_call_evaluator\")\n  optimizer_builder.add_conditional_edges(\n      \"llm_call_evaluator\",\n      route_joke,\n      {  # Name returned by route_joke : Name of next node to visit\n          \"Accepted\": END,\n          \"Rejected + Feedback\": \"llm_call_generator\",\n      },\n  )\n\n# Compile the workflow\n  optimizer_workflow = optimizer_builder.compile()\n\n# Show the workflow\n  display(Image(optimizer_workflow.get_graph().draw_mermaid_png()))\n\n# Invoke\n  state = optimizer_workflow.invoke({\"topic\": \"Cats\"})\n  print(state[\"joke\"])\n  python Functional API theme={null}\n  # Schema for structured output to use in evaluation\n  class Feedback(BaseModel):\n      grade: Literal[\"funny\", \"not funny\"] = Field(\n          description=\"Decide if the joke is funny or not.\",\n      )\n      feedback: str = Field(\n          description=\"If the joke is not funny, provide feedback on how to improve it.\",\n      )\n\n# Augment the LLM with schema for structured output\n  evaluator = llm.with_structured_output(Feedback)\n\n# Nodes\n  @task\n  def llm_call_generator(topic: str, feedback: Feedback):\n      \"\"\"LLM generates a joke\"\"\"\n      if feedback:\n          msg = llm.invoke(\n              f\"Write a joke about {topic} but take into account the feedback: {feedback}\"\n          )\n      else:\n          msg = llm.invoke(f\"Write a joke about {topic}\")\n      return msg.content\n\n@task\n  def llm_call_evaluator(joke: str):\n      \"\"\"LLM evaluates the joke\"\"\"\n      feedback = evaluator.invoke(f\"Grade the joke {joke}\")\n      return feedback\n\n@entrypoint()\n  def optimizer_workflow(topic: str):\n      feedback = None\n      while True:\n          joke = llm_call_generator(topic, feedback).result()\n          feedback = llm_call_evaluator(joke).result()\n          if feedback.grade == \"funny\":\n              break\n\n# Invoke\n  for step in optimizer_workflow.stream(\"Cats\", stream_mode=\"updates\"):\n      print(step)\n      print(\"\\n\")\n  python Using tools theme={null}\nfrom langchain.tools import tool",
  "code_samples": [
    {
      "code": "## Evaluator-optimizer\n\nIn evaluator-optimizer workflows, one LLM call creates a response and the other evaluates that response. If the evaluator or a [human-in-the-loop](/oss/python/langgraph/interrupts) determines the response needs refinement, feedback is provided and the response is recreated. This loop continues until an acceptable response is generated.\n\nEvaluator-optimizer workflows are commonly used when there's particular success criteria for a task, but iteration is required to meet that criteria. For example, there's not always a perfect match when translating text between two languages. It might take a few iterations to generate a translation with the same meaning across the two languages.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=9bd0474f42b6040b14ed6968a9ab4e3c\" alt=\"evaluator_optimizer.png\" data-og-width=\"1004\" width=\"1004\" data-og-height=\"340\" height=\"340\" data-path=\"oss/images/evaluator_optimizer.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?w=280&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=ab36856e5f9a518b22e71278aa8b1711 280w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?w=560&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=3ec597c92270278c2bac203d36b611c2 560w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?w=840&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=3ad3bfb734a0e509d9b87fdb4e808bfd 840w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?w=1100&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=e82bd25a463d3cdf76036649c03358a9 1100w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?w=1650&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=d31717ae3e76243dd975a53f46e8c1f6 1650w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/evaluator_optimizer.png?w=2500&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=a9bb4fb1583f6ad06c0b13602cd14811 2500w\" />\n\n<CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n## Agents\n\nAgents are typically implemented as an LLM performing actions using [tools](/oss/python/langchain/tools). They operate in continuous feedback loops, and are used in situations where problems and solutions are unpredictable. Agents have more autonomy than workflows, and can make decisions about the tools they use and how to solve problems. You can still define the available toolset and guidelines for how agents behave.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=bd8da41dbf8b5e6fc9ea6bb10cb63e38\" alt=\"agent.png\" data-og-width=\"1732\" width=\"1732\" data-og-height=\"712\" height=\"712\" data-path=\"oss/images/agent.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=280&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=f7a590604edc49cfa273b5856f3a3ee3 280w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=560&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=dff9b17d345fe0fea25616b3b0dc6ebf 560w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=840&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=bd932835b919f5e58be77221b6d0f194 840w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=1100&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=d53318b0c9c898a6146991691cbac058 1100w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=1650&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=ea66fb96bc07c595d321b8b71e651ddb 1650w, https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=2500&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=b02599a3c9ba2a5c830b9a346f9d26c9 2500w\" />\n\n<Note>\n  To get started with agents, see the [quickstart](/oss/python/langchain/quickstart) or read more about [how they work](/oss/python/langchain/agents) in LangChain.\n</Note>",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Evaluator-optimizer",
      "id": "evaluator-optimizer"
    },
    {
      "level": "h2",
      "text": "Agents",
      "id": "agents"
    }
  ],
  "url": "llms-txt#invoke",
  "links": []
}