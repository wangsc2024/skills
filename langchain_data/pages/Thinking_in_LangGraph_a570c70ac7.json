{
  "title": "Thinking in LangGraph",
  "content": "Source: https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph\n\nLearn how to think about building agents with LangGraph\n\nWhen you build an agent with LangGraph, you will first break it apart into discrete steps called **nodes**. Then, you will describe the different decisions and transitions from each of your nodes. Finally, you connect nodes together through a shared **state** that each node can read from and write to.\n\nIn this walkthrough, we'll guide you through the thought process of building a customer support email agent with LangGraph.\n\n## Start with the process you want to automate\n\nImagine that you need to build an AI agent that handles customer support emails. Your product team has given you these requirements:\n\nTo implement an agent in LangGraph, you will usually follow the same five steps.\n\n## Step 1: Map out your workflow as discrete steps\n\nStart by identifying the distinct steps in your process. Each step will become a **node** (a function that does one specific thing). Then, sketch how these steps connect to each other.\n\nThe arrows in this diagram show possible paths, but the actual decision of which path to take happens inside each node.\n\nNow that we've identified the components in our workflow, let's understand what each node needs to do:\n\n* `Read Email`: Extract and parse the email content\n* `Classify Intent`: Use an LLM to categorize urgency and topic, then route to appropriate action\n* `Doc Search`: Query your knowledge base for relevant information\n* `Bug Track`: Create or update issue in tracking system\n* `Draft Reply`: Generate an appropriate response\n* `Human Review`: Escalate to human agent for approval or handling\n* `Send Reply`: Dispatch the email response\n\n<Tip>\n  Notice that some nodes make decisions about where to go next (`Classify Intent`, `Draft Reply`, `Human Review`), while others always proceed to the same next step (`Read Email` always goes to `Classify Intent`, `Doc Search` always goes to `Draft Reply`).\n</Tip>\n\n## Step 2: Identify what each step needs to do\n\nFor each node in your graph, determine what type of operation it represents and what context it needs to work properly.\n\n<CardGroup cols={2}>\n  <Card title=\"LLM steps\" icon=\"brain\" href=\"#llm-steps\">\n    Use when you need to understand, analyze, generate text, or make reasoning decisions\n  </Card>\n\n<Card title=\"Data steps\" icon=\"database\" href=\"#data-steps\">\n    Use when you need to retrieve information from external sources\n  </Card>\n\n<Card title=\"Action steps\" icon=\"bolt\" href=\"#action-steps\">\n    Use when you need to perform external actions\n  </Card>\n\n<Card title=\"User input steps\" icon=\"user\" href=\"#user-input-steps\">\n    Use when you need human intervention\n  </Card>\n</CardGroup>\n\nWhen a step needs to understand, analyze, generate text, or make reasoning decisions:\n\n<AccordionGroup>\n  <Accordion title=\"Classify intent\">\n    * Static context (prompt): Classification categories, urgency definitions, response format\n    * Dynamic context (from state): Email content, sender information\n    * Desired outcome: Structured classification that determines routing\n  </Accordion>\n\n<Accordion title=\"Draft reply\">\n    * Static context (prompt): Tone guidelines, company policies, response templates\n    * Dynamic context (from state): Classification results, search results, customer history\n    * Desired outcome: Professional email response ready for review\n  </Accordion>\n</AccordionGroup>\n\nWhen a step needs to retrieve information from external sources:\n\n<AccordionGroup>\n  <Accordion title=\"Document search\">\n    * Parameters: Query built from intent and topic\n    * Retry strategy: Yes, with exponential backoff for transient failures\n    * Caching: Could cache common queries to reduce API calls\n  </Accordion>\n\n<Accordion title=\"Customer history lookup\">\n    * Parameters: Customer email or ID from state\n    * Retry strategy: Yes, but with fallback to basic info if unavailable\n    * Caching: Yes, with time-to-live to balance freshness and performance\n  </Accordion>\n</AccordionGroup>\n\nWhen a step needs to perform an external action:\n\n<AccordionGroup>\n  <Accordion title=\"Send reply\">\n    * When to execute node: After approval (human or automated)\n    * Retry strategy: Yes, with exponential backoff for network issues\n    * Should not cache: Each send is a unique action\n  </Accordion>\n\n<Accordion title=\"Bug track\">\n    * When to execute node: Always when intent is \"bug\"\n    * Retry strategy: Yes, critical to not lose bug reports\n    * Returns: Ticket ID to include in response\n  </Accordion>\n</AccordionGroup>\n\nWhen a step needs human intervention:\n\n<AccordionGroup>\n  <Accordion title=\"Human review node\">\n    * Context for decision: Original email, draft response, urgency, classification\n    * Expected input format: Approval boolean plus optional edited response\n    * When triggered: High urgency, complex issues, or quality concerns\n  </Accordion>\n</AccordionGroup>\n\n## Step 3: Design your state\n\nState is the shared [memory](/oss/python/concepts/memory) accessible to all nodes in your agent. Think of it as the notebook your agent uses to keep track of everything it learns and decides as it works through the process.\n\n### What belongs in state?\n\nAsk yourself these questions about each piece of data:\n\n<CardGroup cols={2}>\n  <Card title=\"Include in state\" icon=\"check\">\n    Does it need to persist across steps? If yes, it goes in state.\n  </Card>\n\n<Card title=\"Don't store\" icon=\"code\">\n    Can you derive it from other data? If yes, compute it when needed instead of storing it in state.\n  </Card>\n</CardGroup>\n\nFor our email agent, we need to track:\n\n* The original email and sender info (can't reconstruct these later)\n* Classification results (needed by multiple later/downstream nodes)\n* Search results and customer data (expensive to re-fetch)\n* The draft response (needs to persist through review)\n* Execution metadata (for debugging and recovery)\n\n### Keep state raw, format prompts on-demand\n\n<Tip>\n  A key principle: your state should store raw data, not formatted text. Format prompts inside nodes when you need them.\n</Tip>\n\nThis separation means:\n\n* Different nodes can format the same data differently for their needs\n* You can change prompt templates without modifying your state schema\n* Debugging is clearer – you see exactly what data each node received\n* Your agent can evolve without breaking existing state\n\nLet's define our state:\n\n```python  theme={null}\nfrom typing import TypedDict, Literal",
  "code_samples": [
    {
      "code": "To implement an agent in LangGraph, you will usually follow the same five steps.\n\n## Step 1: Map out your workflow as discrete steps\n\nStart by identifying the distinct steps in your process. Each step will become a **node** (a function that does one specific thing). Then, sketch how these steps connect to each other.",
      "language": "unknown"
    },
    {
      "code": "The arrows in this diagram show possible paths, but the actual decision of which path to take happens inside each node.\n\nNow that we've identified the components in our workflow, let's understand what each node needs to do:\n\n* `Read Email`: Extract and parse the email content\n* `Classify Intent`: Use an LLM to categorize urgency and topic, then route to appropriate action\n* `Doc Search`: Query your knowledge base for relevant information\n* `Bug Track`: Create or update issue in tracking system\n* `Draft Reply`: Generate an appropriate response\n* `Human Review`: Escalate to human agent for approval or handling\n* `Send Reply`: Dispatch the email response\n\n<Tip>\n  Notice that some nodes make decisions about where to go next (`Classify Intent`, `Draft Reply`, `Human Review`), while others always proceed to the same next step (`Read Email` always goes to `Classify Intent`, `Doc Search` always goes to `Draft Reply`).\n</Tip>\n\n## Step 2: Identify what each step needs to do\n\nFor each node in your graph, determine what type of operation it represents and what context it needs to work properly.\n\n<CardGroup cols={2}>\n  <Card title=\"LLM steps\" icon=\"brain\" href=\"#llm-steps\">\n    Use when you need to understand, analyze, generate text, or make reasoning decisions\n  </Card>\n\n  <Card title=\"Data steps\" icon=\"database\" href=\"#data-steps\">\n    Use when you need to retrieve information from external sources\n  </Card>\n\n  <Card title=\"Action steps\" icon=\"bolt\" href=\"#action-steps\">\n    Use when you need to perform external actions\n  </Card>\n\n  <Card title=\"User input steps\" icon=\"user\" href=\"#user-input-steps\">\n    Use when you need human intervention\n  </Card>\n</CardGroup>\n\n### LLM steps\n\nWhen a step needs to understand, analyze, generate text, or make reasoning decisions:\n\n<AccordionGroup>\n  <Accordion title=\"Classify intent\">\n    * Static context (prompt): Classification categories, urgency definitions, response format\n    * Dynamic context (from state): Email content, sender information\n    * Desired outcome: Structured classification that determines routing\n  </Accordion>\n\n  <Accordion title=\"Draft reply\">\n    * Static context (prompt): Tone guidelines, company policies, response templates\n    * Dynamic context (from state): Classification results, search results, customer history\n    * Desired outcome: Professional email response ready for review\n  </Accordion>\n</AccordionGroup>\n\n### Data steps\n\nWhen a step needs to retrieve information from external sources:\n\n<AccordionGroup>\n  <Accordion title=\"Document search\">\n    * Parameters: Query built from intent and topic\n    * Retry strategy: Yes, with exponential backoff for transient failures\n    * Caching: Could cache common queries to reduce API calls\n  </Accordion>\n\n  <Accordion title=\"Customer history lookup\">\n    * Parameters: Customer email or ID from state\n    * Retry strategy: Yes, but with fallback to basic info if unavailable\n    * Caching: Yes, with time-to-live to balance freshness and performance\n  </Accordion>\n</AccordionGroup>\n\n### Action steps\n\nWhen a step needs to perform an external action:\n\n<AccordionGroup>\n  <Accordion title=\"Send reply\">\n    * When to execute node: After approval (human or automated)\n    * Retry strategy: Yes, with exponential backoff for network issues\n    * Should not cache: Each send is a unique action\n  </Accordion>\n\n  <Accordion title=\"Bug track\">\n    * When to execute node: Always when intent is \"bug\"\n    * Retry strategy: Yes, critical to not lose bug reports\n    * Returns: Ticket ID to include in response\n  </Accordion>\n</AccordionGroup>\n\n### User input steps\n\nWhen a step needs human intervention:\n\n<AccordionGroup>\n  <Accordion title=\"Human review node\">\n    * Context for decision: Original email, draft response, urgency, classification\n    * Expected input format: Approval boolean plus optional edited response\n    * When triggered: High urgency, complex issues, or quality concerns\n  </Accordion>\n</AccordionGroup>\n\n## Step 3: Design your state\n\nState is the shared [memory](/oss/python/concepts/memory) accessible to all nodes in your agent. Think of it as the notebook your agent uses to keep track of everything it learns and decides as it works through the process.\n\n### What belongs in state?\n\nAsk yourself these questions about each piece of data:\n\n<CardGroup cols={2}>\n  <Card title=\"Include in state\" icon=\"check\">\n    Does it need to persist across steps? If yes, it goes in state.\n  </Card>\n\n  <Card title=\"Don't store\" icon=\"code\">\n    Can you derive it from other data? If yes, compute it when needed instead of storing it in state.\n  </Card>\n</CardGroup>\n\nFor our email agent, we need to track:\n\n* The original email and sender info (can't reconstruct these later)\n* Classification results (needed by multiple later/downstream nodes)\n* Search results and customer data (expensive to re-fetch)\n* The draft response (needs to persist through review)\n* Execution metadata (for debugging and recovery)\n\n### Keep state raw, format prompts on-demand\n\n<Tip>\n  A key principle: your state should store raw data, not formatted text. Format prompts inside nodes when you need them.\n</Tip>\n\nThis separation means:\n\n* Different nodes can format the same data differently for their needs\n* You can change prompt templates without modifying your state schema\n* Debugging is clearer – you see exactly what data each node received\n* Your agent can evolve without breaking existing state\n\nLet's define our state:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Start with the process you want to automate",
      "id": "start-with-the-process-you-want-to-automate"
    },
    {
      "level": "h2",
      "text": "Step 1: Map out your workflow as discrete steps",
      "id": "step-1:-map-out-your-workflow-as-discrete-steps"
    },
    {
      "level": "h2",
      "text": "Step 2: Identify what each step needs to do",
      "id": "step-2:-identify-what-each-step-needs-to-do"
    },
    {
      "level": "h3",
      "text": "LLM steps",
      "id": "llm-steps"
    },
    {
      "level": "h3",
      "text": "Data steps",
      "id": "data-steps"
    },
    {
      "level": "h3",
      "text": "Action steps",
      "id": "action-steps"
    },
    {
      "level": "h3",
      "text": "User input steps",
      "id": "user-input-steps"
    },
    {
      "level": "h2",
      "text": "Step 3: Design your state",
      "id": "step-3:-design-your-state"
    },
    {
      "level": "h3",
      "text": "What belongs in state?",
      "id": "what-belongs-in-state?"
    },
    {
      "level": "h3",
      "text": "Keep state raw, format prompts on-demand",
      "id": "keep-state-raw,-format-prompts-on-demand"
    }
  ],
  "url": "llms-txt#thinking-in-langgraph",
  "links": []
}