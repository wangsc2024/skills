{
  "title": "Agent Server",
  "content": "Source: https://docs.langchain.com/langsmith/agent-server\n\nLangSmith Deployment's **Agent Server** offers an API for creating and managing agent-based applications. It is built on the concept of [assistants](/langsmith/assistants), which are agents configured for specific tasks, and includes built-in [persistence](/oss/python/langgraph/persistence#memory-store) and a **task queue**. This versatile API supports a wide range of agentic application use cases, from background processing to real-time interactions.\n\nUse Agent Server to create and manage [assistants](/langsmith/assistants), [threads](/oss/python/langgraph/persistence#threads), [runs](/langsmith/assistants#execution), [cron jobs](/langsmith/cron-jobs), [webhooks](/langsmith/use-webhooks), and more.\n\n<Tip>\n  **API reference**<br />\n  For detailed information on the API endpoints and data models, refer to the [API reference docs](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html).\n</Tip>\n\nTo use the Enterprise version of the Agent Server, you must acquire a license key that you will need to specify when running the Docker image. To acquire a license key, [contact our sales team](https://www.langchain.com/contact-sales).\n\nYou can run the Enterprise version of the Agent Server on the following LangSmith [platform](/langsmith/platform-setup) options:\n\n* [Cloud](/langsmith/cloud)\n* [Hybrid](/langsmith/hybrid)\n* [Self-hosted](/langsmith/self-hosted)\n\n## Application structure\n\nTo deploy an Agent Server application, you need to specify the graph(s) you want to deploy, as well as any relevant configuration settings, such as dependencies and environment variables.\n\nRead the [application structure](/langsmith/application-structure) guide to learn how to structure your LangGraph application for deployment.\n\n## Parts of a deployment\n\nWhen you deploy Agent Server, you are deploying one or more [graphs](#graphs), a database for [persistence](/oss/python/langgraph/persistence), and a task queue.\n\nWhen you deploy a graph with Agent Server, you are deploying a \"blueprint\" for an [Assistant](/langsmith/assistants).\n\nAn [Assistant](/langsmith/assistants) is a graph paired with specific configuration settings. You can create multiple assistants per graph, each with unique settings to accommodate different use cases\nthat can be served by the same graph.\n\nUpon deployment, Agent Server will automatically create a default assistant for each graph using the graph's default configuration settings.\n\n<Note>\n  We often think of a graph as implementing an [agent](/oss/python/langgraph/workflows-agents), but a graph does not necessarily need to implement an agent. For example, a graph could implement a simple\n  chatbot that only supports back-and-forth conversation, without the ability to influence any application control flow. In reality, as applications get more complex, a graph will often implement a more complex flow that may use [multiple agents](/oss/python/langchain/multi-agent) working in tandem.\n</Note>\n\n### Persistence and task queue\n\nAgent Server leverages a database for [persistence](/oss/python/langgraph/persistence) and a task queue.\n\n[PostgreSQL](https://www.postgresql.org/) is supported as a database for Agent Server and [Redis](https://redis.io/) as the task queue.\n\nIf you're deploying using [LangSmith cloud](/langsmith/cloud), these components are managed for you. If you're deploying Agent Server on your [own infrastructure](/langsmith/self-hosted), you'll need to set up and manage these components yourself.\n\nFor more information on how these components are set up and managed, review the [hosting options](/langsmith/platform-setup) guide.\n\n* [Application Structure](/langsmith/application-structure) guide explains how to structure your application for deployment.\n* The [API Reference](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html) provides detailed information on the API endpoints and data models.\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-server.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Application structure",
      "id": "application-structure"
    },
    {
      "level": "h2",
      "text": "Parts of a deployment",
      "id": "parts-of-a-deployment"
    },
    {
      "level": "h3",
      "text": "Graphs",
      "id": "graphs"
    },
    {
      "level": "h3",
      "text": "Persistence and task queue",
      "id": "persistence-and-task-queue"
    },
    {
      "level": "h2",
      "text": "Learn more",
      "id": "learn-more"
    }
  ],
  "url": "llms-txt#agent-server",
  "links": []
}