{
  "title": "Agent will call go_back_to_warranty and restart the warranty verification step",
  "content": "python  theme={null}\n  \"\"\"\n  Customer Support State Machine Example\n\nThis example demonstrates the state machine pattern.\n  A single agent dynamically changes its behavior based on the current_step state,\n  creating a state machine for sequential information collection.\n  \"\"\"\n\nfrom langgraph.checkpoint.memory import InMemorySaver\n  from langgraph.types import Command\n  from typing import Callable, Literal\n  from typing_extensions import NotRequired\n\nfrom langchain.agents import AgentState, create_agent\n  from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse, SummarizationMiddleware\n  from langchain.chat_models import init_chat_model\n  from langchain.messages import HumanMessage, ToolMessage\n  from langchain.tools import tool, ToolRuntime\n\nmodel = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\n\n# Define the possible workflow steps\n  SupportStep = Literal[\"warranty_collector\", \"issue_classifier\", \"resolution_specialist\"]\n\nclass SupportState(AgentState):\n      \"\"\"State for customer support workflow.\"\"\"\n\ncurrent_step: NotRequired[SupportStep]\n      warranty_status: NotRequired[Literal[\"in_warranty\", \"out_of_warranty\"]]\n      issue_type: NotRequired[Literal[\"hardware\", \"software\"]]\n\n@tool\n  def record_warranty_status(\n      status: Literal[\"in_warranty\", \"out_of_warranty\"],\n      runtime: ToolRuntime[None, SupportState],\n  ) -> Command:\n      \"\"\"Record the customer's warranty status and transition to issue classification.\"\"\"\n      return Command(\n          update={\n              \"messages\": [\n                  ToolMessage(\n                      content=f\"Warranty status recorded as: {status}\",\n                      tool_call_id=runtime.tool_call_id,\n                  )\n              ],\n              \"warranty_status\": status,\n              \"current_step\": \"issue_classifier\",\n          }\n      )\n\n@tool\n  def record_issue_type(\n      issue_type: Literal[\"hardware\", \"software\"],\n      runtime: ToolRuntime[None, SupportState],\n  ) -> Command:\n      \"\"\"Record the type of issue and transition to resolution specialist.\"\"\"\n      return Command(\n          update={\n              \"messages\": [\n                  ToolMessage(\n                      content=f\"Issue type recorded as: {issue_type}\",\n                      tool_call_id=runtime.tool_call_id,\n                  )\n              ],\n              \"issue_type\": issue_type,\n              \"current_step\": \"resolution_specialist\",\n          }\n      )\n\n@tool\n  def escalate_to_human(reason: str) -> str:\n      \"\"\"Escalate the case to a human support specialist.\"\"\"\n      # In a real system, this would create a ticket, notify staff, etc.\n      return f\"Escalating to human support. Reason: {reason}\"\n\n@tool\n  def provide_solution(solution: str) -> str:\n      \"\"\"Provide a solution to the customer's issue.\"\"\"\n      return f\"Solution provided: {solution}\"\n\n# Define prompts as constants\n  WARRANTY_COLLECTOR_PROMPT = \"\"\"You are a customer support agent helping with device issues.\n\nCURRENT STEP: Warranty verification\n\nAt this step, you need to:\n  1. Greet the customer warmly\n  2. Ask if their device is under warranty\n  3. Use record_warranty_status to record their response and move to the next step\n\nBe conversational and friendly. Don't ask multiple questions at once.\"\"\"\n\nISSUE_CLASSIFIER_PROMPT = \"\"\"You are a customer support agent helping with device issues.\n\nCURRENT STEP: Issue classification\n  CUSTOMER INFO: Warranty status is {warranty_status}\n\nAt this step, you need to:\n  1. Ask the customer to describe their issue\n  2. Determine if it's a hardware issue (physical damage, broken parts) or software issue (app crashes, performance)\n  3. Use record_issue_type to record the classification and move to the next step\n\nIf unclear, ask clarifying questions before classifying.\"\"\"\n\nRESOLUTION_SPECIALIST_PROMPT = \"\"\"You are a customer support agent helping with device issues.\n\nCURRENT STEP: Resolution\n  CUSTOMER INFO: Warranty status is {warranty_status}, issue type is {issue_type}\n\nAt this step, you need to:\n  1. For SOFTWARE issues: provide troubleshooting steps using provide_solution\n  2. For HARDWARE issues:\n     - If IN WARRANTY: explain warranty repair process using provide_solution\n     - If OUT OF WARRANTY: escalate_to_human for paid repair options\n\nBe specific and helpful in your solutions.\"\"\"\n\n# Step configuration: maps step name to (prompt, tools, required_state)\n  STEP_CONFIG = {\n      \"warranty_collector\": {\n          \"prompt\": WARRANTY_COLLECTOR_PROMPT,\n          \"tools\": [record_warranty_status],\n          \"requires\": [],\n      },\n      \"issue_classifier\": {\n          \"prompt\": ISSUE_CLASSIFIER_PROMPT,\n          \"tools\": [record_issue_type],\n          \"requires\": [\"warranty_status\"],\n      },\n      \"resolution_specialist\": {\n          \"prompt\": RESOLUTION_SPECIALIST_PROMPT,\n          \"tools\": [provide_solution, escalate_to_human],\n          \"requires\": [\"warranty_status\", \"issue_type\"],\n      },\n  }\n\n@wrap_model_call\n  def apply_step_config(\n      request: ModelRequest,\n      handler: Callable[[ModelRequest], ModelResponse],\n  ) -> ModelResponse:\n      \"\"\"Configure agent behavior based on the current step.\"\"\"\n      # Get current step (defaults to warranty_collector for first interaction)\n      current_step = request.state.get(\"current_step\", \"warranty_collector\")\n\n# Look up step configuration\n      step_config = STEP_CONFIG[current_step]\n\n# Validate required state exists\n      for key in step_config[\"requires\"]:\n          if request.state.get(key) is None:\n              raise ValueError(f\"{key} must be set before reaching {current_step}\")\n\n# Format prompt with state values\n      system_prompt = step_config[\"prompt\"].format(**request.state)\n\n# Inject system prompt and step-specific tools\n      request = request.override(\n          system_prompt=system_prompt,\n          tools=step_config[\"tools\"],\n      )\n\nreturn handler(request)\n\n# Collect all tools from all step configurations\n  all_tools = [\n      record_warranty_status,\n      record_issue_type,\n      provide_solution,\n      escalate_to_human,\n  ]\n\n# Create the agent with step-based configuration and summarization\n  agent = create_agent(\n      model,\n      tools=all_tools,\n      state_schema=SupportState,\n      middleware=[\n          apply_step_config,\n          SummarizationMiddleware(\n              model=\"gpt-4o-mini\",\n              trigger=(\"tokens\", 4000),\n              keep=(\"messages\", 10)\n          )\n      ],\n      checkpointer=InMemorySaver(),\n  )\n\n# ============================================================================\n  # Test the workflow\n  # ============================================================================\n\nif __name__ == \"__main__\":\n      thread_id = str(uuid.uuid4())\n      config = {\"configurable\": {\"thread_id\": thread_id}}\n\nresult = agent.invoke(\n          {\"messages\": [HumanMessage(\"Hi, my phone screen is cracked\")]},\n          config\n      )\n\nresult = agent.invoke(\n          {\"messages\": [HumanMessage(\"Yes, it's still under warranty\")]},\n          config\n      )\n\nresult = agent.invoke(\n          {\"messages\": [HumanMessage(\"The screen is physically cracked from dropping it\")]},\n          config\n      )\n\nresult = agent.invoke(\n          {\"messages\": [HumanMessage(\"What should I do?\")]},\n          config\n      )\n      for msg in result['messages']:\n          msg.pretty_print()\n  ```\n</Expandable>\n\n* Learn about the [subagents pattern](/oss/python/langchain/multi-agent/subagents-personal-assistant) for centralized orchestration\n* Explore [middleware](/oss/python/langchain/middleware) for more dynamic behaviors\n* Read the [multi-agent overview](/oss/python/langchain/multi-agent) to compare patterns\n* Use [LangSmith](https://smith.langchain.com) to debug and monitor your multi-agent system\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/multi-agent/handoffs-customer-support.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "## Complete example\n\nHere's everything together in a runnable script:\n\n<Expandable title=\"Complete code\" defaultOpen={false}>",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Complete example",
      "id": "complete-example"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    }
  ],
  "url": "llms-txt#agent-will-call-go_back_to_warranty-and-restart-the-warranty-verification-step",
  "links": []
}