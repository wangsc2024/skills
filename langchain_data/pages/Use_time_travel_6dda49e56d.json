{
  "title": "Use time-travel",
  "content": "Source: https://docs.langchain.com/oss/python/langgraph/use-time-travel\n\nWhen working with non-deterministic systems that make model-based decisions (e.g., agents powered by LLMs), it can be useful to examine their decision-making process in detail:\n\n1. <Icon icon=\"lightbulb\" size={16} /> **Understand reasoning**: Analyze the steps that led to a successful result.\n2. <Icon icon=\"bug\" size={16} /> **Debug mistakes**: Identify where and why errors occurred.\n3. <Icon icon=\"magnifying-glass\" size={16} /> **Explore alternatives**: Test different paths to uncover better solutions.\n\nLangGraph provides [time travel](/oss/python/langgraph/use-time-travel) functionality to support these use cases. Specifically, you can resume execution from a prior checkpoint â€” either replaying the same state or modifying it to explore alternatives. In all cases, resuming past execution produces a new fork in the history.\n\nTo use [time-travel](/oss/python/langgraph/use-time-travel) in LangGraph:\n\n1. [Run the graph](#1-run-the-graph) with initial inputs using [`invoke`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.invoke) or [`stream`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.stream) methods.\n2. [Identify a checkpoint in an existing thread](#2-identify-a-checkpoint): Use the [`get_state_history`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.get_state_history) method to retrieve the execution history for a specific `thread_id` and locate the desired `checkpoint_id`.\n   Alternatively, set an [interrupt](/oss/python/langgraph/interrupts) before the node(s) where you want execution to pause. You can then find the most recent checkpoint recorded up to that interrupt.\n3. [Update the graph state (optional)](#3-update-the-state-optional): Use the [`update_state`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.update_state) method to modify the graph's state at the checkpoint and resume execution from alternative state.\n4. [Resume execution from the checkpoint](#4-resume-execution-from-the-checkpoint): Use the `invoke` or `stream` methods with an input of `None` and a configuration containing the appropriate `thread_id` and `checkpoint_id`.\n\n<Tip>\n  For a conceptual overview of time-travel, see [Time travel](/oss/python/langgraph/use-time-travel).\n</Tip>\n\nThis example builds a simple LangGraph workflow that generates a joke topic and writes a joke using an LLM. It demonstrates how to run the graph, retrieve past execution checkpoints, optionally modify the state, and resume execution from a chosen checkpoint to explore alternate outcomes.\n\nFirst we need to install the packages required\n\nNext, we need to set API keys for Anthropic (the LLM we will use)\n\n<Tip>\n  Sign up for [LangSmith](https://smith.langchain.com) to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph.\n</Tip>\n\n```python  theme={null}\nimport uuid\n\nfrom typing_extensions import TypedDict, NotRequired\nfrom langgraph.graph import StateGraph, START, END\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nclass State(TypedDict):\n    topic: NotRequired[str]\n    joke: NotRequired[str]\n\nmodel = init_chat_model(\n    \"claude-sonnet-4-5-20250929\",\n    temperature=0,\n)\n\ndef generate_topic(state: State):\n    \"\"\"LLM call to generate a topic for the joke\"\"\"\n    msg = model.invoke(\"Give me a funny topic for a joke\")\n    return {\"topic\": msg.content}\n\ndef write_joke(state: State):\n    \"\"\"LLM call to write a joke based on the topic\"\"\"\n    msg = model.invoke(f\"Write a short joke about {state['topic']}\")\n    return {\"joke\": msg.content}",
  "code_samples": [
    {
      "code": "Next, we need to set API keys for Anthropic (the LLM we will use)",
      "language": "unknown"
    },
    {
      "code": "<Tip>\n  Sign up for [LangSmith](https://smith.langchain.com) to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph.\n</Tip>",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "In a workflow",
      "id": "in-a-workflow"
    },
    {
      "level": "h3",
      "text": "Setup",
      "id": "setup"
    }
  ],
  "url": "llms-txt#use-time-travel",
  "links": []
}