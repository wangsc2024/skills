{
  "title": "Example: force a model to create a tool call",
  "content": "def call_get_schema(state: MessagesState):\n    # Note that LangChain enforces that all models accept `tool_choice=\"any\"`\n    # as well as `tool_choice=<string name of tool>`.\n    llm_with_tools = model.bind_tools([get_schema_tool], tool_choice=\"any\")\n    response = llm_with_tools.invoke(state[\"messages\"])\n\nreturn {\"messages\": [response]}\n\ngenerate_query_system_prompt = \"\"\"\nYou are an agent designed to interact with a SQL database.\nGiven an input question, create a syntactically correct {dialect} query to run,\nthen look at the results of the query and return the answer. Unless the user\nspecifies a specific number of examples they wish to obtain, always limit your\nquery to at most {top_k} results.\n\nYou can order the results by a relevant column to return the most interesting\nexamples in the database. Never query for all the columns from a specific table,\nonly ask for the relevant columns given the question.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n\"\"\".format(\n    dialect=db.dialect,\n    top_k=5,\n)\n\ndef generate_query(state: MessagesState):\n    system_message = {\n        \"role\": \"system\",\n        \"content\": generate_query_system_prompt,\n    }\n    # We do not force a tool call here, to allow the model to\n    # respond naturally when it obtains the solution.\n    llm_with_tools = model.bind_tools([run_query_tool])\n    response = llm_with_tools.invoke([system_message] + state[\"messages\"])\n\nreturn {\"messages\": [response]}\n\ncheck_query_system_prompt = \"\"\"\nYou are a SQL expert with a strong attention to detail.\nDouble check the {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes,\njust reproduce the original query.\n\nYou will call the appropriate tool to execute the query after running this check.\n\"\"\".format(dialect=db.dialect)\n\ndef check_query(state: MessagesState):\n    system_message = {\n        \"role\": \"system\",\n        \"content\": check_query_system_prompt,\n    }\n\n# Generate an artificial user message to check\n    tool_call = state[\"messages\"][-1].tool_calls[0]\n    user_message = {\"role\": \"user\", \"content\": tool_call[\"args\"][\"query\"]}\n    llm_with_tools = model.bind_tools([run_query_tool], tool_choice=\"any\")\n    response = llm_with_tools.invoke([system_message, user_message])\n    response.id = state[\"messages\"][-1].id\n\nreturn {\"messages\": [response]}\npython  theme={null}\ndef should_continue(state: MessagesState) -> Literal[END, \"check_query\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if not last_message.tool_calls:\n        return END\n    else:\n        return \"check_query\"\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(list_tables)\nbuilder.add_node(call_get_schema)\nbuilder.add_node(get_schema_node, \"get_schema\")\nbuilder.add_node(generate_query)\nbuilder.add_node(check_query)\nbuilder.add_node(run_query_node, \"run_query\")\n\nbuilder.add_edge(START, \"list_tables\")\nbuilder.add_edge(\"list_tables\", \"call_get_schema\")\nbuilder.add_edge(\"call_get_schema\", \"get_schema\")\nbuilder.add_edge(\"get_schema\", \"generate_query\")\nbuilder.add_conditional_edges(\n    \"generate_query\",\n    should_continue,\n)\nbuilder.add_edge(\"check_query\", \"run_query\")\nbuilder.add_edge(\"run_query\", \"generate_query\")\n\nagent = builder.compile()\npython  theme={null}\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\ndisplay(Image(agent.get_graph().draw_mermaid_png()))\npython  theme={null}\nquestion = \"Which genre on average has the longest tracks?\"\n\nfor step in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n    stream_mode=\"values\",\n):\n    step[\"messages\"][-1].pretty_print()\n\n================================ Human Message =================================\n\nWhich genre on average has the longest tracks?\n================================== Ai Message ==================================\n\nAvailable tables: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n================================== Ai Message ==================================\nTool Calls:\n  sql_db_schema (call_yzje0tj7JK3TEzDx4QnRR3lL)\n Call ID: call_yzje0tj7JK3TEzDx4QnRR3lL\n  Args:\n    table_names: Genre, Track\n================================= Tool Message =================================\nName: sql_db_schema\n\nCREATE TABLE \"Genre\" (\n\t\"GenreId\" INTEGER NOT NULL,\n\t\"Name\" NVARCHAR(120),\n\tPRIMARY KEY (\"GenreId\")\n)\n\n/*\n3 rows from Genre table:\nGenreId\tName\n1\tRock\n2\tJazz\n3\tMetal\n*/\n\nCREATE TABLE \"Track\" (\n\t\"TrackId\" INTEGER NOT NULL,\n\t\"Name\" NVARCHAR(200) NOT NULL,\n\t\"AlbumId\" INTEGER,\n\t\"MediaTypeId\" INTEGER NOT NULL,\n\t\"GenreId\" INTEGER,\n\t\"Composer\" NVARCHAR(220),\n\t\"Milliseconds\" INTEGER NOT NULL,\n\t\"Bytes\" INTEGER,\n\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL,\n\tPRIMARY KEY (\"TrackId\"),\n\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"),\n\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"),\n\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\n)\n\n/*\n3 rows from Track table:\nTrackId\tName\tAlbumId\tMediaTypeId\tGenreId\tComposer\tMilliseconds\tBytes\tUnitPrice\n1\tFor Those About To Rock (We Salute You)\t1\t1\t1\tAngus Young, Malcolm Young, Brian Johnson\t343719\t11170334\t0.99\n2\tBalls to the Wall\t2\t2\t1\tU. Dirkschneider, W. Hoffmann, H. Frank, P. Baltes, S. Kaufmann, G. Hoffmann\t342562\t5510424\t0.99\n3\tFast As a Shark\t3\t2\t1\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\t230619\t3990994\t0.99\n*/\n================================== Ai Message ==================================\nTool Calls:\n  sql_db_query (call_cb9ApLfZLSq7CWg6jd0im90b)\n Call ID: call_cb9ApLfZLSq7CWg6jd0im90b\n  Args:\n    query: SELECT Genre.Name, AVG(Track.Milliseconds) AS AvgMilliseconds FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId GROUP BY Genre.GenreId ORDER BY AvgMilliseconds DESC LIMIT 5;\n================================== Ai Message ==================================\nTool Calls:\n  sql_db_query (call_DMVALfnQ4kJsuF3Yl6jxbeAU)\n Call ID: call_DMVALfnQ4kJsuF3Yl6jxbeAU\n  Args:\n    query: SELECT Genre.Name, AVG(Track.Milliseconds) AS AvgMilliseconds FROM Track JOIN Genre ON Track.GenreId = Genre.GenreId GROUP BY Genre.GenreId ORDER BY AvgMilliseconds DESC LIMIT 5;\n================================= Tool Message =================================\nName: sql_db_query\n\n[('Sci Fi & Fantasy', 2911783.0384615385), ('Science Fiction', 2625549.076923077), ('Drama', 2575283.78125), ('TV Shows', 2145041.0215053763), ('Comedy', 1585263.705882353)]\n================================== Ai Message ==================================\n\nThe genre with the longest tracks on average is \"Sci Fi & Fantasy,\" with an average track length of approximately 2,911,783 milliseconds. Other genres with relatively long tracks include \"Science Fiction,\" \"Drama,\" \"TV Shows,\" and \"Comedy.\"\npython  theme={null}\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain.tools import tool\nfrom langgraph.types import interrupt\n\n@tool(\n    run_query_tool.name,\n    description=run_query_tool.description,\n    args_schema=run_query_tool.args_schema\n)\ndef run_query_tool_with_interrupt(config: RunnableConfig, **tool_input):\n    request = {\n        \"action\": run_query_tool.name,\n        \"args\": tool_input,\n        \"description\": \"Please review the tool call\"\n    }\n    response = interrupt([request]) # [!code highlight]\n    # approve the tool call\n    if response[\"type\"] == \"accept\":\n        tool_response = run_query_tool.invoke(tool_input, config)\n    # update tool call args\n    elif response[\"type\"] == \"edit\":\n        tool_input = response[\"args\"][\"args\"]\n        tool_response = run_query_tool.invoke(tool_input, config)\n    # respond to the LLM with user feedback\n    elif response[\"type\"] == \"response\":\n        user_feedback = response[\"args\"]\n        tool_response = user_feedback\n    else:\n        raise ValueError(f\"Unsupported interrupt response type: {response['type']}\")",
  "code_samples": [
    {
      "code": "## 5. Implement the agent\n\nWe can now assemble these steps into a workflow using the [Graph API](/oss/python/langgraph/graph-api). We define a [conditional edge](/oss/python/langgraph/graph-api#conditional-edges) at the query generation step that will route to the query checker if a query is generated, or end if there are no tool calls present, such that the LLM has delivered a response to the query.",
      "language": "unknown"
    },
    {
      "code": "We visualize the application below:",
      "language": "unknown"
    },
    {
      "code": "<img src=\"https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=1ddd4aae369fb8c143edaccb0a09c81f\" alt=\"SQL agent graph\" style={{ height: \"800px\" }} data-og-width=\"308\" width=\"308\" data-og-height=\"645\" height=\"645\" data-path=\"oss/images/sql-agent-langgraph.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?w=280&fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=e5d3e67f17d65e438370f7d771e3ba7d 280w, https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?w=560&fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=dbcb80fdb2d00a6dc33dc90f05d100b5 560w, https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?w=840&fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=72be69a1e7ac39afad3d0aa03ecffffa 840w, https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?w=1100&fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=5ad351b8b6641defe17882f5e102cab0 1100w, https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?w=1650&fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=8a5cefc8ac6938d0b4b0946e0522ffaa 1650w, https://mintcdn.com/langchain-5e9cc07a/aAi4RLdXQAh8fThS/oss/images/sql-agent-langgraph.png?w=2500&fit=max&auto=format&n=aAi4RLdXQAh8fThS&q=85&s=0b5b7711b4b2ece3a3ccb10a2b012166 2500w\" />\n\nWe can now invoke the graph:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "<Tip>\n  See [LangSmith trace](https://smith.langchain.com/public/94b8c9ac-12f7-4692-8706-836a1f30f1ea/r) for the above run.\n</Tip>\n\n## 6. Implement human-in-the-loop review\n\nIt can be prudent to check the agent's SQL queries before they are executed for any unintended actions or inefficiencies.\n\nHere we leverage LangGraph's [human-in-the-loop](/oss/python/langgraph/interrupts) features to pause the run before executing a SQL query and wait for human review. Using LangGraph's [persistence layer](/oss/python/langgraph/persistence), we can pause the run indefinitely (or at least as long as the persistence layer is alive).\n\nLet's wrap the `sql_db_query` tool in a node that receives human input. We can implement this using the [interrupt](/oss/python/langgraph/interrupts) function. Below, we allow for input to approve the tool call, edit its arguments, or provide user feedback.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "5. Implement the agent",
      "id": "5.-implement-the-agent"
    },
    {
      "level": "h2",
      "text": "6. Implement human-in-the-loop review",
      "id": "6.-implement-human-in-the-loop-review"
    }
  ],
  "url": "llms-txt#example:-force-a-model-to-create-a-tool-call",
  "links": []
}