{
  "title": "Agent harness capabilities",
  "content": "Source: https://docs.langchain.com/oss/python/deepagents/harness\n\nWe think of `deepagents` as an [\"agent harness\"](https://blog.langchain.com/agent-frameworks-runtimes-and-harnesses-oh-my/). It is the same core tool calling loop as other agent frameworks, but with built-in tools and capabilities.\n\nThis page lists out the components that make up the agent harness.\n\n## File system access\n\nThe harness provides six tools for file system operations, making files first-class citizens in the agent's environment:\n\n| Tool         | Description                                                                                   |\n| ------------ | --------------------------------------------------------------------------------------------- |\n| `ls`         | List files in a directory with metadata (size, modified time)                                 |\n| `read_file`  | Read file contents with line numbers, supports offset/limit for large files                   |\n| `write_file` | Create new files                                                                              |\n| `edit_file`  | Perform exact string replacements in files (with global replace mode)                         |\n| `glob`       | Find files matching patterns (e.g., `**/*.py`)                                                |\n| `grep`       | Search file contents with multiple output modes (files only, content with context, or counts) |\n\n## Large tool result eviction\n\nThe harness automatically dumps large tool results to the file system when they exceed a token threshold, preventing context window saturation.\n\n* Monitors tool call results for size (default threshold: 20,000 tokens)\n* When exceeded, writes the result to a file instead\n* Replaces the tool result with a concise reference to the file\n* Agent can later read the file if needed\n\n## Pluggable storage backends\n\nThe harness abstracts file system operations behind a protocol, allowing different storage strategies for different use cases.\n\n**Available backends:**\n\n1. **StateBackend** - Ephemeral in-memory storage\n   * Files live in the agent's state (checkpointed with conversation)\n   * Persists within a thread but not across threads\n   * Useful for temporary working files\n\n2. **FilesystemBackend** - Real filesystem access\n   * Read/write from actual disk\n   * Supports virtual mode (sandboxed to a root directory)\n   * Integrates with system tools (ripgrep for grep)\n   * Security features: path validation, size limits, symlink prevention\n\n3. **StoreBackend** - Persistent cross-conversation storage\n   * Uses LangGraph's BaseStore for durability\n   * Namespaced per assistant\\_id\n   * Files persist across conversations\n   * Useful for long-term memory or knowledge bases\n\n4. **CompositeBackend** - Route different paths to different backends\n   * Example: `/` → StateBackend, `/memories/` → StoreBackend\n   * Longest-prefix matching for routing\n   * Enables hybrid storage strategies\n\n## Task delegation (subagents)\n\nThe harness allows the main agent to create ephemeral \"subagents\" for isolated multi-step tasks.\n\n* **Context isolation** - Subagent's work doesn't clutter main agent's context\n* **Parallel execution** - Multiple subagents can run concurrently\n* **Specialization** - Subagents can have different tools/configurations\n* **Token efficiency** - Large subtask context is compressed into a single result\n\n* Main agent has a `task` tool\n* When invoked, creates a fresh agent instance with its own context\n* Subagent executes autonomously until completion\n* Returns a single final report to the main agent\n* Subagents are stateless (can't send multiple messages back)\n\n**Default subagent:**\n\n* \"general-purpose\" subagent automatically available\n* Has filesystem tools by default\n* Can be customized with additional tools/middleware\n\n**Custom subagents:**\n\n* Define specialized subagents with specific tools\n* Example: code-reviewer, web-researcher, test-runner\n* Configure via `subagents` parameter\n\n## Conversation history summarization\n\nThe harness automatically compresses old conversation history when token usage becomes excessive.\n\n* Triggers at 170,000 tokens\n* Keeps the most recent 6 messages intact\n* Older messages are summarized by the model\n\n* Enables very long conversations without hitting context limits\n* Preserves recent context while compressing ancient history\n* Transparent to the agent (appears as a special system message)\n\n## Dangling tool call repair\n\nThe harness fixes message history when tool calls are interrupted or cancelled before receiving results.\n\n* Agent requests tool call: \"Please run X\"\n* Tool call is interrupted (user cancels, error, etc.)\n* Agent sees tool\\_call in AIMessage but no corresponding ToolMessage\n* This creates an invalid message sequence\n\n* Detects AIMessages with tool\\_calls that have no results\n* Creates synthetic ToolMessage responses indicating the call was cancelled\n* Repairs the message history before agent execution\n\n* Prevents agent confusion from incomplete message chains\n* Gracefully handles interruptions and errors\n* Maintains conversation coherence\n\n## To-do list tracking\n\nThe harness provides a `write_todos` tool that agents can use to maintain a structured task list.\n\n* Track multiple tasks with statuses (pending, in\\_progress, completed)\n* Persisted in agent state\n* Helps agent organize complex multi-step work\n* Useful for long-running tasks and planning\n\nThe harness pauses agent execution at specified tool calls to allow human approval/modification.\n\n* Map tool names to interrupt configurations\n* Example: `{\"edit_file\": True}` - pause before every edit\n* Can provide approval messages or modify tool inputs\n\n* Safety gates for destructive operations\n* User verification before expensive API calls\n* Interactive debugging and guidance\n\n## Prompt caching (Anthropic)\n\nThe harness enables Anthropic's prompt caching feature to reduce redundant token processing.\n\n* Caches portions of the prompt that repeat across turns\n* Significantly reduces latency and cost for long system prompts\n* Automatically skips for non-Anthropic models\n\n* System prompts (especially with filesystem docs) can be 5k+ tokens\n* These repeat every turn without caching\n* Caching provides \\~10x speedup and cost reduction\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/deepagents/harness.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "File system access",
      "id": "file-system-access"
    },
    {
      "level": "h2",
      "text": "Large tool result eviction",
      "id": "large-tool-result-eviction"
    },
    {
      "level": "h2",
      "text": "Pluggable storage backends",
      "id": "pluggable-storage-backends"
    },
    {
      "level": "h2",
      "text": "Task delegation (subagents)",
      "id": "task-delegation-(subagents)"
    },
    {
      "level": "h2",
      "text": "Conversation history summarization",
      "id": "conversation-history-summarization"
    },
    {
      "level": "h2",
      "text": "Dangling tool call repair",
      "id": "dangling-tool-call-repair"
    },
    {
      "level": "h2",
      "text": "To-do list tracking",
      "id": "to-do-list-tracking"
    },
    {
      "level": "h2",
      "text": "Human-in-the-Loop",
      "id": "human-in-the-loop"
    },
    {
      "level": "h2",
      "text": "Prompt caching (Anthropic)",
      "id": "prompt-caching-(anthropic)"
    }
  ],
  "url": "llms-txt#agent-harness-capabilities",
  "links": []
}