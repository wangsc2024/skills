{
  "title": "Custom state can be passed in invoke",
  "content": "result = agent.invoke(\n    {\n        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n        \"user_id\": \"user_123\",  # [!code highlight]\n        \"preferences\": {\"theme\": \"dark\"}  # [!code highlight]\n    },\n    {\"configurable\": {\"thread_id\": \"1\"}})\npython  theme={null}\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import before_model\nfrom langgraph.runtime import Runtime\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Any\n\n@before_model\ndef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n    messages = state[\"messages\"]\n\nif len(messages) <= 3:\n        return None  # No changes needed\n\nfirst_msg = messages[0]\n    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n    new_messages = [first_msg] + recent_messages\n\nreturn {\n        \"messages\": [\n            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n            *new_messages\n        ]\n    }\n\nagent = create_agent(\n    your_model_here,\n    tools=your_tools_here,\n    middleware=[trim_messages],\n    checkpointer=InMemorySaver(),\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nagent.invoke({\"messages\": \"hi, my name is bob\"}, config)\nagent.invoke({\"messages\": \"write a short poem about cats\"}, config)\nagent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n\"\"\"\n================================== Ai Message ==================================\n\nYour name is Bob. You told me that earlier.\nIf you'd like me to call you a nickname or use a different name, just say the word.\n\"\"\"\npython  theme={null}\nfrom langchain.messages import RemoveMessage  # [!code highlight]\n\ndef delete_messages(state):\n    messages = state[\"messages\"]\n    if len(messages) > 2:\n        # remove the earliest two messages\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}  # [!code highlight]\npython  theme={null}\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES  # [!code highlight]\n\ndef delete_messages(state):\n    return {\"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  # [!code highlight]\npython  theme={null}\nfrom langchain.messages import RemoveMessage\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.agents.middleware import after_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.runtime import Runtime\nfrom langchain_core.runnables import RunnableConfig\n\n@after_model\ndef delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n    messages = state[\"messages\"]\n    if len(messages) > 2:\n        # remove the earliest two messages\n        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n    return None\n\nagent = create_agent(\n    \"gpt-5-nano\",\n    tools=[],\n    system_prompt=\"Please be concise and to the point.\",\n    middleware=[delete_old_messages],\n    checkpointer=InMemorySaver(),\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n\nfor event in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n    config,\n    stream_mode=\"values\",\n):\n    print([(message.type, message.content) for message in event[\"messages\"]])\n\nfor event in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n    config,\n    stream_mode=\"values\",\n):\n    print([(message.type, message.content) for message in event[\"messages\"]])\n\n[('human', \"hi! I'm bob\")]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.')]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.'), ('human', \"what's my name?\")]\n[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob. How can I help you today, Bob?')]\n[('human', \"what's my name?\"), ('ai', 'Your name is Bob. How can I help you today, Bob?')]\npython  theme={null}\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import SummarizationMiddleware\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain_core.runnables import RunnableConfig\n\ncheckpointer = InMemorySaver()\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[],\n    middleware=[\n        SummarizationMiddleware(\n            model=\"gpt-4o-mini\",\n            trigger=(\"tokens\", 4000),\n            keep=(\"messages\", 20)\n        )\n    ],\n    checkpointer=checkpointer,\n)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\nagent.invoke({\"messages\": \"hi, my name is bob\"}, config)\nagent.invoke({\"messages\": \"write a short poem about cats\"}, config)\nagent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\nfinal_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n\nfinal_response[\"messages\"][-1].pretty_print()\n\"\"\"\n================================== Ai Message ==================================\n\nYour name is Bob!\n\"\"\"\npython  theme={null}\nfrom langchain.agents import create_agent, AgentState\nfrom langchain.tools import tool, ToolRuntime\n\nclass CustomState(AgentState):\n    user_id: str\n\n@tool\ndef get_user_info(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Look up user info.\"\"\"\n    user_id = runtime.state[\"user_id\"]\n    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n\nagent = create_agent(\n    model=\"gpt-5-nano\",\n    tools=[get_user_info],\n    state_schema=CustomState,\n)\n\nresult = agent.invoke({\n    \"messages\": \"look up user information\",\n    \"user_id\": \"user_123\"\n})\nprint(result[\"messages\"][-1].content)",
  "code_samples": [
    {
      "code": "## Common patterns\n\nWith [short-term memory](#add-short-term-memory) enabled, long conversations can exceed the LLM's context window. Common solutions are:\n\n<CardGroup cols={2}>\n  <Card title=\"Trim messages\" icon=\"scissors\" href=\"#trim-messages\" arrow>\n    Remove first or last N messages (before calling LLM)\n  </Card>\n\n  <Card title=\"Delete messages\" icon=\"trash\" href=\"#delete-messages\" arrow>\n    Delete messages from LangGraph state permanently\n  </Card>\n\n  <Card title=\"Summarize messages\" icon=\"layer-group\" href=\"#summarize-messages\" arrow>\n    Summarize earlier messages in the history and replace them with a summary\n  </Card>\n\n  <Card title=\"Custom strategies\" icon=\"gears\">\n    Custom strategies (e.g., message filtering, etc.)\n  </Card>\n</CardGroup>\n\nThis allows the agent to keep track of the conversation without exceeding the LLM's context window.\n\n### Trim messages\n\nMost LLMs have a maximum supported context window (denominated in tokens).\n\nOne way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you're using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the `strategy` (e.g., keep the last `max_tokens`) to use for handling the boundary.\n\nTo trim message history in an agent, use the [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware decorator:",
      "language": "unknown"
    },
    {
      "code": "### Delete messages\n\nYou can delete messages from the graph state to manage the message history.\n\nThis is useful when you want to remove specific messages or clear the entire message history.\n\nTo delete messages from the graph state, you can use the `RemoveMessage`.\n\nFor `RemoveMessage` to work, you need to use a state key with [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) [reducer](/oss/python/langgraph/graph-api#reducers).\n\nThe default [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) provides this.\n\nTo remove specific messages:",
      "language": "unknown"
    },
    {
      "code": "To remove **all** messages:",
      "language": "unknown"
    },
    {
      "code": "<Warning>\n  When deleting messages, **make sure** that the resulting message history is valid. Check the limitations of the LLM provider you're using. For example:\n\n  * Some providers expect message history to start with a `user` message\n  * Most providers require `assistant` messages with tool calls to be followed by corresponding `tool` result messages.\n</Warning>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Summarize messages\n\nThe problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue.\nBecause of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=c8ed3facdccd4ef5c7e52902c72ba938\" alt=\"Summary\" data-og-width=\"609\" width=\"609\" data-og-height=\"242\" height=\"242\" data-path=\"oss/images/summary.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?w=280&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=4208b9b0cc9f459f3dc4e5219918471b 280w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?w=560&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=7acb77c081545f57042368f4e9d0c8cb 560w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?w=840&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=2fcfdb0c481d2e1d361e76db763a41e5 840w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?w=1100&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=4abdac693a562788aa0db8681bef8ea7 1100w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?w=1650&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=40acfefa91dcb11b247a6e4a7705f22b 1650w, https://mintcdn.com/langchain-5e9cc07a/ybiAaBfoBvFquMDz/oss/images/summary.png?w=2500&fit=max&auto=format&n=ybiAaBfoBvFquMDz&q=85&s=8d765aaf7551e8b0fc2720de7d2ac2a8 2500w\" />\n\nTo summarize message history in an agent, use the built-in [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization):",
      "language": "unknown"
    },
    {
      "code": "See [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization) for more configuration options.\n\n## Access memory\n\nYou can access and modify the short-term memory (state) of an agent in several ways:\n\n### Tools\n\n#### Read short-term memory in a tool\n\nAccess short term memory (state) in a tool using the `ToolRuntime` parameter.\n\nThe `tool_runtime` parameter is hidden from the tool signature (so the model doesn't see it), but the tool can access the state through it.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Common patterns",
      "id": "common-patterns"
    },
    {
      "level": "h3",
      "text": "Trim messages",
      "id": "trim-messages"
    },
    {
      "level": "h3",
      "text": "Delete messages",
      "id": "delete-messages"
    },
    {
      "level": "h3",
      "text": "Summarize messages",
      "id": "summarize-messages"
    },
    {
      "level": "h2",
      "text": "Access memory",
      "id": "access-memory"
    },
    {
      "level": "h3",
      "text": "Tools",
      "id": "tools"
    }
  ],
  "url": "llms-txt#custom-state-can-be-passed-in-invoke",
  "links": []
}