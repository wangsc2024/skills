{
  "title": "Continue conversation",
  "content": "messages = [\n    HumanMessage(\"What's the weather in San Francisco?\"),\n    ai_message,  # Model's tool call\n    tool_message,  # Tool execution result\n]\nresponse = model.invoke(messages)  # Model processes the result\npython  theme={null}\n    from langchain.messages import ToolMessage\n\n# Sent to model\n    message_content = \"It was the best of times, it was the worst of times.\"\n\n# Artifact available downstream\n    artifact = {\"document_id\": \"doc_123\", \"page\": 0}\n\ntool_message = ToolMessage(\n        content=message_content,\n        tool_call_id=\"call_123\",\n        name=\"search_books\",\n        artifact=artifact,\n    )\n    python  theme={null}\nfrom langchain.messages import HumanMessage",
  "code_samples": [
    {
      "code": "<Accordion title=\"Attributes\">\n  <ParamField path=\"content\" type=\"string\" required>\n    The stringified output of the tool call.\n  </ParamField>\n\n  <ParamField path=\"tool_call_id\" type=\"string\" required>\n    The ID of the tool call that this message is responding to. Must match the ID of the tool call in the [`AIMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.AIMessage).\n  </ParamField>\n\n  <ParamField path=\"name\" type=\"string\" required>\n    The name of the tool that was called.\n  </ParamField>\n\n  <ParamField path=\"artifact\" type=\"dict\">\n    Additional data not sent to the model but can be accessed programmatically.\n  </ParamField>\n</Accordion>\n\n<Note>\n  The `artifact` field stores supplementary data that won't be sent to the model but can be accessed programmatically. This is useful for storing raw results, debugging information, or data for downstream processing without cluttering the model's context.\n\n  <Accordion title=\"Example: Using artifact for retrieval metadata\">\n    For example, a [retrieval](/oss/python/langchain/retrieval) tool could retrieve a passage from a document for reference by a model. Where message `content` contains text that the model will reference, an `artifact` can contain document identifiers or other metadata that an application can use (e.g., to render a page). See example below:",
      "language": "unknown"
    },
    {
      "code": "See the [RAG tutorial](/oss/python/langchain/rag) for an end-to-end example of building retrieval [agents](/oss/python/langchain/agents) with LangChain.\n  </Accordion>\n</Note>\n\n***\n\n## Message content\n\nYou can think of a message's content as the payload of data that gets sent to the model. Messages have a `content` attribute that is loosely-typed, supporting strings and lists of untyped objects (e.g., dictionaries). This allows support for provider-native structures directly in LangChain chat models, such as [multimodal](#multimodal) content and other data.\n\nSeparately, LangChain provides dedicated content types for text, reasoning, citations, multi-modal data, server-side tool calls, and other message content. See [content blocks](#standard-content-blocks) below.\n\nLangChain chat models accept message content in the `content` attribute.\n\nThis may contain either:\n\n1. A string\n2. A list of content blocks in a provider-native format\n3. A list of [LangChain's standard content blocks](#standard-content-blocks)\n\nSee below for an example using [multimodal](#multimodal) inputs:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Message content",
      "id": "message-content"
    }
  ],
  "url": "llms-txt#continue-conversation",
  "links": []
}