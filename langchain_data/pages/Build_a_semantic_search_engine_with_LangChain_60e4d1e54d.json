{
  "title": "Build a semantic search engine with LangChain",
  "content": "Source: https://docs.langchain.com/oss/python/langchain/knowledge-base\n\nThis tutorial will familiarize you with LangChain's [document loader](/oss/python/langchain/retrieval#document-loaders), [embedding](/oss/python/langchain/retrieval#embedding-models), and [vector store](/oss/python/langchain/retrieval#vector-store) abstractions. These abstractions are designed to support retrieval of data--  from (vector) databases and other sources -- for integration with LLM workflows. They are important for applications that fetch data to be reasoned over as part of model inference, as in the case of retrieval-augmented generation, or [RAG](/oss/python/langchain/retrieval).\n\nHere we will build a search engine over a PDF document. This will allow us to retrieve passages in the PDF that are similar to an input query. The guide also includes a minimal RAG implementation on top of the search engine.\n\nThis guide focuses on retrieval of text data. We will cover the following concepts:\n\n* [Documents and document loaders](/oss/python/integrations/document_loaders);\n* [Text splitters](/oss/python/integrations/splitters);\n* [Embeddings](/oss/python/integrations/text_embedding);\n* [Vector stores](/oss/python/integrations/vectorstores) and [retrievers](/oss/python/integrations/retrievers).\n\nThis tutorial requires the `langchain-community` and `pypdf` packages:\n\nFor more details, see our [Installation guide](/oss/python/langchain/install).\n\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\nThe best way to do this is with [LangSmith](https://smith.langchain.com).\n\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\n\nOr, if in a notebook, you can set them with:\n\n## 1. Documents and Document Loaders\n\nLangChain implements a [Document](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) abstraction, which is intended to represent a unit of text and associated metadata. It has three attributes:\n\n* `page_content`: a string representing the content;\n* `metadata`: a dict containing arbitrary metadata;\n* `id`: (optional) a string identifier for the document.\n\nThe `metadata` attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) object often represents a chunk of a larger document.\n\nWe can generate sample documents when desired:\n\nHowever, the LangChain ecosystem implements [document loaders](/oss/python/langchain/retrieval#document-loaders) that [integrate with hundreds of common sources](/oss/python/integrations/document_loaders/). This makes it easy to incorporate data from these sources into your AI application.\n\n### Loading documents\n\nLet's load a PDF into a sequence of [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects. [Here is a sample PDF](https://github.com/langchain-ai/langchain/blob/v0.3/docs/docs/example_data/nke-10k-2023.pdf) -- a 10-k filing for Nike from 2023. We can consult the LangChain documentation for [available PDF document loaders](/oss/python/integrations/document_loaders/#pdfs).\n\n`PyPDFLoader` loads one [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) object per PDF page. For each, we can easily access:\n\n* The string content of the page;\n* Metadata containing the file name and page number.\n\nFor both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not \"washed out\" by surrounding text.\n\nWe can use [text splitters](/oss/python/langchain/retrieval#text_splitters) for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters\nwith 200 characters of overlap between chunks. The overlap helps\nmitigate the possibility of separating a statement from important\ncontext related to it. We use the\n`RecursiveCharacterTextSplitter`,\nwhich will recursively split the document using common separators like\nnew lines until each chunk is the appropriate size. This is the\nrecommended text splitter for generic text use cases.\n\nWe set `add_start_index=True` so that the character index where each\nsplit Document starts within the initial Document is preserved as\nmetadata attribute “start\\_index”.\n\nVector search is a common way to store and search over unstructured data (such as unstructured text). The idea is to store numeric vectors that are associated with the text. Given a query, we can [embed](/oss/python/langchain/retrieval#embedding_models) it as a vector of the same dimension and use vector similarity metrics (such as cosine similarity) to identify related text.\n\nLangChain supports embeddings from [dozens of providers](/oss/python/integrations/text_embedding/). These models specify how text should be converted into a numeric vector. Let's select a model:\n\n<Tabs>\n  <Tab title=\"OpenAI\">\n\n<Tab title=\"Google Gemini\">\n\n<Tab title=\"Google Vertex\">\n\n<Tab title=\"HuggingFace\">\n\n<Tab title=\"MistralAI\">\n\n<Tab title=\"Voyage AI\">\n\n<Tab title=\"IBM watsonx\">\n\n<Tab title=\"Isaacus\">\n\nArmed with a model for generating text embeddings, we can next store them in a special data structure that supports efficient similarity search.\n\nLangChain [VectorStore](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore) objects contain methods for adding text and [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects to the store, and querying them using various similarity metrics. They are often initialized with [embedding](/oss/python/langchain/retrieval#embedding_models) models, which determine how text data is translated to numeric vectors.\n\nLangChain includes a suite of [integrations](/oss/python/integrations/vectorstores) with different vector store technologies. Some vector stores are hosted by a provider (e.g., various cloud providers) and require specific credentials to use; some (such as [Postgres](/oss/python/integrations/vectorstores/pgvector)) run in separate infrastructure that can be run locally or via a third-party; others can run in-memory for lightweight workloads. Let's select a vector store:\n\n<Tabs>\n  <Tab title=\"In-memory\">\n\n<Tab title=\"Amazon OpenSearch\">\n\n<Tab title=\"AstraDB\">\n\n<Tab title=\"MongoDB\">\n\n<Tab title=\"PGVector\">\n\n<Tab title=\"PGVectorStore\">\n\n<Tab title=\"Pinecone\">\n\nHaving instantiated our vector store, we can now index the documents.\n\nNote that most vector store implementations will allow you to connect to an existing vector store--  e.g., by providing a client, index name, or other information. See the documentation for a specific [integration](/oss/python/integrations/vectorstores) for more detail.\n\nOnce we've instantiated a [`VectorStore`](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore) that contains documents, we can query it. [VectorStore](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore) includes methods for querying:\n\n* Synchronously and asynchronously;\n* By string query and by vector;\n* With and without returning similarity scores;\n* By similarity and [maximum marginal relevance](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore.max_marginal_relevance_search) (to balance similarity with query to diversity in retrieved results).\n\nThe methods will generally include a list of [Document](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects in their outputs.\n\nEmbeddings typically represent text as a \"dense\" vector such that texts with similar meanings are geometrically close. This lets us retrieve relevant information just by passing in a question, without knowledge of any specific key-terms used in the document.\n\nReturn documents based on similarity to a string query:\n\n```python  theme={null}",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\nFor more details, see our [Installation guide](/oss/python/langchain/install).\n\n### LangSmith\n\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\nThe best way to do this is with [LangSmith](https://smith.langchain.com).\n\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:",
      "language": "unknown"
    },
    {
      "code": "Or, if in a notebook, you can set them with:",
      "language": "unknown"
    },
    {
      "code": "## 1. Documents and Document Loaders\n\nLangChain implements a [Document](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) abstraction, which is intended to represent a unit of text and associated metadata. It has three attributes:\n\n* `page_content`: a string representing the content;\n* `metadata`: a dict containing arbitrary metadata;\n* `id`: (optional) a string identifier for the document.\n\nThe `metadata` attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) object often represents a chunk of a larger document.\n\nWe can generate sample documents when desired:",
      "language": "unknown"
    },
    {
      "code": "However, the LangChain ecosystem implements [document loaders](/oss/python/langchain/retrieval#document-loaders) that [integrate with hundreds of common sources](/oss/python/integrations/document_loaders/). This makes it easy to incorporate data from these sources into your AI application.\n\n### Loading documents\n\nLet's load a PDF into a sequence of [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects. [Here is a sample PDF](https://github.com/langchain-ai/langchain/blob/v0.3/docs/docs/example_data/nke-10k-2023.pdf) -- a 10-k filing for Nike from 2023. We can consult the LangChain documentation for [available PDF document loaders](/oss/python/integrations/document_loaders/#pdfs).",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "`PyPDFLoader` loads one [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) object per PDF page. For each, we can easily access:\n\n* The string content of the page;\n* Metadata containing the file name and page number.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Splitting\n\nFor both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not \"washed out\" by surrounding text.\n\nWe can use [text splitters](/oss/python/langchain/retrieval#text_splitters) for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters\nwith 200 characters of overlap between chunks. The overlap helps\nmitigate the possibility of separating a statement from important\ncontext related to it. We use the\n`RecursiveCharacterTextSplitter`,\nwhich will recursively split the document using common separators like\nnew lines until each chunk is the appropriate size. This is the\nrecommended text splitter for generic text use cases.\n\nWe set `add_start_index=True` so that the character index where each\nsplit Document starts within the initial Document is preserved as\nmetadata attribute “start\\_index”.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## 2. Embeddings\n\nVector search is a common way to store and search over unstructured data (such as unstructured text). The idea is to store numeric vectors that are associated with the text. Given a query, we can [embed](/oss/python/langchain/retrieval#embedding_models) it as a vector of the same dimension and use vector similarity metrics (such as cosine similarity) to identify related text.\n\nLangChain supports embeddings from [dozens of providers](/oss/python/integrations/text_embedding/). These models specify how text should be converted into a numeric vector. Let's select a model:\n\n<Tabs>\n  <Tab title=\"OpenAI\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Azure\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Google Gemini\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Google Vertex\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"AWS\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"HuggingFace\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Ollama\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Cohere\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"MistralAI\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Nomic\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"NVIDIA\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Voyage AI\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"IBM watsonx\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Fake\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Isaacus\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n</Tabs>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Armed with a model for generating text embeddings, we can next store them in a special data structure that supports efficient similarity search.\n\n## 3. Vector stores\n\nLangChain [VectorStore](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore) objects contain methods for adding text and [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects to the store, and querying them using various similarity metrics. They are often initialized with [embedding](/oss/python/langchain/retrieval#embedding_models) models, which determine how text data is translated to numeric vectors.\n\nLangChain includes a suite of [integrations](/oss/python/integrations/vectorstores) with different vector store technologies. Some vector stores are hosted by a provider (e.g., various cloud providers) and require specific credentials to use; some (such as [Postgres](/oss/python/integrations/vectorstores/pgvector)) run in separate infrastructure that can be run locally or via a third-party; others can run in-memory for lightweight workloads. Let's select a vector store:\n\n<Tabs>\n  <Tab title=\"In-memory\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Amazon OpenSearch\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"AstraDB\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Chroma\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"FAISS\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Milvus\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"MongoDB\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"PGVector\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"PGVectorStore\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Pinecone\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n\n  <Tab title=\"Qdrant\">",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</Tab>\n</Tabs>\n\nHaving instantiated our vector store, we can now index the documents.",
      "language": "unknown"
    },
    {
      "code": "Note that most vector store implementations will allow you to connect to an existing vector store--  e.g., by providing a client, index name, or other information. See the documentation for a specific [integration](/oss/python/integrations/vectorstores) for more detail.\n\nOnce we've instantiated a [`VectorStore`](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore) that contains documents, we can query it. [VectorStore](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore) includes methods for querying:\n\n* Synchronously and asynchronously;\n* By string query and by vector;\n* With and without returning similarity scores;\n* By similarity and [maximum marginal relevance](https://reference.langchain.com/python/langchain_core/vectorstores/?h=#langchain_core.vectorstores.base.VectorStore.max_marginal_relevance_search) (to balance similarity with query to diversity in retrieved results).\n\nThe methods will generally include a list of [Document](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects in their outputs.\n\n**Usage**\n\nEmbeddings typically represent text as a \"dense\" vector such that texts with similar meanings are geometrically close. This lets us retrieve relevant information just by passing in a question, without knowledge of any specific key-terms used in the document.\n\nReturn documents based on similarity to a string query:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Async query:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Return scores:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h3",
      "text": "Concepts",
      "id": "concepts"
    },
    {
      "level": "h2",
      "text": "Setup",
      "id": "setup"
    },
    {
      "level": "h3",
      "text": "Installation",
      "id": "installation"
    },
    {
      "level": "h3",
      "text": "LangSmith",
      "id": "langsmith"
    },
    {
      "level": "h2",
      "text": "1. Documents and Document Loaders",
      "id": "1.-documents-and-document-loaders"
    },
    {
      "level": "h3",
      "text": "Loading documents",
      "id": "loading-documents"
    },
    {
      "level": "h3",
      "text": "Splitting",
      "id": "splitting"
    },
    {
      "level": "h2",
      "text": "2. Embeddings",
      "id": "2.-embeddings"
    },
    {
      "level": "h2",
      "text": "3. Vector stores",
      "id": "3.-vector-stores"
    }
  ],
  "url": "llms-txt#build-a-semantic-search-engine-with-langchain",
  "links": []
}