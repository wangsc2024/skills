{
  "title": "How to use Studio",
  "content": "Source: https://docs.langchain.com/langsmith/use-studio\n\nThis page describes the core workflows you’ll use in Studio. It explains how to run your application, manage assistant configurations, and work with conversation threads. Each section includes steps in both graph mode (full-featured view of your graph’s execution) and chat mode (lightweight conversational interface):\n\n* [Run application](#run-application): Execute your application or agent and observe its behavior.\n* [Manage assistants](#manage-assistants): Create, edit, and select the assistant configuration used by your application.\n* [Manage threads](#manage-threads): View and organize the threads, including forking or editing past runs for debugging.\n\n<Tabs>\n  <Tab title=\"Graph\">\n    ### Specify input\n\n1. Define the input to your graph in the **Input** section on the left side of the page, below the graph interface. Studio will attempt to render a form for your input based on the graph's defined [state schema](/oss/python/langgraph/graph-api/#schema). To disable this, click the **View Raw** button, which will present you with a JSON editor.\n    2. Click the up or down arrows at the top of the **Input** section to toggle through and use previously submitted inputs.\n\nTo specify the [assistant](/langsmith/assistants) that is used for the run:\n\n1. Click the **Settings** button in the bottom left corner. If an assistant is currently selected the button will also list the assistant name. If no assistant is selected it will say **Manage Assistants**.\n    2. Select the assistant to run.\n    3. Click the **Active** toggle at the top of the modal to activate it.\n\nFor more information, refer to [Manage assistants](#manage-assistants).\n\nClick the dropdown next to **Submit** and click the toggle to enable or disable streaming.\n\nTo run your graph with breakpoints:\n\n1. Click **Interrupt**.\n    2. Select a node and whether to pause before or after that node has executed.\n    3. Click **Continue** in the thread log to resume execution.\n\nFor more information on breakpoints, refer to [Human-in-the-loop](/oss/python/langchain/human-in-the-loop).\n\nTo submit the run with the specified input and run settings:\n\n1. Click the **Submit** button. This will add a [run](/langsmith/assistants#execution) to the existing selected [thread](/oss/python/langgraph/persistence#threads). If no thread is currently selected, a new one will be created.\n    2. To cancel the ongoing run, click the **Cancel** button.\n  </Tab>\n\n<Tab title=\"Chat\">\n    Specify the input to your chat application in the bottom of the conversation panel.\n\n1. Click the **Send message** button to submit the input as a Human message and have the response streamed back.\n\nTo cancel the ongoing run:\n\n1. Click **Cancel**.\n    2. Click the **Show tool calls** toggle to hide or show tool calls in the conversation.\n  </Tab>\n</Tabs>\n\nStudio lets you view, edit, and update your assistants, and allows you to run your graph using these assistant configurations.\n\nFor more conceptual details, refer to the [Assistants overview](/langsmith/assistants/).\n\n<Tabs>\n  <Tab title=\"Graph\">\n    To view your assistants:\n\n1. Click **Manage Assistants** in the bottom left corner. This opens a modal for you to view all the assistants for the selected graph.\n    2. Specify the assistant and its version you would like to mark as **Active**. LangSmith will use this assistant when runs are submitted.\n\nThe **Default configuration** option will be active, which reflects the default configuration defined in your graph. Edits made to this configuration will be used to update the run-time configuration, but will not update or create a new assistant unless you click **Create new assistant**.\n  </Tab>\n\n<Tab title=\"Chat\">\n    Chat mode enables you to switch through the different assistants in your graph via the dropdown selector at the top of the page. To create, edit, or delete assistants, use Graph mode.\n  </Tab>\n</Tabs>\n\nStudio provides tools to view all [threads](/oss/python/langgraph/persistence#threads) saved on the server and edit their state. You can create new threads, switch between threads, and modify past states both in graph mode and chat mode.\n\n<Tabs>\n  <Tab title=\"Graph\">\n    ### View threads\n\n1. In the top of the right-hand pane, select the dropdown menu to view existing threads.\n    2. Select the desired thread, and the thread history will populate in the right-hand side of the page.\n    3. To create a new thread, click **+ New Thread** and [submit a run](#run-application).\n    4. To view more granular information in the thread, drag the slider at the top of the page to the right. To view less information, drag the slider to the left. Additionally, collapse or expand individual turns, nodes, and keys of the state.\n    5. Switch between `Pretty` and `JSON` mode for different rendering formats.\n\n### Edit thread history\n\nTo edit the state of the thread:\n\n1. Select <Icon icon=\"pencil\" /> **Edit node state** next to the desired node.\n    2. Edit the node's output as desired and click **Fork** to confirm. This will create a new forked run from the checkpoint of the selected node.\n\nIf you instead want to re-run the thread from a given checkpoint without editing the state, click **Re-run from here**. This will again create a new forked run from the selected checkpoint. This is useful for re-running with changes that are not specific to the state, such as the selected assistant.\n  </Tab>\n\n<Tab title=\"Chat\">\n    1. View all threads in the right-hand pane of the page.\n    2. Select the desired thread and the thread history will populate in the center panel.\n    3. To create a new thread, click **+** and submit a run.\n\nTo edit a human message in the thread:\n\n1. Click <Icon icon=\"pencil\" /> **Edit node state** below the human message.\n    2. Edit the message as desired and submit. This will create a new fork of the conversation history.\n    3. To re-generate an AI message, click the retry icon below the AI message.\n  </Tab>\n</Tabs>\n\nRefer to the following guides for more detail on tasks you can complete in Studio:\n\n* [Iterate on prompts](/langsmith/observability-studio)\n* [Run experiments over datasets](/langsmith/observability-studio#run-experiments-over-a-dataset)\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/use-studio.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Run application",
      "id": "run-application"
    },
    {
      "level": "h2",
      "text": "Manage assistants",
      "id": "manage-assistants"
    },
    {
      "level": "h2",
      "text": "Manage threads",
      "id": "manage-threads"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    }
  ],
  "url": "llms-txt#how-to-use-studio",
  "links": []
}