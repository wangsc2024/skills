{
  "title": "A2A endpoint in Agent Server",
  "content": "Source: https://docs.langchain.com/langsmith/server-a2a\n\n[Agent2Agent (A2A)](https://a2a-protocol.org/latest/) is Google's protocol for enabling communication between conversational AI agents. [LangSmith implements A2A support](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html#tag/a2a/post/a2a/\\{assistant_id}), allowing your agents to communicate with other A2A-compatible agents through a standardized protocol.\n\nThe A2A endpoint is available in [Agent Server](/langsmith/agent-server) at `/a2a/{assistant_id}`.\n\nAgent Server supports the following A2A RPC methods:\n\n* **message/send**: Send a message to an assistant and receive a complete response\n* **message/stream**: Send a message and stream responses in real-time using Server-Sent Events (SSE)\n* **tasks/get**: Retrieve the status and results of a previously created task\n\n## Agent Card Discovery\n\nEach assistant automatically exposes an A2A Agent Card that describes its capabilities and provides the information needed for other agents to connect. You can retrieve the agent card for any assistant using:\n\nThe agent card includes the assistant's name, description, available skills, supported input/output modes, and the A2A endpoint URL for communication.\n\nTo use A2A, ensure you have the following dependencies installed:\n\n* `langgraph-api >= 0.4.21`\n\n* Upgrade to use langgraph-api>=0.4.21.\n* Deploy your agent with message-based state structure.\n* Connect with other A2A-compatible agents using the endpoint.\n\n## Creating an A2A-compatible agent\n\nThis example creates an A2A-compatible agent that processes incoming messages using OpenAI's API and maintains conversational state. The agent defines a message-based state structure and handles the A2A protocol's message format.\n\nTo be compatible with the [A2A \"text\" parts](https://a2a-protocol.org/dev/specification/#651-textpart-object), the agent must have a `messages` key in state. Here's an example:\n\n```python  theme={null}\n\"\"\"LangGraph A2A conversational agent.\n\nSupports the A2A protocol with messages input for conversational interactions.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, TypedDict\n\nfrom langgraph.graph import StateGraph\nfrom langgraph.runtime import Runtime\nfrom openai import AsyncOpenAI\n\nclass Context(TypedDict):\n    \"\"\"Context parameters for the agent.\"\"\"\n    my_configurable_param: str\n\n@dataclass\nclass State:\n    \"\"\"Input state for the agent.\n\nDefines the initial structure for A2A conversational messages.\n    \"\"\"\n    messages: List[Dict[str, Any]]\n\nasync def call_model(state: State, runtime: Runtime[Context]) -> Dict[str, Any]:\n    \"\"\"Process conversational messages and returns output using OpenAI.\"\"\"\n    # Initialize OpenAI client\n    client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Process the incoming messages\n    latest_message = state.messages[-1] if state.messages else {}\n    user_content = latest_message.get(\"content\", \"No message content\")\n\n# Create messages for OpenAI API\n    openai_messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful conversational agent. Keep responses brief and engaging.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": user_content\n        }\n    ]\n\ntry:\n        # Make OpenAI API call\n        response = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=openai_messages,\n            max_tokens=100,\n            temperature=0.7\n        )\n\nai_response = response.choices[0].message.content\n\nexcept Exception as e:\n        ai_response = f\"I received your message but had trouble processing it. Error: {str(e)[:50]}...\"\n\n# Create a response message\n    response_message = {\n        \"role\": \"assistant\",\n        \"content\": ai_response\n    }\n\nreturn {\n        \"messages\": state.messages + [response_message]\n    }",
  "code_samples": [
    {
      "code": "GET /.well-known/agent-card.json?assistant_id={assistant_id}",
      "language": "unknown"
    },
    {
      "code": "## Usage overview\n\nTo enable A2A:\n\n* Upgrade to use langgraph-api>=0.4.21.\n* Deploy your agent with message-based state structure.\n* Connect with other A2A-compatible agents using the endpoint.\n\n## Creating an A2A-compatible agent\n\nThis example creates an A2A-compatible agent that processes incoming messages using OpenAI's API and maintains conversational state. The agent defines a message-based state structure and handles the A2A protocol's message format.\n\nTo be compatible with the [A2A \"text\" parts](https://a2a-protocol.org/dev/specification/#651-textpart-object), the agent must have a `messages` key in state. Here's an example:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Supported methods",
      "id": "supported-methods"
    },
    {
      "level": "h2",
      "text": "Agent Card Discovery",
      "id": "agent-card-discovery"
    },
    {
      "level": "h2",
      "text": "Requirements",
      "id": "requirements"
    },
    {
      "level": "h2",
      "text": "Usage overview",
      "id": "usage-overview"
    },
    {
      "level": "h2",
      "text": "Creating an A2A-compatible agent",
      "id": "creating-an-a2a-compatible-agent"
    }
  ],
  "url": "llms-txt#a2a-endpoint-in-agent-server",
  "links": []
}