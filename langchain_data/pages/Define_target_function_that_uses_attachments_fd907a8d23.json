{
  "title": "Define target function that uses attachments",
  "content": "def file_qa(inputs, attachments):\n    # Read the audio bytes from the reader and encode them in base64\n    audio_reader = attachments[\"my_wav\"][\"reader\"]\n    audio_b64 = base64.b64encode(audio_reader.read()).decode('utf-8')\n\naudio_completion = client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": inputs[\"audio_question\"]\n                    },\n                    {\n                        \"type\": \"input_audio\",\n                        \"input_audio\": {\n                            \"data\": audio_b64,\n                            \"format\": \"wav\"\n                        }\n                    }\n                ]\n            }\n        ]\n    )\n\n# Most models support taking in an image URL directly in addition to base64 encoded images\n    # You can pipe the image pre-signed URL directly to the model\n    image_url = attachments[\"my_img\"][\"presigned_url\"]\n    image_completion = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n          {\n            \"role\": \"user\",\n            \"content\": [\n              {\"type\": \"text\", \"text\": inputs[\"image_question\"]},\n              {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                  \"url\": image_url,\n                },\n              },\n            ],\n          }\n        ],\n    )\n\nreturn {\n        \"audio_answer\": audio_completion.choices[0].message.content,\n        \"image_answer\": image_completion.choices[0].message.content,\n    }\ntypescript  theme={null}\n{\n  presigned_url: string,\n  mime_type: string,\n}\ntypescript  theme={null}\nimport OpenAI from \"openai\";\nimport { wrapOpenAI } from \"langsmith/wrappers\";\n\nconst client: any = wrapOpenAI(new OpenAI());\n\nasync function fileQA(inputs: Record<string, any>, config?: Record<string, any>) {\n  const presignedUrl = config?.attachments?.[\"my_wav\"]?.presigned_url;\n  if (!presignedUrl) {\n    throw new Error(\"No presigned URL provided for audio.\");\n  }\n\nconst response = await fetch(presignedUrl);\n  if (!response.ok) {\n    throw new Error(`Failed to fetch audio: ${response.statusText}`);\n  }\n\nconst arrayBuffer = await response.arrayBuffer();\n  const uint8Array = new Uint8Array(arrayBuffer);\n  const audioB64 = Buffer.from(uint8Array).toString(\"base64\");\n\nconst audioCompletion = await client.chat.completions.create({\n    model: \"gpt-4o-audio-preview\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          { type: \"text\", text: inputs[\"audio_question\"] },\n          {\n            type: \"input_audio\",\n            input_audio: {\n              data: audioB64,\n              format: \"wav\",\n            },\n          },\n        ],\n      },\n    ],\n  });\n\nconst imageUrl = config?.attachments?.[\"my_img\"]?.presigned_url\n  const imageCompletion = await client.chat.completions.create({\n    model: \"gpt-4o-mini\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          { type: \"text\", text: inputs[\"image_question\"] },\n          {\n            type: \"image_url\",\n            image_url: {\n              url: imageUrl,\n            },\n          },\n        ],\n      },\n    ],\n  });\n\nreturn {\n    audio_answer: audioCompletion.choices[0].message.content,\n    image_answer: imageCompletion.choices[0].message.content,\n  };\n}\npython Python theme={null}\n  # Assumes you've installed pydantic\n  from pydantic import BaseModel\n\ndef valid_image_description(outputs: dict, attachments: dict) -> bool:\n    \"\"\"Use an LLM to judge if the image description and images are consistent.\"\"\"\n    instructions = \"\"\"\n    Does the description of the following image make sense?\n    Please carefully review the image and the description to determine if the description is valid.\n    \"\"\"\n\nclass Response(BaseModel):\n        description_is_valid: bool\n\nimage_url = attachments[\"my_img\"][\"presigned_url\"]\n    response = client.beta.chat.completions.parse(\n        model=\"gpt-4o\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": instructions\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n                    {\"type\": \"text\", \"text\": outputs[\"image_answer\"]}\n                ]\n            }\n        ],\n        response_format=Response\n    )\n    return response.choices[0].message.parsed.description_is_valid\n\nls_client.evaluate(\n    file_qa,\n    data=dataset_name,\n    evaluators=[valid_image_description],\n  )\n  typescript TypeScript theme={null}\n  import { zodResponseFormat } from 'openai/helpers/zod';\n  import { z } from 'zod';\n  import { evaluate } from \"langsmith/evaluation\";\n\nconst DescriptionResponse = z.object({\n    description_is_valid: z.boolean(),\n  });\n\nasync function validImageDescription({\n    outputs,\n    attachments,\n  }: {\n    outputs?: any;\n    attachments?: any;\n  }): Promise<{ key: string; score: boolean}> {\n    const instructions = `Does the description of the following image make sense?\n  Please carefully review the image and the description to determine if the description is valid.`;\n\nconst imageUrl = attachments?.[\"my_img\"]?.presigned_url\n    const completion = await client.beta.chat.completions.parse({\n        model: \"gpt-4o\",\n        messages: [\n            {\n                role: \"system\",\n                content: instructions,\n            },\n            {\n                role: \"user\",\n                content: [\n                    { type: \"image_url\", image_url: { url: imageUrl } },\n                    { type: \"text\", text: outputs?.image_answer },\n                ],\n            },\n        ],\n        response_format: zodResponseFormat(DescriptionResponse, 'imageResponse'),\n    });\n\nconst score: boolean = completion.choices[0]?.message?.parsed?.description_is_valid ?? false;\n    return { key: \"valid_image_description\", score };\n  }\n\nconst resp = await evaluate(fileQA, {\n    data: datasetName,\n    // Need to pass flag to include attachments\n    includeAttachments: true,\n    evaluators: [validImageDescription],\n    client: langsmithClient\n  });\n  python Python theme={null}\n  example_update = {\n    \"id\": example_id,\n    \"attachments\": {\n        # These are net new attachments\n        \"my_new_file\": (\"text/plain\", b\"foo bar\"),\n    },\n    \"inputs\": inputs,\n    \"outputs\": outputs,\n    # Any attachments not in rename/retain will be deleted.\n    # In this case, that would be \"my_img\" if we uploaded it.\n    \"attachments_operations\": {\n        # Retained attachments will stay exactly the same\n        \"retain\": [\"my_pdf\"],\n        # Renaming attachments preserves the original data\n        \"rename\": {\n            \"my_wav\": \"my_new_wav\",\n        }\n    },\n  }\n\nls_client.update_examples(dataset_id=dataset.id, updates=[example_update])\n  typescript TypeScript theme={null}\n  import { ExampleUpdateWithAttachments } from \"langsmith/schemas\";\n\nconst exampleUpdate: ExampleUpdateWithAttachments = {\n    id: exampleId,\n    attachments: {\n      // These are net new attachments\n      \"my_new_file\": {\n        mimeType: \"text/plain\",\n        data: Buffer.from(\"foo bar\")\n      },\n    },\n    attachments_operations: {\n      // Retained attachments will stay exactly the same\n      retain: [\"my_img\"],\n      // Renaming attachments preserves the original data\n      rename: {\n        \"my_wav\": \"my_new_wav\",\n      },\n      // Any attachments not in rename/retain will be deleted\n      // In this case, that would be \"my_pdf\"\n    },\n  };\n\nawait langsmithClient.updateExamplesMultipart(dataset.id, [exampleUpdate]);\n  ```\n</CodeGroup>\n\n### 1. Create examples with attachments\n\nYou can add examples with attachments to a dataset in a few different ways.\n\n#### From existing runs\n\nWhen adding runs to a LangSmith dataset, attachments can be selectively propagated from the source run to the destination example. To learn more, please see [this guide](/langsmith/manage-datasets-in-application#add-runs-from-the-tracing-project-ui).\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=b8fa62cb39c4f1fc67d9b24fa78d1653\" alt=\"Add trace with attachments to dataset\" data-og-width=\"1662\" width=\"1662\" data-og-height=\"679\" height=\"679\" data-path=\"langsmith/images/add-trace-with-attachments-to-dataset.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?w=280&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=72ee339359616ed8f03f4ddbfe86bc23 280w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?w=560&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=cb6f558f8a0391588583a7b5d520a27f 560w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?w=840&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=bc51ed2e68af972e488051fc1ae01caf 840w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?w=1100&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=d58d097b70ad0f6b7a327058c659d8d9 1100w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?w=1650&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=cbac645e6534290036d24963c231a878 1650w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-trace-with-attachments-to-dataset.png?w=2500&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=b4ff5c59dd6c2b23d97bfd5e34206a50 2500w\" />\n\nYou can create examples with attachments directly from the LangSmith UI. Click the `+ Example` button in the `Examples` tab of the dataset UI. Then upload attachments using the \"Upload Files\" button:\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=183f929c807f59157e93d40354057933\" alt=\"Create example with attachments\" data-og-width=\"3456\" width=\"3456\" data-og-height=\"1856\" height=\"1856\" data-path=\"langsmith/images/create-example-with-attachments.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?w=280&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=c80316a80e8359d14aa42aac6767b677 280w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?w=560&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=1921a813aea4e6fa62bcf7cfd169662e 560w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?w=840&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=35d6882ec8757e56d81eba2033220cf7 840w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?w=1100&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=0b93d237b11ab6bf8693b287ee19dc4b 1100w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?w=1650&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=38384c5a8166b41535657ec8a6337b49 1650w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/create-example-with-attachments.png?w=2500&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=b0f8622286209391451895c2e4c7b03b 2500w\" />\n\nOnce uploaded, you can view examples with attachments in the LangSmith UI. Each attachment will be rendered with a preview for easy inspection. <img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=8f813bdf7d3bfd5a840e5f8c47693ed3\" alt=\"Attachments with examples\" data-og-width=\"1331\" width=\"1331\" data-og-height=\"593\" height=\"593\" data-path=\"langsmith/images/attachments-with-examples.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?w=280&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=0ecc6a1a59da5972731c4f36fc0154d8 280w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?w=560&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=f7985b2778973b594e8522964eb13770 560w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?w=840&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=f062086524f7aff66c094ac0e259c04e 840w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?w=1100&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=970e61cff6a2cfc749c14481afe2a3f9 1100w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?w=1650&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=4c34be3eb64547daf4879b2f2dab3ec4 1650w, https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachments-with-examples.png?w=2500&fit=max&auto=format&n=E8FdemkcQxROovD9&q=85&s=700119fd1a262ce0f85d924b684141a4 2500w\" />\n\n### 2. Create a multimodal prompt\n\nThe LangSmith UI allows you to include attachments in your prompts when evaluating multimodal models:\n\nFirst, click the file icon in the message where you want to add multimodal content. Next, add a template variable for the attachment(s) you want to include for each example.\n\n* For a single attachment type: Use the suggested variable name. Note: all examples must have an attachment with this name.\n* For multiple attachments or if your attachments have varying names from one example to another: Use the `All attachments` variable to include all available attachments for each example.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/adding-multimodal-variable.gif?s=07a15c9fc5e6fc743f92b6b41ab8c9e0\" alt=\"Adding multimodal variable\" data-og-width=\"1700\" width=\"1700\" data-og-height=\"1080\" height=\"1080\" data-path=\"langsmith/images/adding-multimodal-variable.gif\" data-optimize=\"true\" data-opv=\"3\" />\n\n### Define custom evaluators\n\n<Note>\n  The LangSmith playground does not currently support pulling multimodal content into evaluators. If this would be helpful for your use case, please let us know in the [LangChain Forum](https://forum.langchain.com/) (sign up [here](https://www.langchain.com/join-community) if you're not already a member)!\n</Note>\n\nYou can evaluate a model's text output by adding an evaluator that takes in the example's inputs and outputs. Even without multimodal support in your evaluators, you can still run text-only evaluations. For example:\n\n* OCR → text correction: Use a vision model to extract text from a document, then evaluate the accuracy of the extracted output.\n* Speech-to-text → transcription quality: Use a voice model to transcribe audio to text, then evaluate the transcription against your reference.\n\nFor more information on defining custom evaluators, see the [LLM as Judge](/langsmith/llm-as-judge) guide.\n\n### Update examples with attachments\n\n<Note>\n  Attachments are limited to 20MB in size in the UI.\n</Note>\n\nWhen editing an example in the UI, you can:\n\n* Upload new attachments\n* Rename and delete attachments\n* Reset attachments to their previous state using the quick reset button\n\nChanges are not saved until you click submit.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/attachment-editing.gif?s=4f165ed98fe81722961778ebbe1691ed\" alt=\"Attachment editing\" data-og-width=\"1204\" width=\"1204\" data-og-height=\"720\" height=\"720\" data-path=\"langsmith/images/attachment-editing.gif\" data-optimize=\"true\" data-opv=\"3\" />\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/evaluate-with-attachments.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "#### TypeScript\n\nIn the TypeScript SDK, the `config` argument is used to pass in the attachments to the target function if `includeAttachments` is set to `true`.\n\nThe `config` will contain `attachments` which is an object mapping the attachment name to an object of the form:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Define custom evaluators\n\nThe exact same rules apply as above to determine whether the evaluator should receive attachments.\n\nThe evaluator below uses an LLM to judge if the reasoning and the answer are consistent. To learn more about how to define llm-based evaluators, please see [this guide](/langsmith/llm-as-judge).\n\n<CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</CodeGroup>\n\n## Update examples with attachments\n\nIn the code above, we showed how to add examples with attachments to a dataset. It is also possible to update these same examples using the SDK.\n\nAs with existing examples, datasets are versioned when you update them with attachments. Therefore, you can navigate to the dataset version history to see the changes made to each example. To learn more, please see [this guide](/langsmith/manage-datasets-in-application).\n\nWhen updating an example with attachments, you can update attachments in a few different ways:\n\n* Pass in new attachments\n* Rename existing attachments\n* Delete existing attachments\n\nNote that:\n\n* Any existing attachments that are not explicitly renamed or retained **will be deleted**.\n* An error will be raised if you pass in a non-existent attachment name to `retain` or `rename`.\n* New attachments take precedence over existing attachments in case the same attachment name appears in the `attachments` and `attachment_operations` fields.\n\n<CodeGroup>",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "Define custom evaluators",
      "id": "define-custom-evaluators"
    },
    {
      "level": "h2",
      "text": "Update examples with attachments",
      "id": "update-examples-with-attachments"
    },
    {
      "level": "h2",
      "text": "UI",
      "id": "ui"
    },
    {
      "level": "h3",
      "text": "1. Create examples with attachments",
      "id": "1.-create-examples-with-attachments"
    },
    {
      "level": "h3",
      "text": "2. Create a multimodal prompt",
      "id": "2.-create-a-multimodal-prompt"
    },
    {
      "level": "h3",
      "text": "Define custom evaluators",
      "id": "define-custom-evaluators"
    },
    {
      "level": "h3",
      "text": "Update examples with attachments",
      "id": "update-examples-with-attachments"
    }
  ],
  "url": "llms-txt#define-target-function-that-uses-attachments",
  "links": []
}