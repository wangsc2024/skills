{
  "title": "./src/agent/webapp.py",
  "content": "from fastapi import FastAPI\n\n@app.get(\"/hello\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\njson  theme={null}\n{\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"agent\": \"./src/agent/graph.py:graph\"\n  },\n  \"env\": \".env\",\n  \"http\": {\n    \"app\": \"./src/agent/webapp.py:app\"\n  }\n  // Other configuration options like auth, store, etc.\n}\nbash  theme={null}\nlanggraph dev --no-browser\n```\n\nIf you navigate to `localhost:2024/hello` in your browser (`2024` is the default development port), you should see the `/hello` endpoint returning `{\"Hello\": \"World\"}`.\n\n<Note>\n  **Shadowing default endpoints**\n  The routes you create in the app are given priority over the system defaults, meaning you can shadow and redefine the behavior of any default endpoint.\n</Note>\n\nYou can deploy this app as-is to LangSmith or to your self-hosted platform.\n\nNow that you've added a custom route to your deployment, you can use this same technique to further customize how your server behaves, such as defining custom [custom middleware](/langsmith/custom-middleware) and [custom lifespan events](/langsmith/custom-lifespan).\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/custom-routes.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "## Configure `langgraph.json`\n\nAdd the following to your `langgraph.json` configuration file. Make sure the path points to the FastAPI application instance `app` in the `webapp.py` file you created above.",
      "language": "unknown"
    },
    {
      "code": "## Start server\n\nTest the server out locally:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Configure `langgraph.json`",
      "id": "configure-`langgraph.json`"
    },
    {
      "level": "h2",
      "text": "Start server",
      "id": "start-server"
    },
    {
      "level": "h2",
      "text": "Deploying",
      "id": "deploying"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    }
  ],
  "url": "llms-txt#./src/agent/webapp.py",
  "links": []
}