{
  "title": "Prompt engineering concepts",
  "content": "Source: https://docs.langchain.com/langsmith/prompt-engineering-concepts\n\nWhile traditional software applications are built by writing code, AI applications often derive their logic from prompts.\n\nThis guide will walk through the key concepts of prompt engineering in LangSmith.\n\n## Why prompt engineering?\n\nA prompt sets the stage for the model, like an audience member at an improv show directing the actor's next performance - it guides the model's behavior without changing its underlying capabilities. Just as telling an actor to \"be a pirate\" determines how they act, a prompt provides instructions, examples, and context that shape how the model responds.\n\nPrompt engineering is important because it allows you to change the way the model behaves. While there are other ways to change the model's behavior (like fine-tuning), prompt engineering is usually the simplest to get started with and often provides the highest ROI.\n\nWe often see that prompt engineering is multi-disciplinary. Sometimes the best prompt engineer is not the software engineer who is building the application, but rather the product manager or another domain expert. It is important to have the proper tooling and infrastructure to support this cross-disciplinary building.\n\n## Prompts vs. prompt templates\n\nAlthough we often use these terms interchangably, it is important to understand the difference between \"prompts\" and \"prompt templates\".\n\nPrompts refer to the messages that are passed into the language model.\n\nPrompt Templates refer to a way of formatting information to get that prompt to hold the information that you want. Prompt templates can include variables for few shot examples, outside context, or any other external data that is needed in your prompt.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=714ad4962c85cfb8847ebbf01559c217\" alt=\"Prompt vs prompt template\" data-og-width=\"1084\" width=\"1084\" data-og-height=\"450\" height=\"450\" data-path=\"langsmith/images/prompt-vs-prompt-template.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?w=280&fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=81497578f297dd5a7311de6f1c06ef85 280w, https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?w=560&fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=d13dfcf34430d876cdc1a2b77a5fd3c4 560w, https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?w=840&fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=feec2461df390de635a2534b50eab8e6 840w, https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?w=1100&fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=e1851de62aa377fc3d70ec62dd91c5b2 1100w, https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?w=1650&fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=6bccce7c02cb065f9ef8964fbe3112b6 1650w, https://mintcdn.com/langchain-5e9cc07a/H9jA2WRyA-MV4-H0/langsmith/images/prompt-vs-prompt-template.png?w=2500&fit=max&auto=format&n=H9jA2WRyA-MV4-H0&q=85&s=c3494cef2e70686d55493ded764cc8c0 2500w\" />\n\n## Prompts in LangSmith\n\nYou can store and version prompts templates in LangSmith. There are few key aspects of a prompt template to understand.\n\n### Chat vs Completion\n\nThere are two different types of prompts: `chat` style prompts and `completion` style prompts.\n\nChat style prompts are a **list of messages**. This is the prompting style supported by most model APIs these days, and so this should generally be preferred.\n\nCompletion style prompts are just a string. This is an older style of prompting, and so mostly exists for legacy reasons.\n\n### F-string vs. mustache\n\nYou can format your prompt with input variables using either [f-string](https://realpython.com/python-f-strings/) or [mustache](https://mustache.github.io/mustache.5.html) format. Here is an example prompt with f-string format:\n\nAnd here is one with mustache:\n\nTo add a conditional mustache prompt:\n\n* The playground UI will pick up `is_logged_in` variable, but any nested variables you'll need to specify yourself. Paste the following into inputs to ensure the above conditional prompt works:\n\n<Check>\n  The LangSmith Playground uses `f-string` as the default template format, but you can switch to `mustache` format in the prompt settings/template format section. `mustache` gives you more flexibility around conditional variables, loops, and nested keys. For conditional variables, you'll need to manually add json variables in the 'inputs' section. Read [the documentation](https://mustache.github.io/mustache.5.html)\n</Check>\n\nTools are interfaces the LLM can use to interact with the outside world. Tools consist of a name, description, and JSON schema of arguments used to call the tool.\n\n### Structured output\n\nStructured output is a feature of most state of the art LLMs, wherein instead of producing raw text as output they stick to a specified schema. This may or may not use [Tools](#tools) under the hood.\n\n<Check>\n  Structured output is similar to tools, but different in a few key ways. With tools, the LLM choose which tool to call (or may choose not to call any); with structured output, the LLM **always** responds in this format. With tools, the LLM may select **multiple** tools; with structured output, only one response is generate.\n</Check>\n\nOptionally, you can store a model configuration alongside a prompt template. This includes the name of the model and any other parameters (temperature, etc).\n\nVerisioning is a key part of iterating and collaborating on your different prompts.\n\nEvery saved update to a prompt creates a new commit with a unique commit hash. This allows you to:\n\n* View the full history of changes to a prompt.\n* Review earlier versions.\n* Revert to a previous state if needed.\n* Reference specific versions in your code using the commit hash (e.g., `client.pull_prompt(\"prompt_name:commit_hash\")`).\n\nIn the UI, you can compare a commit with its previous version by toggling **Show diff** in the top-right corner of the **Commits** tab.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=a045b239f92dc1c616c7e42ae282c2b9\" alt=\"The commit hashes list for a prompt with the diff of one commit.\" data-og-width=\"2884\" width=\"2884\" data-og-height=\"1426\" height=\"1426\" data-path=\"langsmith/images/commit-diff.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?w=280&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=5f1f1e66762226af9ec78e7dcd88a40e 280w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?w=560&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=9170a56b51a619a3aea586942c6d1825 560w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?w=840&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=198ae20ca965b50d42178bb241bddf46 840w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?w=1100&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=5e56c9323edf28650c4c667def63d7d1 1100w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?w=1650&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=25b8995161ed4523c09526eee44aef8a 1650w, https://mintcdn.com/langchain-5e9cc07a/aKRoUGXX6ygp4DlC/langsmith/images/commit-diff.png?w=2500&fit=max&auto=format&n=aKRoUGXX6ygp4DlC&q=85&s=ac495d702a4df63f35ac47e5584a1c4b 2500w\" />\n\nCommit tags are human-readable labels that point to specific commits in your prompt's history. Unlike commit hashes, tags can be moved to point to different commits, allowing you to update which version your code references without changing the code itself.\n\nUse cases for commit tags can include:\n\n* **Environment-specific tags**: Mark commits for `production` or `staging` environments, which allows you to switch between different versions without changing your code.\n* **Version control**: Mark stable versions of your prompts, for example, `v1`, `v2`, which lets you reference specific versions in your code and track changes over time.\n* **Collaboration**: Mark versions ready for review, which enables you to share specific versions with collaborators and get feedback.\n\n<Note>\n  **Not to be confused with resource tags**: Commit tags reference specific prompt versions. [Resource tags](/langsmith/set-up-resource-tags) are key-value pairs used to organize workspace resources.\n</Note>\n\nFor detailed information on creating and managing commit tags, see [Manage prompts](/langsmith/manage-prompts#commit-tags).\n\nThe prompt playground makes the process of iterating and testing your prompts seamless. You can enter the playground from the sidebar or directly from a saved prompt.\n\nIn the playground you can:\n\n* Change the model being used\n* Change prompt template being used\n* Change the output schema\n* Change the tools available\n* Enter the input variables to run through the prompt template\n* Run the prompt through the model\n* Observe the outputs\n\n<Callout type=\"info\" icon=\"bird\">\n  Use **[Polly](/langsmith/polly)** in the Playground to optimize prompts, generate tools, and create output schemas with AI assistance.\n</Callout>\n\n## Testing multiple prompts\n\nYou can add more prompts to your playground to easily compare outputs and decide which version is better:\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/E8FdemkcQxROovD9/langsmith/images/add-prompt-to-playground.gif?s=1c6f0c32b45a3f480b16d704c09570fc\" alt=\"Add prompt to playground\" data-og-width=\"1000\" width=\"1000\" data-og-height=\"539\" height=\"539\" data-path=\"langsmith/images/add-prompt-to-playground.gif\" data-optimize=\"true\" data-opv=\"3\" />\n\n## Testing over a dataset\n\nTo test over a dataset, you simply select the dataset from the top right and press Start. You can modify whether the results are streamed back as well as how many repitions there are in the test.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/ImHGLQW1HnQYwnJV/langsmith/images/test-over-dataset-in-playground.gif?s=aaf0f90a0c61934a928f81d5e11e2c35\" alt=\"Test over dataset in playground\" data-og-width=\"1000\" width=\"1000\" data-og-height=\"539\" height=\"539\" data-path=\"langsmith/images/test-over-dataset-in-playground.gif\" data-optimize=\"true\" data-opv=\"3\" />\n\nYou can click on the \"View Experiment\" button to dive deeper into the results of the test.\n\n<iframe className=\"w-full aspect-video rounded-xl\" src=\"https://www.youtube.com/embed/h4f6bIWGkog?si=IVJFfhldC7M3HL4G\" title=\"YouTube video player\" frameBorder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowFullScreen />\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/prompt-engineering-concepts.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [
    {
      "code": "And here is one with mustache:",
      "language": "unknown"
    },
    {
      "code": "To add a conditional mustache prompt:",
      "language": "unknown"
    },
    {
      "code": "* The playground UI will pick up `is_logged_in` variable, but any nested variables you'll need to specify yourself. Paste the following into inputs to ensure the above conditional prompt works:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Why prompt engineering?",
      "id": "why-prompt-engineering?"
    },
    {
      "level": "h2",
      "text": "Prompts vs. prompt templates",
      "id": "prompts-vs.-prompt-templates"
    },
    {
      "level": "h2",
      "text": "Prompts in LangSmith",
      "id": "prompts-in-langsmith"
    },
    {
      "level": "h3",
      "text": "Chat vs Completion",
      "id": "chat-vs-completion"
    },
    {
      "level": "h3",
      "text": "F-string vs. mustache",
      "id": "f-string-vs.-mustache"
    },
    {
      "level": "h3",
      "text": "Tools",
      "id": "tools"
    },
    {
      "level": "h3",
      "text": "Structured output",
      "id": "structured-output"
    },
    {
      "level": "h3",
      "text": "Model",
      "id": "model"
    },
    {
      "level": "h2",
      "text": "Prompt versioning",
      "id": "prompt-versioning"
    },
    {
      "level": "h3",
      "text": "Commits",
      "id": "commits"
    },
    {
      "level": "h3",
      "text": "Tags",
      "id": "tags"
    },
    {
      "level": "h2",
      "text": "Prompt playground",
      "id": "prompt-playground"
    },
    {
      "level": "h2",
      "text": "Testing multiple prompts",
      "id": "testing-multiple-prompts"
    },
    {
      "level": "h2",
      "text": "Testing over a dataset",
      "id": "testing-over-a-dataset"
    },
    {
      "level": "h2",
      "text": "Video guide",
      "id": "video-guide"
    }
  ],
  "url": "llms-txt#prompt-engineering-concepts",
  "links": []
}