{
  "title": "Feedback data format",
  "content": "Source: https://docs.langchain.com/langsmith/feedback-data-format\n\n<Check>\n  Before diving into this content, it might be helpful to read the following:\n\n* [Conceptual guide on tracing and feedback](/langsmith/observability-concepts)\n</Check>\n\n**Feedback** is LangSmith's way of storing the criteria and scores from evaluation on a particular trace or intermediate run (span). Feedback can be produced from a variety of ways, such as:\n\n1. [Sent up along with a trace](/langsmith/attach-user-feedback) from the LLM application\n2. Generated by a user in the app [inline](/langsmith/annotate-traces-inline) or in an [annotation queue](/langsmith/annotation-queues)\n3. Generated by an automatic evaluator during [offline evaluation](/langsmith/evaluate-llm-application)\n4. Generated by an [online evaluator](/langsmith/online-evaluations)\n\nFeedback is stored in a simple format with the following fields:\n\n| Field Name                | Type     | Description                                                                                            |\n| ------------------------- | -------- | ------------------------------------------------------------------------------------------------------ |\n| id                        | UUID     | Unique identifier for the record itself                                                                |\n| created\\_at               | datetime | Timestamp when the record was created                                                                  |\n| modified\\_at              | datetime | Timestamp when the record was last modified                                                            |\n| session\\_id               | UUID     | Unique identifier for the experiment or tracing project the run was a part of                          |\n| run\\_id                   | UUID     | Unique identifier for a specific run within a session                                                  |\n| key                       | string   | A key describing the criteria of the feedback, eg \"correctness\"                                        |\n| score                     | number   | Numerical score associated with the feedback key                                                       |\n| value                     | string   | Reserved for storing a value associated with the score. Useful for categorical feedback.               |\n| comment                   | string   | Any comment or annotation associated with the record. This can be a justification for the score given. |\n| correction                | object   | Reserved for storing correction details, if any                                                        |\n| feedback\\_source          | object   | Object containing information about the feedback source                                                |\n| feedback\\_source.type     | string   | The type of source where the feedback originated, eg \"api\", \"app\", \"evaluator\"                         |\n| feedback\\_source.metadata | object   | Reserved for additional metadata, currently                                                            |\n| feedback\\_source.user\\_id | UUID     | Unique identifier for the user providing feedback                                                      |\n\nHere is an example JSON representation of a feedback record in the above format:\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/feedback-data-format.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>",
  "code_samples": [],
  "headings": [],
  "url": "llms-txt#feedback-data-format",
  "links": []
}