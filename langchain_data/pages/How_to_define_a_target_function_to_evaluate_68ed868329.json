{
  "title": "How to define a target function to evaluate",
  "content": "Source: https://docs.langchain.com/langsmith/define-target-function\n\nThere are three main pieces need to run an evaluation:\n\n1. A [dataset](/langsmith/evaluation-concepts#datasets) of test inputs and expected outputs.\n2. A target function which is what you're evaluating.\n3. [Evaluators](/langsmith/evaluation-concepts#evaluators) that score your target function's outputs.\n\nThis guide shows you how to define the target function depending on the part of your application you are evaluating. See here for [how to create a dataset](/langsmith/manage-datasets-programmatically) and [how to define evaluators](/langsmith/code-evaluator), and here for an [end-to-end example of running an evaluation](/langsmith/evaluate-llm-application).\n\n## Target function signature\n\nIn order to evaluate an application in code, we need a way to run the application. When using `evaluate()` ([Python](https://docs.smith.langchain.com/reference/python/client/langsmith.client.Client#langsmith.client.Client.evaluate)/[TypeScript](https://docs.smith.langchain.com/reference/js/functions/evaluation.evaluate))we'll do this by passing in a *target function* argument. This is a function that takes in a dataset [Example's](/langsmith/evaluation-concepts#examples) inputs and returns the application output as a dict. Within this function we can call our application however we'd like. We can also format the output however we'd like. The key is that any evaluator functions we define should work with the output format we return in our target function.\n\n```python  theme={null}\nfrom langsmith import Client",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Target function signature",
      "id": "target-function-signature"
    }
  ],
  "url": "llms-txt#how-to-define-a-target-function-to-evaluate",
  "links": []
}