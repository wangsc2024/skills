{
  "title": "Guardrails",
  "content": "Source: https://docs.langchain.com/oss/python/langchain/guardrails\n\nImplement safety checks and content filtering for your agents\n\nGuardrails help you build safe, compliant AI applications by validating and filtering content at key points in your agent's execution. They can detect sensitive information, enforce content policies, validate outputs, and prevent unsafe behaviors before they cause problems.\n\nCommon use cases include:\n\n* Preventing PII leakage\n* Detecting and blocking prompt injection attacks\n* Blocking inappropriate or harmful content\n* Enforcing business rules and compliance requirements\n* Validating output quality and accuracy\n\nYou can implement guardrails using [middleware](/oss/python/langchain/middleware) to intercept execution at strategic points - before the agent starts, after it completes, or around model and tool calls.\n\n<div style={{ display: \"flex\", justifyContent: \"center\" }}>\n  <img src=\"https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=eb4404b137edec6f6f0c8ccb8323eaf1\" alt=\"Middleware flow diagram\" className=\"rounded-lg\" data-og-width=\"500\" width=\"500\" data-og-height=\"560\" height=\"560\" data-path=\"oss/images/middleware_final.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=280&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=483413aa87cf93323b0f47c0dd5528e8 280w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=560&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=41b7dd647447978ff776edafe5f42499 560w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=840&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=e9b14e264f68345de08ae76f032c52d4 840w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=1100&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=ec45e1932d1279b1beee4a4b016b473f 1100w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=1650&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=3bca5ebf8aa56632b8a9826f7f112e57 1650w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=2500&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=437f141d1266f08a95f030c2804691d9 2500w\" />\n</div>\n\nGuardrails can be implemented using two complementary approaches:\n\n<CardGroup cols={2}>\n  <Card title=\"Deterministic guardrails\" icon=\"list-check\">\n    Use rule-based logic like regex patterns, keyword matching, or explicit checks. Fast, predictable, and cost-effective, but may miss nuanced violations.\n  </Card>\n\n<Card title=\"Model-based guardrails\" icon=\"brain\">\n    Use LLMs or classifiers to evaluate content with semantic understanding. Catch subtle issues that rules miss, but are slower and more expensive.\n  </Card>\n</CardGroup>\n\nLangChain provides both built-in guardrails (e.g., [PII detection](#pii-detection), [human-in-the-loop](#human-in-the-loop)) and a flexible middleware system for building custom guardrails using either approach.\n\n## Built-in guardrails\n\nLangChain provides built-in middleware for detecting and handling Personally Identifiable Information (PII) in conversations. This middleware can detect common PII types like emails, credit cards, IP addresses, and more.\n\nPII detection middleware is helpful for cases such as health care and financial applications with compliance requirements, customer service agents that need to sanitize logs, and generally any application handling sensitive user data.\n\nThe PII middleware supports multiple strategies for handling detected PII:\n\n| Strategy | Description                             | Example               |\n| -------- | --------------------------------------- | --------------------- |\n| `redact` | Replace with `[REDACTED_{PII_TYPE}]`    | `[REDACTED_EMAIL]`    |\n| `mask`   | Partially obscure (e.g., last 4 digits) | `****-****-****-1234` |\n| `hash`   | Replace with deterministic hash         | `a8f5f167...`         |\n| `block`  | Raise exception when detected           | Error thrown          |\n\n```python  theme={null}\nfrom langchain.agents import create_agent\nfrom langchain.agents.middleware import PIIMiddleware\n\nagent = create_agent(\n    model=\"gpt-4o\",\n    tools=[customer_service_tool, email_tool],\n    middleware=[\n        # Redact emails in user input before sending to model\n        PIIMiddleware(\n            \"email\",\n            strategy=\"redact\",\n            apply_to_input=True,\n        ),\n        # Mask credit cards in user input\n        PIIMiddleware(\n            \"credit_card\",\n            strategy=\"mask\",\n            apply_to_input=True,\n        ),\n        # Block API keys - raise error if detected\n        PIIMiddleware(\n            \"api_key\",\n            detector=r\"sk-[a-zA-Z0-9]{32}\",\n            strategy=\"block\",\n            apply_to_input=True,\n        ),\n    ],\n)",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "Built-in guardrails",
      "id": "built-in-guardrails"
    },
    {
      "level": "h3",
      "text": "PII detection",
      "id": "pii-detection"
    }
  ],
  "url": "llms-txt#guardrails",
  "links": []
}