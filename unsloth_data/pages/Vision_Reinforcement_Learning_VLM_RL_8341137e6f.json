{
  "title": "Vision Reinforcement Learning (VLM RL)",
  "content": "Train Vision/multimodal models via GRPO and RL with Unsloth!\n\nUnsloth now supports vision/multimodal RL with [Qwen3-VL](https://docs.unsloth.ai/models/qwen3-vl-how-to-run-and-fine-tune), [Gemma 3](https://docs.unsloth.ai/models/gemma-3-how-to-run-and-fine-tune) and more. Due to Unsloth's unique [weight sharing](https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide/..#what-unsloth-offers-for-rl) and custom kernels, Unsloth makes VLM RL **1.5–2× faster,** uses **90% less VRAM**, and enables **15× longer context** lengths than FA2 setups, with no accuracy loss. This update also introduces Qwen's [GSPO](#gspo-rl) algorithm.\n\nUnsloth can train Qwen3-VL-8B with GSPO/GRPO on a free Colab T4 GPU. Other VLMs work too, but may need larger GPUs. Gemma requires newer GPUs than T4 because vLLM [restricts to Bfloat16](https://docs.unsloth.ai/models/gemma-3-how-to-run-and-fine-tune#unsloth-fine-tuning-fixes), thus we recommend NVIDIA L4 on Colab. Our notebooks solve numerical math problems involving images and diagrams:\n\n* **Qwen-3 VL-8B** (vLLM inference)**:** [Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_VL_\\(8B\\)-Vision-GRPO.ipynb)\n* **Qwen-2.5 VL-7B** (vLLM inference)**:** [Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb) •[ Kaggle](https://www.kaggle.com/notebooks/welcome?src=https://github.com/unslothai/notebooks/blob/main/nb/Kaggle-Qwen2_5_7B_VL_GRPO.ipynb\\&accelerator=nvidiaTeslaT4)\n* **Gemma-3-4B** (Unsloth inference): [Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_\\(4B\\)-Vision-GRPO.ipynb)\n\nWe have also added vLLM VLM integration into Unsloth natively, so all you have to do to use vLLM inference is enable the `fast_inference=True` flag when initializing the model. Special thanks to [Sinoué GAD](https://github.com/unslothai/unsloth/pull/2752) for providing the [first notebook](https://github.com/GAD-cell/vlm-grpo/blob/main/examples/VLM_GRPO_basic_example.ipynb) that made integrating VLM RL easier!\n\nThis VLM support also integrates our latest update for even more memory efficient + faster RL including our [Standby feature](https://docs.unsloth.ai/get-started/memory-efficient-rl#unsloth-standby), which uniquely limits speed degradation compared to other implementations.\n\n{% hint style=\"info\" %}\nYou can only use `fast_inference` for VLMs supported by vLLM. Some models, like Llama 3.2 Vision thus only can run without vLLM, but they still work in Unsloth.\n{% endhint %}\n\nIt is also important to note, that vLLM does not support LoRA for vision/encoder layers, thus set `finetune_vision_layers = False` when loading a LoRA adapter.\\\nHowever you CAN train the vision layers as well if you use inference via transformers/Unsloth.",
  "code_samples": [
    {
      "code": "os.environ['UNSLOTH_VLLM_STANDBY'] = '1' # To enable memory efficient GRPO with vLLM\nmodel, tokenizer = FastVisionModel.from_pretrained(\n    model_name = \"Qwen/Qwen2.5-VL-7B-Instruct\",\n    max_seq_length = 16384, #Must be this large to fit image in context\n    load_in_4bit = True, # False for LoRA 16bit\n    fast_inference = True, # Enable vLLM fast inference\n    gpu_memory_utilization = 0.8, # Reduce if out of memory\n)",
      "language": "python"
    }
  ],
  "headings": [],
  "url": "llms-txt#vision-reinforcement-learning-(vlm-rl)",
  "links": []
}