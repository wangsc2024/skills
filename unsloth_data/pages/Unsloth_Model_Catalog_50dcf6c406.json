{
  "title": "Unsloth Model Catalog",
  "content": "Unsloth model catalog for all our [Dynamic](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs) GGUF, 4-bit, 16-bit models on Hugging Face.\n\n{% tabs %}\n{% tab title=\"• GGUF + 4-bit\" %} <a href=\"#deepseek-models\" class=\"button secondary\">DeepSeek</a><a href=\"#llama-models\" class=\"button secondary\">Llama</a><a href=\"#gemma-models\" class=\"button secondary\">Gemma</a><a href=\"#qwen-models\" class=\"button secondary\">Qwen</a><a href=\"#mistral-models\" class=\"button secondary\">Mistral</a><a href=\"#phi-models\" class=\"button secondary\">Phi</a>\n\n**GGUFs** let you run models in tools like Ollama, Open WebUI, and llama.cpp.\\\n**Instruct (4-bit)** safetensors can be used for inference or fine-tuning.\n\n#### New & recommended models:\n\n| Model                                                                                | Variant            | GGUF                                                                                                                                                            | Instruct (4-bit)                                                                                                                                                                       |\n| ------------------------------------------------------------------------------------ | ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [**gpt-oss**](https://docs.unsloth.ai/models/gpt-oss-how-to-run-and-fine-tune)       | 120B               | [link](https://huggingface.co/unsloth/gpt-oss-120b-GGUF)                                                                                                        | [link](https://huggingface.co/unsloth/gpt-oss-120b-unsloth-bnb-4bit)                                                                                                                   |\n|                                                                                      | 20B                | [link](https://huggingface.co/unsloth/gpt-oss-20b-GGUF)                                                                                                         | [link](https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit)                                                                                                                    |\n| NVIDIA [Nemotron 3](https://docs.unsloth.ai/models/nemotron-3)                       | 30B                | [link](https://huggingface.co/unsloth/Nemotron-3-Nano-30B-A3B-GGUF)                                                                                             | —                                                                                                                                                                                      |\n| [**Ministral 3**](https://docs.unsloth.ai/models/ministral-3)                        | 3B                 | [Instruct](https://huggingface.co/unsloth/Ministral-3-3B-Instruct-2512-GGUF) • [Reasoning](https://huggingface.co/unsloth/Ministral-3-3B-Reasoning-2512-GGUF)   | [Instruct](https://huggingface.co/unsloth/Ministral-3-14B-Instruct-2512-unsloth-bnb-4bit) • [Reasoning](https://huggingface.co/unsloth/Ministral-3-3B-Reasoning-2512-GGUF)             |\n|                                                                                      | 8B                 | [Instruct](https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-GGUF) • [Reasoning](https://huggingface.co/unsloth/Ministral-3-8B-Reasoning-2512-GGUF)   | [Instruct](https://huggingface.co/unsloth/Ministral-3-8B-Instruct-2512-unsloth-bnb-4bit) • [Reasoning](https://huggingface.co/unsloth/Ministral-3-8B-Reasoning-2512-unsloth-bnb-4bit)  |\n|                                                                                      | 14B                | [Instruct](https://huggingface.co/unsloth/Ministral-3-14B-Instruct-2512-GGUF) • [Reasoning](https://huggingface.co/unsloth/Ministral-3-14B-Reasoning-2512-GGUF) | [Instruct](https://huggingface.co/unsloth/Ministral-3-3B-Instruct-2512-unsloth-bnb-4bit) • [Reasoning](https://huggingface.co/unsloth/Ministral-3-14B-Reasoning-2512-unsloth-bnb-4bit) |\n| [**Devstral 2**](https://docs.unsloth.ai/models/devstral-2)                          | 24B                | [link](https://huggingface.co/unsloth/Devstral-Small-2-24B-Instruct-2512-GGUF)                                                                                  | —                                                                                                                                                                                      |\n|                                                                                      | 123B               | [link](https://huggingface.co/unsloth/Devstral-2-123B-Instruct-2512-GGUF)                                                                                       | —                                                                                                                                                                                      |\n| **Mistral Large 3**                                                                  | 675B               | [link](https://huggingface.co/unsloth/Mistral-Large-3-675B-Instruct-2512-GGUF)                                                                                  | [link](https://huggingface.co/unsloth/Mistral-Large-3-675B-Instruct-2512-NVFP4)                                                                                                        |\n| [**FunctionGemma**](https://docs.unsloth.ai/models/functiongemma)                    | 270M               | [link](https://huggingface.co/unsloth/functiongemma-270m-it-GGUF)                                                                                               | —                                                                                                                                                                                      |\n| FLUX.2                                                                               | dev                | [link](https://huggingface.co/unsloth/FLUX.2-dev-GGUF)                                                                                                          | —                                                                                                                                                                                      |\n| [**Qwen3-Next**](https://docs.unsloth.ai/models/qwen3-next)                          | 80B-A3B-Instruct   | [link](https://huggingface.co/unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF)                                                                                         | [link](https://huggingface.co/unsloth/Qwen3-Next-80B-A3B-Instruct-bnb-4bit/)                                                                                                           |\n|                                                                                      | 80B-A3B-Thinking   | [link](https://huggingface.co/unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF)                                                                                         | —                                                                                                                                                                                      |\n| [**Qwen3-VL**](https://docs.unsloth.ai/models/qwen3-vl-how-to-run-and-fine-tune)     | 2B-Instruct        | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Instruct-GGUF)                                                                                                | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Instruct-unsloth-bnb-4bit)                                                                                                           |\n|                                                                                      | 2B-Thinking        | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Thinking-GGUF)                                                                                                | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Thinking-unsloth-bnb-4bit)                                                                                                           |\n|                                                                                      | 4B-Instruct        | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Instruct-GGUF)                                                                                                | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit)                                                                                                           |\n|                                                                                      | 4B-Thinking        | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Thinking-GGUF)                                                                                                | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Thinking-unsloth-bnb-4bit)                                                                                                           |\n|                                                                                      | 8B-Instruct        | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Instruct-GGUF)                                                                                                | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit)                                                                                                           |\n|                                                                                      | 8B-Thinking        | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Thinking-GGUF)                                                                                                | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Thinking-unsloth-bnb-4bit)                                                                                                           |\n|                                                                                      | 30B-A3B-Instruct   | [link](https://huggingface.co/unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF)                                                                                           | —                                                                                                                                                                                      |\n|                                                                                      | 30B-A3B-Thinking   | [link](https://huggingface.co/unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF)                                                                                           | —                                                                                                                                                                                      |\n|                                                                                      | 32B-Instruct       | [link](https://huggingface.co/unsloth/Qwen3-VL-32B-Instruct-GGUF)                                                                                               | [link](https://huggingface.co/unsloth/Qwen3-VL-32B-Instruct-unsloth-bnb-4bit)                                                                                                          |\n|                                                                                      | 32B-Thinking       | [link](https://huggingface.co/unsloth/Qwen3-VL-32B-Thinking-GGUF)                                                                                               | [link](https://huggingface.co/unsloth/Qwen3-VL-32B-Thinking-unsloth-bnb-4bit)                                                                                                          |\n|                                                                                      | 235B-A22B-Instruct | [link](https://huggingface.co/unsloth/Qwen3-VL-235B-A22B-Instruct-GGUF)                                                                                         | —                                                                                                                                                                                      |\n|                                                                                      | 235B-A22B-Thinking | [link](https://huggingface.co/unsloth/Qwen3-VL-235B-A22B-Thinking-GGUF)                                                                                         | —                                                                                                                                                                                      |\n| [**Qwen3-2507**](https://docs.unsloth.ai/models/qwen3-next)                          | 30B-A3B-Instruct   | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF)                                                                                         | —                                                                                                                                                                                      |\n|                                                                                      | 30B-A3B-Thinking   | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF)                                                                                         | —                                                                                                                                                                                      |\n|                                                                                      | 235B-A22B-Thinking | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF/)                                                                                      | —                                                                                                                                                                                      |\n|                                                                                      | 235B-A22B-Instruct | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/)                                                                                      | —                                                                                                                                                                                      |\n| [**Qwen3-Coder**](https://docs.unsloth.ai/models/qwen3-coder-how-to-run-locally)     | 30B-A3B            | [link](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF)                                                                                        | —                                                                                                                                                                                      |\n|                                                                                      | 480B-A35B          | [link](https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF)                                                                                      | —                                                                                                                                                                                      |\n| [**GLM**](https://docs.unsloth.ai/models/glm-4.6-how-to-run-locally)                 | 4.6V-Flash         | [link](https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF)                                                                                                      | —                                                                                                                                                                                      |\n|                                                                                      | 4.6                | [link](https://huggingface.co/unsloth/GLM-4.6-GGUF)                                                                                                             | —                                                                                                                                                                                      |\n|                                                                                      | 4.5-Air            | [link](https://huggingface.co/unsloth/GLM-4.5-Air-GGUF)                                                                                                         | —                                                                                                                                                                                      |\n| [**DeepSeek-V3.1**](https://docs.unsloth.ai/models/deepseek-v3.1-how-to-run-locally) | Terminus           | [link](https://huggingface.co/unsloth/DeepSeek-V3.1-Terminus-GGUF)                                                                                              | —                                                                                                                                                                                      |\n|                                                                                      | V3.1               | [link](https://huggingface.co/unsloth/DeepSeek-V3.1-GGUF)                                                                                                       | —                                                                                                                                                                                      |\n| **Granite-4.0**                                                                      | H-Small            | [link](https://huggingface.co/unsloth/granite-4.0-h-small-GGUF)                                                                                                 | [link](https://huggingface.co/unsloth/granite-4.0-h-small-unsloth-bnb-4bit)                                                                                                            |\n| **Kimi-K2**                                                                          | Thinking           | [link](https://huggingface.co/unsloth/Kimi-K2-Thinking-GGUF)                                                                                                    | —                                                                                                                                                                                      |\n|                                                                                      | 0905               | [link](https://huggingface.co/unsloth/Kimi-K2-Instruct-0905-GGUF)                                                                                               | —                                                                                                                                                                                      |\n| **Gemma 3n**                                                                         | E2B                | [link](https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF)                                                                                                     | [link](https://huggingface.co/unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit)                                                                                                                |\n|                                                                                      | E4B                | [link](https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF)                                                                                                     | [link](https://huggingface.co/unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit)                                                                                                                |\n| **DeepSeek-R1-0528**                                                                 | R1-0528-Qwen3-8B   | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF)                                                                                           | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-unsloth-bnb-4bit)                                                                                                      |\n|                                                                                      | R1-0528            | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF)                                                                                                    | —                                                                                                                                                                                      |\n\n#### DeepSeek models:\n\n| Model             | Variant                | GGUF                                                                      | Instruct (4-bit)                                                                      |\n| ----------------- | ---------------------- | ------------------------------------------------------------------------- | ------------------------------------------------------------------------------------- |\n| **DeepSeek-V3.1** | Terminus               | [link](https://huggingface.co/unsloth/DeepSeek-V3.1-Terminus-GGUF)        |                                                                                       |\n|                   | V3.1                   | [link](https://huggingface.co/unsloth/DeepSeek-V3.1-GGUF)                 |                                                                                       |\n| **DeepSeek-V3**   | V3-0324                | [link](https://huggingface.co/unsloth/DeepSeek-V3-0324-GGUF)              | —                                                                                     |\n|                   | V3                     | [link](https://huggingface.co/unsloth/DeepSeek-V3-GGUF)                   | —                                                                                     |\n| **DeepSeek-R1**   | R1-0528                | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-GGUF)              | —                                                                                     |\n|                   | R1-0528-Qwen3-8B       | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF)     | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-unsloth-bnb-4bit)     |\n|                   | R1                     | [link](https://huggingface.co/unsloth/DeepSeek-R1-GGUF)                   | —                                                                                     |\n|                   | R1 Zero                | [link](https://huggingface.co/unsloth/DeepSeek-R1-Zero-GGUF)              | —                                                                                     |\n|                   | Distill Llama 3 8 B    | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF)  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit)  |\n|                   | Distill Llama 3.3 70 B | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF) | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-bnb-4bit)         |\n|                   | Distill Qwen 2.5 1.5 B | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF) | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit) |\n|                   | Distill Qwen 2.5 7 B   | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF)   | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit)   |\n|                   | Distill Qwen 2.5 14 B  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-14B-GGUF)  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit)  |\n|                   | Distill Qwen 2.5 32 B  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF)  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit)          |\n\n| Model         | Variant             | GGUF                                                                           | Instruct (4-bit)                                                                       |\n| ------------- | ------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------- |\n| **Llama 4**   | Scout 17 B-16 E     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF)     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-unsloth-bnb-4bit) |\n|               | Maverick 17 B-128 E | [link](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct-GGUF) | —                                                                                      |\n| **Llama 3.3** | 70 B                | [link](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF)             | [link](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-bnb-4bit)                 |\n| **Llama 3.2** | 1 B                 | [link](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-GGUF)              | [link](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-bnb-4bit)                  |\n|               | 3 B                 | [link](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF)              | [link](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-bnb-4bit)                  |\n|               | 11 B Vision         | —                                                                              | [link](https://huggingface.co/unsloth/Llama-3.2-11B-Vision-Instruct-unsloth-bnb-4bit)  |\n|               | 90 B Vision         | —                                                                              | [link](https://huggingface.co/unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit)          |\n| **Llama 3.1** | 8 B                 | [link](https://huggingface.co/unsloth/Llama-3.1-8B-Instruct-GGUF)              | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit)             |\n|               | 70 B                | —                                                                              | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-70B-Instruct-bnb-4bit)            |\n|               | 405 B               | —                                                                              | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-405B-Instruct-bnb-4bit)           |\n| **Llama 3**   | 8 B                 | —                                                                              | [link](https://huggingface.co/unsloth/llama-3-8b-Instruct-bnb-4bit)                    |\n|               | 70 B                | —                                                                              | [link](https://huggingface.co/unsloth/llama-3-70b-bnb-4bit)                            |\n| **Llama 2**   | 7 B                 | —                                                                              | [link](https://huggingface.co/unsloth/llama-2-7b-chat-bnb-4bit)                        |\n|               | 13 B                | —                                                                              | [link](https://huggingface.co/unsloth/llama-2-13b-bnb-4bit)                            |\n| **CodeLlama** | 7 B                 | —                                                                              | [link](https://huggingface.co/unsloth/codellama-7b-bnb-4bit)                           |\n|               | 13 B                | —                                                                              | [link](https://huggingface.co/unsloth/codellama-13b-bnb-4bit)                          |\n|               | 34 B                | —                                                                              | [link](https://huggingface.co/unsloth/codellama-34b-bnb-4bit)                          |\n\n| Model             | Variant       | GGUF                                                              | Instruct (4-bit)                                                             |\n| ----------------- | ------------- | ----------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n| **FunctionGemma** | 270M          | [link](https://huggingface.co/unsloth/functiongemma-270m-it-GGUF) | —                                                                            |\n| **Gemma 3n**      | E2B           | ​[link](https://huggingface.co/unsloth/gemma-3n-E2B-it-GGUF)      | [link](https://huggingface.co/unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit)      |\n|                   | E4B           | [link](https://huggingface.co/unsloth/gemma-3n-E4B-it-GGUF)       | [link](https://huggingface.co/unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit)      |\n| **Gemma 3**       | 270M          | [link](https://huggingface.co/unsloth/gemma-3-270m-it-GGUF)       | [link](https://huggingface.co/unsloth/gemma-3-270m-it)                       |\n|                   | 1 B           | [link](https://huggingface.co/unsloth/gemma-3-1b-it-GGUF)         | [link](https://huggingface.co/unsloth/gemma-3-1b-it-unsloth-bnb-4bit)        |\n|                   | 4 B           | [link](https://huggingface.co/unsloth/gemma-3-4b-it-GGUF)         | [link](https://huggingface.co/unsloth/gemma-3-4b-it-unsloth-bnb-4bit)        |\n|                   | 12 B          | [link](https://huggingface.co/unsloth/gemma-3-12b-it-GGUF)        | [link](https://huggingface.co/unsloth/gemma-3-12b-it-unsloth-bnb-4bit)       |\n|                   | 27 B          | [link](https://huggingface.co/unsloth/gemma-3-27b-it-GGUF)        | [link](https://huggingface.co/unsloth/gemma-3-27b-it-unsloth-bnb-4bit)       |\n| **MedGemma**      | 4 B (vision)  | [link](https://huggingface.co/unsloth/medgemma-4b-it-GGUF)        | [link](https://huggingface.co/unsloth/medgemma-4b-it-unsloth-bnb-4bit)       |\n|                   | 27 B (vision) | [link](https://huggingface.co/unsloth/medgemma-27b-it-GGUF)       | [link](https://huggingface.co/unsloth/medgemma-27b-text-it-unsloth-bnb-4bit) |\n| **Gemma 2**       | 2 B           | [link](https://huggingface.co/unsloth/gemma-2-it-GGUF)            | [link](https://huggingface.co/unsloth/gemma-2-2b-it-bnb-4bit)                |\n|                   | 9 B           | —                                                                 | [link](https://huggingface.co/unsloth/gemma-2-9b-it-bnb-4bit)                |\n|                   | 27 B          | —                                                                 | [link](https://huggingface.co/unsloth/gemma-2-27b-it-bnb-4bit)               |\n\n| Model                                                                            | Variant            | GGUF                                                                         | Instruct (4-bit)                                                                |\n| -------------------------------------------------------------------------------- | ------------------ | ---------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |\n| [**Qwen3-VL**](https://docs.unsloth.ai/models/qwen3-vl-how-to-run-and-fine-tune) | 2B-Instruct        | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Instruct-GGUF)             | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Instruct-unsloth-bnb-4bit)    |\n|                                                                                  | 2B-Thinking        | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Thinking-GGUF)             | [link](https://huggingface.co/unsloth/Qwen3-VL-2B-Thinking-unsloth-bnb-4bit)    |\n|                                                                                  | 4B-Instruct        | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Instruct-GGUF)             | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Instruct-unsloth-bnb-4bit)    |\n|                                                                                  | 4B-Thinking        | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Thinking-GGUF)             | [link](https://huggingface.co/unsloth/Qwen3-VL-4B-Thinking-unsloth-bnb-4bit)    |\n|                                                                                  | 8B-Instruct        | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Instruct-GGUF)             | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit)    |\n|                                                                                  | 8B-Thinking        | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Thinking-GGUF)             | [link](https://huggingface.co/unsloth/Qwen3-VL-8B-Thinking-unsloth-bnb-4bit)    |\n| **Qwen3-Coder**                                                                  | 30B-A3B            | [link](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF)     | —                                                                               |\n|                                                                                  | 480B-A35B          | [link](https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-GGUF)   | —                                                                               |\n| [**Qwen3-2507**](https://docs.unsloth.ai/models/qwen3-next)                      | 30B-A3B-Instruct   | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF)      | —                                                                               |\n|                                                                                  | 30B-A3B-Thinking   | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF)      | —                                                                               |\n|                                                                                  | 235B-A22B-Thinking | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF/)   | —                                                                               |\n|                                                                                  | 235B-A22B-Instruct | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF/)   | —                                                                               |\n| **Qwen 3**                                                                       | 0.6 B              | [link](https://huggingface.co/unsloth/Qwen3-0.6B-GGUF)                       | [link](https://huggingface.co/unsloth/Qwen3-0.6B-unsloth-bnb-4bit)              |\n|                                                                                  | 1.7 B              | [link](https://huggingface.co/unsloth/Qwen3-1.7B-GGUF)                       | [link](https://huggingface.co/unsloth/Qwen3-1.7B-unsloth-bnb-4bit)              |\n|                                                                                  | 4 B                | [link](https://huggingface.co/unsloth/Qwen3-4B-GGUF)                         | [link](https://huggingface.co/unsloth/Qwen3-4B-unsloth-bnb-4bit)                |\n|                                                                                  | 8 B                | [link](https://huggingface.co/unsloth/Qwen3-8B-GGUF)                         | [link](https://huggingface.co/unsloth/Qwen3-8B-unsloth-bnb-4bit)                |\n|                                                                                  | 14 B               | [link](https://huggingface.co/unsloth/Qwen3-14B-GGUF)                        | [link](https://huggingface.co/unsloth/Qwen3-14B-unsloth-bnb-4bit)               |\n|                                                                                  | 30 B-A3B           | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-GGUF)                    | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-bnb-4bit)                   |\n|                                                                                  | 32 B               | [link](https://huggingface.co/unsloth/Qwen3-32B-GGUF)                        | [link](https://huggingface.co/unsloth/Qwen3-32B-unsloth-bnb-4bit)               |\n|                                                                                  | 235 B-A22B         | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B-GGUF)                  | —                                                                               |\n| **Qwen 2.5 Omni**                                                                | 3 B                | [link](https://huggingface.co/unsloth/Qwen2.5-Omni-3B-GGUF)                  | —                                                                               |\n|                                                                                  | 7 B                | [link](https://huggingface.co/unsloth/Qwen2.5-Omni-7B-GGUF)                  | —                                                                               |\n| **Qwen 2.5 VL**                                                                  | 3 B                | [link](https://huggingface.co/unsloth/Qwen2.5-VL-3B-Instruct-GGUF)           | [link](https://huggingface.co/unsloth/Qwen2.5-VL-3B-Instruct-unsloth-bnb-4bit)  |\n|                                                                                  | 7 B                | [link](https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF)           | [link](https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit)  |\n|                                                                                  | 32 B               | [link](https://huggingface.co/unsloth/Qwen2.5-VL-32B-Instruct-GGUF)          | [link](https://huggingface.co/unsloth/Qwen2.5-VL-32B-Instruct-unsloth-bnb-4bit) |\n|                                                                                  | 72 B               | [link](https://huggingface.co/unsloth/Qwen2.5-VL-72B-Instruct-GGUF)          | [link](https://huggingface.co/unsloth/Qwen2.5-VL-72B-Instruct-unsloth-bnb-4bit) |\n| **Qwen 2.5**                                                                     | 0.5 B              | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct-bnb-4bit)           |\n|                                                                                  | 1.5 B              | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-1.5B-Instruct-bnb-4bit)           |\n|                                                                                  | 3 B                | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-3B-Instruct-bnb-4bit)             |\n|                                                                                  | 7 B                | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-7B-Instruct-bnb-4bit)             |\n|                                                                                  | 14 B               | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-14B-Instruct-bnb-4bit)            |\n|                                                                                  | 32 B               | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-32B-Instruct-bnb-4bit)            |\n|                                                                                  | 72 B               | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2.5-72B-Instruct-bnb-4bit)            |\n| **Qwen 2.5 Coder (128 K)**                                                       | 0.5 B              | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-0.5B-Instruct-128K-GGUF) | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-0.5B-Instruct-bnb-4bit)     |\n|                                                                                  | 1.5 B              | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-1.5B-Instruct-128K-GGUF) | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-1.5B-Instruct-bnb-4bit)     |\n|                                                                                  | 3 B                | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-3B-Instruct-128K-GGUF)   | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-3B-Instruct-bnb-4bit)       |\n|                                                                                  | 7 B                | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-7B-Instruct-128K-GGUF)   | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-7B-Instruct-bnb-4bit)       |\n|                                                                                  | 14 B               | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-14B-Instruct-128K-GGUF)  | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit)      |\n|                                                                                  | 32 B               | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-32B-Instruct-128K-GGUF)  | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-32B-Instruct-bnb-4bit)      |\n| **QwQ**                                                                          | 32 B               | [link](https://huggingface.co/unsloth/QwQ-32B-GGUF)                          | [link](https://huggingface.co/unsloth/QwQ-32B-unsloth-bnb-4bit)                 |\n| **QVQ (preview)**                                                                | 72 B               | —                                                                            | [link](https://huggingface.co/unsloth/QVQ-72B-Preview-bnb-4bit)                 |\n| **Qwen 2 (chat)**                                                                | 1.5 B              | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2-1.5B-Instruct-bnb-4bit)             |\n|                                                                                  | 7 B                | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2-7B-Instruct-bnb-4bit)               |\n|                                                                                  | 72 B               | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2-72B-Instruct-bnb-4bit)              |\n| **Qwen 2 VL**                                                                    | 2 B                | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2-VL-2B-Instruct-unsloth-bnb-4bit)    |\n|                                                                                  | 7 B                | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2-VL-7B-Instruct-unsloth-bnb-4bit)    |\n|                                                                                  | 72 B               | —                                                                            | [link](https://huggingface.co/unsloth/Qwen2-VL-72B-Instruct-bnb-4bit)           |\n\n| Model             | Variant           | GGUF                                                                            | Instruct (4-bit)                                                                            |\n| ----------------- | ----------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **Magistral**     | Small (2506)      | [link](https://huggingface.co/unsloth/Magistral-Small-2506-GGUF)                | [link](https://huggingface.co/unsloth/Magistral-Small-2506-unsloth-bnb-4bit)                |\n|                   | Small (2509)      | [link](https://huggingface.co/unsloth/Magistral-Small-2509-GGUF)                | [link](https://huggingface.co/unsloth/Magistral-Small-2509-unsloth-bnb-4bit)                |\n|                   | Small (2507)      | [link](https://huggingface.co/unsloth/Magistral-Small-2507-GGUF)                | [link](https://huggingface.co/unsloth/Magistral-Small-2507-unsloth-bnb-4bit)                |\n| **Mistral Small** | 3.2-24 B (2506)   | [link](https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF) | [link](https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-unsloth-bnb-4bit) |\n|                   | 3.1-24 B (2503)   | [link](https://huggingface.co/unsloth/Mistral-Small-3.1-24B-Instruct-2503-GGUF) | [link](https://huggingface.co/unsloth/Mistral-Small-3.1-24B-Instruct-2503-unsloth-bnb-4bit) |\n|                   | 3-24 B (2501)     | [link](https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501-GGUF)     | [link](https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501-unsloth-bnb-4bit)     |\n|                   | 2409-22 B         | —                                                                               | [link](https://huggingface.co/unsloth/Mistral-Small-Instruct-2409-bnb-4bit)                 |\n| **Devstral**      | Small-24 B (2507) | [link](https://huggingface.co/unsloth/Devstral-Small-2507-GGUF)                 | [link](https://huggingface.co/unsloth/Devstral-Small-2507-unsloth-bnb-4bit)                 |\n|                   | Small-24 B (2505) | [link](https://huggingface.co/unsloth/Devstral-Small-2505-GGUF)                 | [link](https://huggingface.co/unsloth/Devstral-Small-2505-unsloth-bnb-4bit)                 |\n| **Pixtral**       | 12 B (2409)       | —                                                                               | [link](https://huggingface.co/unsloth/Pixtral-12B-2409-bnb-4bit)                            |\n| **Mistral NeMo**  | 12 B (2407)       | [link](https://huggingface.co/unsloth/Mistral-Nemo-Instruct-2407-GGUF)          | [link](https://huggingface.co/unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit)                  |\n| **Mistral Large** | 2407              | —                                                                               | [link](https://huggingface.co/unsloth/Mistral-Large-Instruct-2407-bnb-4bit)                 |\n| **Mistral 7 B**   | v0.3              | —                                                                               | [link](https://huggingface.co/unsloth/mistral-7b-instruct-v0.3-bnb-4bit)                    |\n|                   | v0.2              | —                                                                               | [link](https://huggingface.co/unsloth/mistral-7b-instruct-v0.2-bnb-4bit)                    |\n| **Mixtral**       | 8 × 7 B           | —                                                                               | [link](https://huggingface.co/unsloth/Mixtral-8x7B-Instruct-v0.1-unsloth-bnb-4bit)          |\n\n| Model       | Variant          | GGUF                                                             | Instruct (4-bit)                                                             |\n| ----------- | ---------------- | ---------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n| **Phi-4**   | Reasoning-plus   | [link](https://huggingface.co/unsloth/Phi-4-reasoning-plus-GGUF) | [link](https://huggingface.co/unsloth/Phi-4-reasoning-plus-unsloth-bnb-4bit) |\n|             | Reasoning        | [link](https://huggingface.co/unsloth/Phi-4-reasoning-GGUF)      | [link](https://huggingface.co/unsloth/phi-4-reasoning-unsloth-bnb-4bit)      |\n|             | Mini-Reasoning   | [link](https://huggingface.co/unsloth/Phi-4-mini-reasoning-GGUF) | [link](https://huggingface.co/unsloth/Phi-4-mini-reasoning-unsloth-bnb-4bit) |\n|             | Phi-4 (instruct) | [link](https://huggingface.co/unsloth/phi-4-GGUF)                | [link](https://huggingface.co/unsloth/phi-4-unsloth-bnb-4bit)                |\n|             | mini (instruct)  | [link](https://huggingface.co/unsloth/Phi-4-mini-instruct-GGUF)  | [link](https://huggingface.co/unsloth/Phi-4-mini-instruct-unsloth-bnb-4bit)  |\n| **Phi-3.5** | mini             | —                                                                | [link](https://huggingface.co/unsloth/Phi-3.5-mini-instruct-bnb-4bit)        |\n| **Phi-3**   | mini             | —                                                                | [link](https://huggingface.co/unsloth/Phi-3-mini-4k-instruct-bnb-4bit)       |\n|             | medium           | —                                                                | [link](https://huggingface.co/unsloth/Phi-3-medium-4k-instruct-bnb-4bit)     |\n\n#### Other (GLM, Orpheus, Smol, Llava etc.) models:\n\n| Model           | Variant              | GGUF                                                                           | Instruct (4-bit)                                                          |\n| --------------- | -------------------- | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------- |\n| GLM             | 4.5-Air              | [link](https://huggingface.co/unsloth/GLM-4.5-Air-GGUF)                        | —                                                                         |\n|                 | 4.5                  | [4.5](https://huggingface.co/unsloth/GLM-4.5-GGUF)                             | —                                                                         |\n|                 | 4-32B-0414           | [4-32B-0414](https://huggingface.co/unsloth/GLM-4-32B-0414-GGUF)               | —                                                                         |\n| **Grok 2**      | 270B                 | [link](https://huggingface.co/unsloth/grok-2-GGUF)                             | —                                                                         |\n| **Baidu-ERNIE** | 4.5-21B-A3B-Thinking | [link](https://huggingface.co/unsloth/ERNIE-4.5-21B-A3B-Thinking-GGUF)         | —                                                                         |\n| Hunyuan         | A13B                 | [link](https://huggingface.co/unsloth/Hunyuan-A13B-Instruct-GGUF)              | —                                                                         |\n| Orpheus         | 0.1-ft (3B)          | [link](https://app.gitbook.com/o/HpyELzcNe0topgVLGCZY/s/xhOjnexMCB3dmuQFQ2Zq/) | [link](https://huggingface.co/unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit) |\n| **LLava**       | 1.5 (7 B)            | —                                                                              | [link](https://huggingface.co/unsloth/llava-1.5-7b-hf-bnb-4bit)           |\n|                 | 1.6 Mistral (7 B)    | —                                                                              | [link](https://huggingface.co/unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit)  |\n| **TinyLlama**   | Chat                 | —                                                                              | [link](https://huggingface.co/unsloth/tinyllama-chat-bnb-4bit)            |\n| **SmolLM 2**    | 135 M                | [link](https://huggingface.co/unsloth/SmolLM2-135M-Instruct-GGUF)              | [link](https://huggingface.co/unsloth/SmolLM2-135M-Instruct-bnb-4bit)     |\n|                 | 360 M                | [link](https://huggingface.co/unsloth/SmolLM2-360M-Instruct-GGUF)              | [link](https://huggingface.co/unsloth/SmolLM2-360M-Instruct-bnb-4bit)     |\n|                 | 1.7 B                | [link](https://huggingface.co/unsloth/SmolLM2-1.7B-Instruct-GGUF)              | [link](https://huggingface.co/unsloth/SmolLM2-1.7B-Instruct-bnb-4bit)     |\n| **Zephyr-SFT**  | 7 B                  | —                                                                              | [link](https://huggingface.co/unsloth/zephyr-sft-bnb-4bit)                |\n| **Yi**          | 6 B (v1.5)           | —                                                                              | [link](https://huggingface.co/unsloth/Yi-1.5-6B-bnb-4bit)                 |\n|                 | 6 B (v1.0)           | —                                                                              | [link](https://huggingface.co/unsloth/yi-6b-bnb-4bit)                     |\n|                 | 34 B (chat)          | —                                                                              | [link](https://huggingface.co/unsloth/yi-34b-chat-bnb-4bit)               |\n|                 | 34 B (base)          | —                                                                              | [link](https://huggingface.co/unsloth/yi-34b-bnb-4bit)                    |\n| {% endtab %}    |                      |                                                                                |                                                                           |\n\n{% tab title=\"• Instruct 16-bit\" %}\n16-bit and 8-bit Instruct models are used for inference or fine-tuning:\n\n| Model                | Variant                | Instruct (16-bit)                                                          |\n| -------------------- | ---------------------- | -------------------------------------------------------------------------- |\n| **gpt-oss** (new)    | 20b                    | [link](https://huggingface.co/unsloth/gpt-oss-20b)                         |\n|                      | 120b                   | [link](https://huggingface.co/unsloth/gpt-oss-120b)                        |\n| **Gemma 3n**         | E2B                    | [link](https://huggingface.co/unsloth/gemma-3n-E4B-it)                     |\n|                      | E4B                    | [link](https://huggingface.co/unsloth/gemma-3n-E2B-it)                     |\n| **DeepSeek-R1-0528** | R1-0528-Qwen3-8B       | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B)           |\n|                      | R1-0528                | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528)                    |\n| **Mistral**          | Small 3.2 24B (2506)   | [link](https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506) |\n|                      | Small 3.1 24B (2503)   | [link](https://huggingface.co/unsloth/Mistral-Small-3.1-24B-Instruct-2503) |\n|                      | Small 3.0 24B (2501)   | [link](https://huggingface.co/unsloth/Mistral-Small-24B-Instruct-2501)     |\n|                      | Magistral Small (2506) | [link](https://huggingface.co/unsloth/Magistral-Small-2506)                |\n| **Qwen 3**           | 0.6 B                  | [link](https://huggingface.co/unsloth/Qwen3-0.6B)                          |\n|                      | 1.7 B                  | [link](https://huggingface.co/unsloth/Qwen3-1.7B)                          |\n|                      | 4 B                    | [link](https://huggingface.co/unsloth/Qwen3-4B)                            |\n|                      | 8 B                    | [link](https://huggingface.co/unsloth/Qwen3-8B)                            |\n|                      | 14 B                   | [link](https://huggingface.co/unsloth/Qwen3-14B)                           |\n|                      | 30B-A3B                | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B)                       |\n|                      | 32 B                   | [link](https://huggingface.co/unsloth/Qwen3-32B)                           |\n|                      | 235B-A22B              | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B)                     |\n| **Llama 4**          | Scout 17B-16E          | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct)      |\n|                      | Maverick 17B-128E      | [link](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct)  |\n| **Qwen 2.5 Omni**    | 3 B                    | [link](https://huggingface.co/unsloth/Qwen2.5-Omni-3B)                     |\n|                      | 7 B                    | [link](https://huggingface.co/unsloth/Qwen2.5-Omni-7B)                     |\n| **Phi-4**            | Reasoning-plus         | [link](https://huggingface.co/unsloth/Phi-4-reasoning-plus)                |\n|                      | Reasoning              | [link](https://huggingface.co/unsloth/Phi-4-reasoning)                     |\n\n| Model           | Variant               | Instruct (16-bit)                                                    |\n| --------------- | --------------------- | -------------------------------------------------------------------- |\n| **DeepSeek-V3** | V3-0324               | [link](https://huggingface.co/unsloth/DeepSeek-V3-0324)              |\n|                 | V3                    | [link](https://huggingface.co/unsloth/DeepSeek-V3)                   |\n| **DeepSeek-R1** | R1-0528               | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528)              |\n|                 | R1-0528-Qwen3-8B      | [link](https://huggingface.co/unsloth/DeepSeek-R1-0528-Qwen3-8B)     |\n|                 | R1                    | [link](https://huggingface.co/unsloth/DeepSeek-R1)                   |\n|                 | R1 Zero               | [link](https://huggingface.co/unsloth/DeepSeek-R1-Zero)              |\n|                 | Distill Llama 3 8B    | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B)  |\n|                 | Distill Llama 3.3 70B | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B) |\n|                 | Distill Qwen 2.5 1.5B | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B) |\n|                 | Distill Qwen 2.5 7B   | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B)   |\n|                 | Distill Qwen 2.5 14B  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-14B)  |\n|                 | Distill Qwen 2.5 32B  | [link](https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-32B)  |\n\n| Family        | Variant           | Instruct (16-bit)                                                         |\n| ------------- | ----------------- | ------------------------------------------------------------------------- |\n| **Llama 4**   | Scout 17B-16E     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct)     |\n|               | Maverick 17B-128E | [link](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E-Instruct) |\n| **Llama 3.3** | 70 B              | [link](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct)             |\n| **Llama 3.2** | 1 B               | [link](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct)              |\n|               | 3 B               | [link](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct)              |\n|               | 11 B Vision       | [link](https://huggingface.co/unsloth/Llama-3.2-11B-Vision-Instruct)      |\n|               | 90 B Vision       | [link](https://huggingface.co/unsloth/Llama-3.2-90B-Vision-Instruct)      |\n| **Llama 3.1** | 8 B               | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct)         |\n|               | 70 B              | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-70B-Instruct)        |\n|               | 405 B             | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-405B-Instruct)       |\n| **Llama 3**   | 8 B               | [link](https://huggingface.co/unsloth/llama-3-8b-Instruct)                |\n|               | 70 B              | [link](https://huggingface.co/unsloth/llama-3-70b-Instruct)               |\n| **Llama 2**   | 7 B               | [link](https://huggingface.co/unsloth/llama-2-7b-chat)                    |\n\n| Model        | Variant | Instruct (16-bit)                                      |\n| ------------ | ------- | ------------------------------------------------------ |\n| **Gemma 3n** | E2B     | [link](https://huggingface.co/unsloth/gemma-3n-E4B-it) |\n|              | E4B     | [link](https://huggingface.co/unsloth/gemma-3n-E2B-it) |\n| **Gemma 3**  | 1 B     | [link](https://huggingface.co/unsloth/gemma-3-1b-it)   |\n|              | 4 B     | [link](https://huggingface.co/unsloth/gemma-3-4b-it)   |\n|              | 12 B    | [link](https://huggingface.co/unsloth/gemma-3-12b-it)  |\n|              | 27 B    | [link](https://huggingface.co/unsloth/gemma-3-27b-it)  |\n| **Gemma 2**  | 2 B     | [link](https://huggingface.co/unsloth/gemma-2b-it)     |\n|              | 9 B     | [link](https://huggingface.co/unsloth/gemma-9b-it)     |\n|              | 27 B    | [link](https://huggingface.co/unsloth/gemma-27b-it)    |\n\n| Family                   | Variant   | Instruct (16-bit)                                                       |\n| ------------------------ | --------- | ----------------------------------------------------------------------- |\n| **Qwen 3**               | 0.6 B     | [link](https://huggingface.co/unsloth/Qwen3-0.6B)                       |\n|                          | 1.7 B     | [link](https://huggingface.co/unsloth/Qwen3-1.7B)                       |\n|                          | 4 B       | [link](https://huggingface.co/unsloth/Qwen3-4B)                         |\n|                          | 8 B       | [link](https://huggingface.co/unsloth/Qwen3-8B)                         |\n|                          | 14 B      | [link](https://huggingface.co/unsloth/Qwen3-14B)                        |\n|                          | 30B-A3B   | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B)                    |\n|                          | 32 B      | [link](https://huggingface.co/unsloth/Qwen3-32B)                        |\n|                          | 235B-A22B | [link](https://huggingface.co/unsloth/Qwen3-235B-A22B)                  |\n| **Qwen 2.5 Omni**        | 3 B       | [link](https://huggingface.co/unsloth/Qwen2.5-Omni-3B)                  |\n|                          | 7 B       | [link](https://huggingface.co/unsloth/Qwen2.5-Omni-7B)                  |\n| **Qwen 2.5 VL**          | 3 B       | [link](https://huggingface.co/unsloth/Qwen2.5-VL-3B-Instruct)           |\n|                          | 7 B       | [link](https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct)           |\n|                          | 32 B      | [link](https://huggingface.co/unsloth/Qwen2.5-VL-32B-Instruct)          |\n|                          | 72 B      | [link](https://huggingface.co/unsloth/Qwen2.5-VL-72B-Instruct)          |\n| **Qwen 2.5**             | 0.5 B     | [link](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct)            |\n|                          | 1.5 B     | [link](https://huggingface.co/unsloth/Qwen2.5-1.5B-Instruct)            |\n|                          | 3 B       | [link](https://huggingface.co/unsloth/Qwen2.5-3B-Instruct)              |\n|                          | 7 B       | [link](https://huggingface.co/unsloth/Qwen2.5-7B-Instruct)              |\n|                          | 14 B      | [link](https://huggingface.co/unsloth/Qwen2.5-14B-Instruct)             |\n|                          | 32 B      | [link](https://huggingface.co/unsloth/Qwen2.5-32B-Instruct)             |\n|                          | 72 B      | [link](https://huggingface.co/unsloth/Qwen2.5-72B-Instruct)             |\n| **Qwen 2.5 Coder 128 K** | 0.5 B     | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-0.5B-Instruct-128K) |\n|                          | 1.5 B     | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-1.5B-Instruct-128K) |\n|                          | 3 B       | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-3B-Instruct-128K)   |\n|                          | 7 B       | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-7B-Instruct-128K)   |\n|                          | 14 B      | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-14B-Instruct-128K)  |\n|                          | 32 B      | [link](https://huggingface.co/unsloth/Qwen2.5-Coder-32B-Instruct-128K)  |\n| **QwQ**                  | 32 B      | [link](https://huggingface.co/unsloth/QwQ-32B)                          |\n| **QVQ (preview)**        | 72 B      | —                                                                       |\n| **Qwen 2 (Chat)**        | 1.5 B     | [link](https://huggingface.co/unsloth/Qwen2-1.5B-Instruct)              |\n|                          | 7 B       | [link](https://huggingface.co/unsloth/Qwen2-7B-Instruct)                |\n|                          | 72 B      | [link](https://huggingface.co/unsloth/Qwen2-72B-Instruct)               |\n| **Qwen 2 VL**            | 2 B       | [link](https://huggingface.co/unsloth/Qwen2-VL-2B-Instruct)             |\n|                          | 7 B       | [link](https://huggingface.co/unsloth/Qwen2-VL-7B-Instruct)             |\n|                          | 72 B      | [link](https://huggingface.co/unsloth/Qwen2-VL-72B-Instruct)            |\n\n| Model            | Variant        | Instruct (16-bit)                                                  |\n| ---------------- | -------------- | ------------------------------------------------------------------ |\n| **Mistral**      | Small 2409-22B | [link](https://huggingface.co/unsloth/Mistral-Small-Instruct-2409) |\n| **Mistral**      | Large 2407     | [link](https://huggingface.co/unsloth/Mistral-Large-Instruct-2407) |\n| **Mistral**      | 7B v0.3        | [link](https://huggingface.co/unsloth/mistral-7b-instruct-v0.3)    |\n| **Mistral**      | 7B v0.2        | [link](https://huggingface.co/unsloth/mistral-7b-instruct-v0.2)    |\n| **Pixtral**      | 12B 2409       | [link](https://huggingface.co/unsloth/Pixtral-12B-2409)            |\n| **Mixtral**      | 8×7B           | [link](https://huggingface.co/unsloth/Mixtral-8x7B-Instruct-v0.1)  |\n| **Mistral NeMo** | 12B 2407       | [link](https://huggingface.co/unsloth/Mistral-Nemo-Instruct-2407)  |\n| **Devstral**     | Small 2505     | [link](https://huggingface.co/unsloth/Devstral-Small-2505)         |\n\n| Model       | Variant        | Instruct (16-bit)                                               |\n| ----------- | -------------- | --------------------------------------------------------------- |\n| **Phi-4**   | Reasoning-plus | [link](https://huggingface.co/unsloth/Phi-4-reasoning-plus)     |\n|             | Reasoning      | [link](https://huggingface.co/unsloth/Phi-4-reasoning)          |\n|             | Phi-4 (core)   | [link](https://huggingface.co/unsloth/Phi-4)                    |\n|             | Mini-Reasoning | [link](https://huggingface.co/unsloth/Phi-4-mini-reasoning)     |\n|             | Mini           | [link](https://huggingface.co/unsloth/Phi-4-mini)               |\n| **Phi-3.5** | Mini           | [link](https://huggingface.co/unsloth/Phi-3.5-mini-instruct)    |\n| **Phi-3**   | Mini           | [link](https://huggingface.co/unsloth/Phi-3-mini-4k-instruct)   |\n|             | Medium         | [link](https://huggingface.co/unsloth/Phi-3-medium-4k-instruct) |\n\n#### Text-to-Speech (TTS) models:\n\n| Model                  | Instruct (16-bit)                                                |\n| ---------------------- | ---------------------------------------------------------------- |\n| Orpheus-3B (v0.1 ft)   | [link](https://huggingface.co/unsloth/orpheus-3b-0.1-ft)         |\n| Orpheus-3B (v0.1 pt)   | [link](https://huggingface.co/unsloth/orpheus-3b-0.1-pretrained) |\n| Sesame-CSM 1B          | [link](https://huggingface.co/unsloth/csm-1b)                    |\n| Whisper Large V3 (STT) | [link](https://huggingface.co/unsloth/whisper-large-v3)          |\n| Llasa-TTS 1B           | [link](https://huggingface.co/unsloth/Llasa-1B)                  |\n| Spark-TTS 0.5B         | [link](https://huggingface.co/unsloth/Spark-TTS-0.5B)            |\n| Oute-TTS 1B            | [link](https://huggingface.co/unsloth/Llama-OuteTTS-1.0-1B)      |\n| {% endtab %}           |                                                                  |\n\n{% tab title=\"• Base 4 & 16-bit\" %}\nBase models are usually used for fine-tuning purposes:\n\n| Model        | Variant           | Base (16-bit)                                                    | Base (4-bit)                                                                           |\n| ------------ | ----------------- | ---------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n| **Gemma 3n** | E2B               | [link](https://huggingface.co/unsloth/gemma-3n-E2B)              | [link](https://huggingface.co/unsloth/gemma-3n-E2B-unsloth-bnb-4bit)                   |\n|              | E4B               | [link](https://huggingface.co/unsloth/gemma-3n-E4B)              | [link](https://huggingface.co/unsloth/gemma-3n-E4B-unsloth-bnb-4bit)                   |\n| **Qwen 3**   | 0.6 B             | [link](https://huggingface.co/unsloth/Qwen3-0.6B-Base)           | [link](https://huggingface.co/unsloth/Qwen3-0.6B-Base-unsloth-bnb-4bit)                |\n|              | 1.7 B             | [link](https://huggingface.co/unsloth/Qwen3-1.7B-Base)           | [link](https://huggingface.co/unsloth/Qwen3-1.7B-Base-unsloth-bnb-4bit)                |\n|              | 4 B               | [link](https://huggingface.co/unsloth/Qwen3-4B-Base)             | [link](https://huggingface.co/unsloth/Qwen3-4B-Base-unsloth-bnb-4bit)                  |\n|              | 8 B               | [link](https://huggingface.co/unsloth/Qwen3-8B-Base)             | [link](https://huggingface.co/unsloth/Qwen3-8B-Base-unsloth-bnb-4bit)                  |\n|              | 14 B              | [link](https://huggingface.co/unsloth/Qwen3-14B-Base)            | [link](https://huggingface.co/unsloth/Qwen3-14B-Base-unsloth-bnb-4bit)                 |\n|              | 30B-A3B           | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Base)        | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Base-bnb-4bit)                     |\n| **Llama 4**  | Scout 17B 16E     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E)     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct-unsloth-bnb-4bit) |\n|              | Maverick 17B 128E | [link](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E) | —                                                                                      |\n\n#### **Llama models:**\n\n| Model         | Variant           | Base (16-bit)                                                    | Base (4-bit)                                                |\n| ------------- | ----------------- | ---------------------------------------------------------------- | ----------------------------------------------------------- |\n| **Llama 4**   | Scout 17B 16E     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E)     | —                                                           |\n|               | Maverick 17B 128E | [link](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E) | —                                                           |\n| **Llama 3.3** | 70 B              | [link](https://huggingface.co/unsloth/Llama-3.3-70B)             | —                                                           |\n| **Llama 3.2** | 1 B               | [link](https://huggingface.co/unsloth/Llama-3.2-1B)              | —                                                           |\n|               | 3 B               | [link](https://huggingface.co/unsloth/Llama-3.2-3B)              | —                                                           |\n|               | 11 B Vision       | [link](https://huggingface.co/unsloth/Llama-3.2-11B-Vision)      | —                                                           |\n|               | 90 B Vision       | [link](https://huggingface.co/unsloth/Llama-3.2-90B-Vision)      | —                                                           |\n| **Llama 3.1** | 8 B               | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-8B)         | —                                                           |\n|               | 70 B              | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-70B)        | —                                                           |\n| **Llama 3**   | 8 B               | [link](https://huggingface.co/unsloth/llama-3-8b)                | [link](https://huggingface.co/unsloth/llama-3-8b-bnb-4bit)  |\n| **Llama 2**   | 7 B               | [link](https://huggingface.co/unsloth/llama-2-7b)                | [link](https://huggingface.co/unsloth/llama-2-7b-bnb-4bit)  |\n|               | 13 B              | [link](https://huggingface.co/unsloth/llama-2-13b)               | [link](https://huggingface.co/unsloth/llama-2-13b-bnb-4bit) |\n\n#### **Qwen models:**\n\n| Model        | Variant | Base (16-bit)                                             | Base (4-bit)                                                               |\n| ------------ | ------- | --------------------------------------------------------- | -------------------------------------------------------------------------- |\n| **Qwen 3**   | 0.6 B   | [link](https://huggingface.co/unsloth/Qwen3-0.6B-Base)    | [link](https://huggingface.co/unsloth/Qwen3-0.6B-Base-unsloth-bnb-4bit)    |\n|              | 1.7 B   | [link](https://huggingface.co/unsloth/Qwen3-1.7B-Base)    | [link](https://huggingface.co/unsloth/Qwen3-1.7B-Base-unsloth-bnb-4bit)    |\n|              | 4 B     | [link](https://huggingface.co/unsloth/Qwen3-4B-Base)      | [link](https://huggingface.co/unsloth/Qwen3-4B-Base-unsloth-bnb-4bit)      |\n|              | 8 B     | [link](https://huggingface.co/unsloth/Qwen3-8B-Base)      | [link](https://huggingface.co/unsloth/Qwen3-8B-Base-unsloth-bnb-4bit)      |\n|              | 14 B    | [link](https://huggingface.co/unsloth/Qwen3-14B-Base)     | [link](https://huggingface.co/unsloth/Qwen3-14B-Base-unsloth-bnb-4bit)     |\n|              | 30B-A3B | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Base) | [link](https://huggingface.co/unsloth/Qwen3-30B-A3B-Base-unsloth-bnb-4bit) |\n| **Qwen 2.5** | 0.5 B   | [link](https://huggingface.co/unsloth/Qwen2.5-0.5B)       | [link](https://huggingface.co/unsloth/Qwen2.5-0.5B-bnb-4bit)               |\n|              | 1.5 B   | [link](https://huggingface.co/unsloth/Qwen2.5-1.5B)       | [link](https://huggingface.co/unsloth/Qwen2.5-1.5B-bnb-4bit)               |\n|              | 3 B     | [link](https://huggingface.co/unsloth/Qwen2.5-3B)         | [link](https://huggingface.co/unsloth/Qwen2.5-3B-bnb-4bit)                 |\n|              | 7 B     | [link](https://huggingface.co/unsloth/Qwen2.5-7B)         | [link](https://huggingface.co/unsloth/Qwen2.5-7B-bnb-4bit)                 |\n|              | 14 B    | [link](https://huggingface.co/unsloth/Qwen2.5-14B)        | [link](https://huggingface.co/unsloth/Qwen2.5-14B-bnb-4bit)                |\n|              | 32 B    | [link](https://huggingface.co/unsloth/Qwen2.5-32B)        | [link](https://huggingface.co/unsloth/Qwen2.5-32B-bnb-4bit)                |\n|              | 72 B    | [link](https://huggingface.co/unsloth/Qwen2.5-72B)        | [link](https://huggingface.co/unsloth/Qwen2.5-72B-bnb-4bit)                |\n| **Qwen 2**   | 1.5 B   | [link](https://huggingface.co/unsloth/Qwen2-1.5B)         | [link](https://huggingface.co/unsloth/Qwen2-1.5B-bnb-4bit)                 |\n|              | 7 B     | [link](https://huggingface.co/unsloth/Qwen2-7B)           | [link](https://huggingface.co/unsloth/Qwen2-7B-bnb-4bit)                   |\n\n#### **Llama models:**\n\n| Model         | Variant           | Base (16-bit)                                                    | Base (4-bit)                                                |\n| ------------- | ----------------- | ---------------------------------------------------------------- | ----------------------------------------------------------- |\n| **Llama 4**   | Scout 17B 16E     | [link](https://huggingface.co/unsloth/Llama-4-Scout-17B-16E)     | —                                                           |\n|               | Maverick 17B 128E | [link](https://huggingface.co/unsloth/Llama-4-Maverick-17B-128E) | —                                                           |\n| **Llama 3.3** | 70 B              | [link](https://huggingface.co/unsloth/Llama-3.3-70B)             | —                                                           |\n| **Llama 3.2** | 1 B               | [link](https://huggingface.co/unsloth/Llama-3.2-1B)              | —                                                           |\n|               | 3 B               | [link](https://huggingface.co/unsloth/Llama-3.2-3B)              | —                                                           |\n|               | 11 B Vision       | [link](https://huggingface.co/unsloth/Llama-3.2-11B-Vision)      | —                                                           |\n|               | 90 B Vision       | [link](https://huggingface.co/unsloth/Llama-3.2-90B-Vision)      | —                                                           |\n| **Llama 3.1** | 8 B               | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-8B)         | —                                                           |\n|               | 70 B              | [link](https://huggingface.co/unsloth/Meta-Llama-3.1-70B)        | —                                                           |\n| **Llama 3**   | 8 B               | [link](https://huggingface.co/unsloth/llama-3-8b)                | [link](https://huggingface.co/unsloth/llama-3-8b-bnb-4bit)  |\n| **Llama 2**   | 7 B               | [link](https://huggingface.co/unsloth/llama-2-7b)                | [link](https://huggingface.co/unsloth/llama-2-7b-bnb-4bit)  |\n|               | 13 B              | [link](https://huggingface.co/unsloth/llama-2-13b)               | [link](https://huggingface.co/unsloth/llama-2-13b-bnb-4bit) |\n\n#### **Gemma models**\n\n| Model       | Variant | Base (16-bit)                                         | Base (4-bit)                                                           |\n| ----------- | ------- | ----------------------------------------------------- | ---------------------------------------------------------------------- |\n| **Gemma 3** | 1 B     | [link](https://huggingface.co/unsloth/gemma-3-1b-pt)  | [link](https://huggingface.co/unsloth/gemma-3-1b-pt-unsloth-bnb-4bit)  |\n|             | 4 B     | [link](https://huggingface.co/unsloth/gemma-3-4b-pt)  | [link](https://huggingface.co/unsloth/gemma-3-4b-pt-unsloth-bnb-4bit)  |\n|             | 12 B    | [link](https://huggingface.co/unsloth/gemma-3-12b-pt) | [link](https://huggingface.co/unsloth/gemma-3-12b-pt-unsloth-bnb-4bit) |\n|             | 27 B    | [link](https://huggingface.co/unsloth/gemma-3-27b-pt) | [link](https://huggingface.co/unsloth/gemma-3-27b-pt-unsloth-bnb-4bit) |\n| **Gemma 2** | 2 B     | [link](https://huggingface.co/unsloth/gemma-2-2b)     | —                                                                      |\n|             | 9 B     | [link](https://huggingface.co/unsloth/gemma-2-9b)     | —                                                                      |\n|             | 27 B    | [link](https://huggingface.co/unsloth/gemma-2-27b)    | —                                                                      |\n\n#### **Mistral models:**\n\n| Model       | Variant          | Base (16-bit)                                                      | Base (4-bit)                                                    |\n| ----------- | ---------------- | ------------------------------------------------------------------ | --------------------------------------------------------------- |\n| **Mistral** | Small 24B 2501   | [link](https://huggingface.co/unsloth/Mistral-Small-24B-Base-2501) | —                                                               |\n|             | NeMo 12B 2407    | [link](https://huggingface.co/unsloth/Mistral-Nemo-Base-2407)      | —                                                               |\n|             | 7B v0.3          | [link](https://huggingface.co/unsloth/mistral-7b-v0.3)             | [link](https://huggingface.co/unsloth/mistral-7b-v0.3-bnb-4bit) |\n|             | 7B v0.2          | [link](https://huggingface.co/unsloth/mistral-7b-v0.2)             | [link](https://huggingface.co/unsloth/mistral-7b-v0.2-bnb-4bit) |\n|             | Pixtral 12B 2409 | [link](https://huggingface.co/unsloth/Pixtral-12B-Base-2409)       | —                                                               |\n\n#### **Other (TTS, TinyLlama) models:**\n\n| Model          | Variant        | Base (16-bit)                                                    | Base (4-bit)                                                                      |\n| -------------- | -------------- | ---------------------------------------------------------------- | --------------------------------------------------------------------------------- |\n| **TinyLlama**  | 1.1 B (Base)   | [link](https://huggingface.co/unsloth/tinyllama)                 | [link](https://huggingface.co/unsloth/tinyllama-bnb-4bit)                         |\n| **Orpheus-3b** | 0.1-pretrained | [link](https://huggingface.co/unsloth/orpheus-3b-0.1-pretrained) | [link](https://huggingface.co/unsloth/orpheus-3b-0.1-pretrained-unsloth-bnb-4bit) |\n| {% endtab %}   |                |                                                                  |                                                                                   |\n\n{% tab title=\"• FP8\" %}\nYou can use our FP8 uploads for training or serving/deployment.\n\nFP8 Dynamic offers slightly faster training and lower VRAM usage than FP8 Block, but with a small trade-off in accuracy.\n\n| Model                 | Variant                                                                                                                                                                                                                                                                                                                                                                                                                                                       | FP8 (Dynamic / Block)                                                                                                                                           |\n| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Llama 3.3**         | 70B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                  | [Dynamic](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-FP8-Block)         |\n| **Llama 3.2**         | 1B Base                                                                                                                                                                                                                                                                                                                                                                                                                                                       | [Dynamic](https://huggingface.co/unsloth/Llama-3.2-1B-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.2-1B-FP8-Block)                             |\n|                       | 1B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [Dynamic](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-FP8-Block)           |\n|                       | 3B Base                                                                                                                                                                                                                                                                                                                                                                                                                                                       | [Dynamic](https://huggingface.co/unsloth/Llama-3.2-3B-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.2-3B-FP8-Block)                             |\n|                       | 3B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [Dynamic](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-FP8-Block)           |\n| **Llama 3.1**         | 8B Base                                                                                                                                                                                                                                                                                                                                                                                                                                                       | [Dynamic](https://huggingface.co/unsloth/Llama-3.1-8B-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.1-8B-FP8-Block)                             |\n|                       | 8B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [Dynamic](https://huggingface.co/unsloth/Llama-3.1-8B-Instruct-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.1-8B-Instruct-FP8-Block)           |\n|                       | 70B Base                                                                                                                                                                                                                                                                                                                                                                                                                                                      | [Dynamic](https://huggingface.co/unsloth/Llama-3.1-70B-FP8-Dynamic) · [Block](https://huggingface.co/unsloth/Llama-3.1-70B-FP8-Block)                           |\n| **Qwen3**             | 0.6B                                                                                                                                                                                                                                                                                                                                                                                                                                                          | [FP8](https://huggingface.co/unsloth/Qwen3-0.6B-FP8)                                                                                                            |\n|                       | 1.7B                                                                                                                                                                                                                                                                                                                                                                                                                                                          | [FP8](https://huggingface.co/unsloth/Qwen3-1.7B-FP8)                                                                                                            |\n|                       | 4B                                                                                                                                                                                                                                                                                                                                                                                                                                                            | [FP8](https://huggingface.co/unsloth/Qwen3-4B-FP8)                                                                                                              |\n|                       | 8B                                                                                                                                                                                                                                                                                                                                                                                                                                                            | [FP8](https://huggingface.co/unsloth/Qwen3-8B-FP8)                                                                                                              |\n|                       | 14B                                                                                                                                                                                                                                                                                                                                                                                                                                                           | [FP8](https://huggingface.co/unsloth/Qwen3-14B-FP8)                                                                                                             |\n|                       | 32B                                                                                                                                                                                                                                                                                                                                                                                                                                                           | [FP8](https://huggingface.co/unsloth/Qwen3-32B-FP8)                                                                                                             |\n|                       | 235B-A22B                                                                                                                                                                                                                                                                                                                                                                                                                                                     | [FP8](https://huggingface.co/unsloth/Qwen3-235B-A22B-FP8)                                                                                                       |\n| **Qwen3 (2507)**      | 4B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [FP8](https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-FP8)                                                                                                |\n|                       | 4B Thinking                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [FP8](https://huggingface.co/unsloth/Qwen3-4B-Thinking-2507-FP8)                                                                                                |\n|                       | 30B-A3B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                              | [FP8](https://huggingface.co/unsloth/Qwen3-30B-A3B-Instruct-2507-FP8)                                                                                           |\n|                       | 30B-A3B Thinking                                                                                                                                                                                                                                                                                                                                                                                                                                              | [FP8](https://huggingface.co/unsloth/Qwen3-30B-A3B-Thinking-2507-FP8)                                                                                           |\n|                       | 235B-A22B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                            | [FP8](https://huggingface.co/unsloth/Qwen3-235B-A22B-Instruct-2507-FP8)                                                                                         |\n|                       | 235B-A22B Thinking                                                                                                                                                                                                                                                                                                                                                                                                                                            | [FP8](https://huggingface.co/unsloth/Qwen3-235B-A22B-Thinking-2507-FP8)                                                                                         |\n| **Qwen3-VL**          | 4B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [FP8](https://huggingface.co/unsloth/Qwen3-VL-4B-Instruct-FP8)                                                                                                  |\n|                       | 4B Thinking                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [FP8](https://huggingface.co/unsloth/Qwen3-VL-4B-Thinking-FP8)                                                                                                  |\n|                       | 8B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [FP8](https://huggingface.co/unsloth/Qwen3-VL-8B-Instruct-FP8)                                                                                                  |\n|                       | 8B Thinking                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [FP8](https://huggingface.co/unsloth/Qwen3-VL-8B-Thinking-FP8)                                                                                                  |\n| **Qwen3-Coder**       | 480B-A35B Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                            | [FP8](https://huggingface.co/unsloth/Qwen3-Coder-480B-A35B-Instruct-FP8)                                                                                        |\n| **Granite 4.0**       | h-tiny                                                                                                                                                                                                                                                                                                                                                                                                                                                        | [FP8 Dynamic](https://huggingface.co/unsloth/granite-4.0-h-tiny-FP8-Dynamic)                                                                                    |\n|                       | h-small                                                                                                                                                                                                                                                                                                                                                                                                                                                       | [FP8 Dynamic](https://huggingface.co/unsloth/granite-4.0-h-small-FP8-Dynamic)                                                                                   |\n| **Magistral Small**   | 2509                                                                                                                                                                                                                                                                                                                                                                                                                                                          | [FP8 Dynamic](https://huggingface.co/unsloth/Magistral-Small-2509-FP8-Dynamic) · [FP8 torchao](https://huggingface.co/unsloth/Magistral-Small-2509-FP8-torchao) |\n| **Mistral Small 3.2** | 24B Instruct-2506                                                                                                                                                                                                                                                                                                                                                                                                                                             | [FP8](https://huggingface.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-FP8)                                                                                   |\n| **Gemma 3**           | <p>270M-it torchao<br>270m — <a href=\"https://huggingface.co/unsloth/gemma-3-270m-it-FP8-Dynamic\">FP8</a><br>1B — <a href=\"https://huggingface.co/unsloth/gemma-3-1b-it-FP8-Dynamic\">FP8</a><br>4B — <a href=\"https://huggingface.co/unsloth/gemma-3-4b-it-FP8-Dynamic\">FP8</a><br>12B — <a href=\"https://huggingface.co/unsloth/gemma-3-12B-it-FP8-Dynamic\">FP8</a><br>27B — <a href=\"https://huggingface.co/unsloth/gemma-3-27b-it-FP8-Dynamic\">FP8</a></p> | [FP8 torchao](https://huggingface.co/unsloth/gemma-3-270m-it-torchao-FP8)                                                                                       |\n| {% endtab %}          |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                                                 |\n| {% endtabs %}         |                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                                                 |",
  "code_samples": [],
  "headings": [],
  "url": "llms-txt#unsloth-model-catalog",
  "links": []
}