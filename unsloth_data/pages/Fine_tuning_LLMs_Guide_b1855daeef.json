{
  "title": "Fine-tuning LLMs Guide",
  "content": "Learn all the basics and best practices of fine-tuning. Beginner-friendly.\n\n## 1. Understand Fine-tuning\n\nFine-tuning an LLM customizes its behavior, enhances + injects knowledge, and optimizes performance for domains/specific tasks. For example:\n\n* **GPT-5** serves as a base model; however, OpenAI fine-tuned it to better comprehend instructions and prompts, leading to the creation of ChatGPT-5 which everyone uses today.\n* ​**DeepSeek-R1-Distill-Llama-8B** is a fine-tuned version of Llama-3.1-8B. DeepSeek utilized data generated by DeepSeek-R1, to fine-tune Llama-3.1-8B. This process, known as distillation (a subcategory of fine-tuning), injects the data into the Llama model to learn reasoning capabilities.\n\nWith [Unsloth](https://github.com/unslothai/unsloth), you can fine-tune for free on Colab, Kaggle, or locally with just 3GB VRAM by using our [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks). By fine-tuning a pre-trained model (e.g. Llama-3.1-8B) on a specialized dataset, you can:\n\n* **Update + Learn New Knowledge**: Inject and learn new domain-specific information.\n* **Customize Behavior**: Adjust the model’s tone, personality, or response style.\n* **Optimize for Tasks**: Improve accuracy and relevance for specific use cases.\n\n**Example usecases**:\n\n* Train LLM to predict if a headline impacts a company positively or negatively.\n* Use historical customer interactions for more accurate and custom responses.\n* Fine-tune LLM on legal texts for contract analysis, case law research, and compliance.\n\nYou can think of a fine-tuned model as a specialized agent designed to do specific tasks more effectively and efficiently. **Fine-tuning can replicate all of RAG's capabilities**, but not vice versa.\n\n#### Fine-tuning misconceptions:\n\nYou may have heard that fine-tuning does not make a model learn new knowledge or RAG performs better than fine-tuning. That is **false**. Read more FAQ + misconceptions [here](https://docs.unsloth.ai/fine-tuning-for-beginners/faq-+-is-fine-tuning-right-for-me#fine-tuning-vs.-rag-whats-the-difference):\n\n{% content-ref url=\"fine-tuning-for-beginners/faq-+-is-fine-tuning-right-for-me\" %}\n[faq-+-is-fine-tuning-right-for-me](https://docs.unsloth.ai/get-started/fine-tuning-for-beginners/faq-+-is-fine-tuning-right-for-me)\n{% endcontent-ref %}\n\n## 2. Choose the Right Model + Method\n\nIf you're a beginner, it is best to start with a small instruct model like Llama 3.1 (8B) and experiment from there. You'll also need to decide between QLoRA and LoRA training:\n\n* **LoRA:** Fine-tunes small, trainable matrices in 16-bit without updating all model weights.\n* **QLoRA:** Combines LoRA with 4-bit quantization to handle very large models with minimal resources.\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-cfc51c261e6d24df3aa967d9b9a482313465cbc1%2Fmodel%20name%20change.png?alt=media\" alt=\"\" width=\"563\"><figcaption></figcaption></figure>\n\nYou can change the model name to whichever model you like by matching it with model's name on Hugging Face e.g. 'unsloth/llama-3.1-8b-unsloth-bnb-4bit'.\n\nWe recommend starting with **Instruct models**, as they allow direct fine-tuning using conversational chat templates (ChatML, ShareGPT etc.) and require less data compared to **Base models** (which uses Alpaca, Vicuna etc). Learn more about the differences between [instruct and base models here](https://docs.unsloth.ai/get-started/what-model-should-i-use#instruct-or-base-model).\n\n* Model names ending in **`unsloth-bnb-4bit`** indicate they are [**Unsloth dynamic 4-bit**](https://unsloth.ai/blog/dynamic-4bit) **quants**. These models consume slightly more VRAM than standard BitsAndBytes 4-bit models but offer significantly higher accuracy.\n* If a model name ends with just **`bnb-4bit`**, without \"unsloth\", it refers to a standard BitsAndBytes 4-bit quantization.\n* Models with **no suffix** are in their original **16-bit or 8-bit formats**. While they are the original models from the official model creators, we sometimes include important fixes - such as chat template or tokenizer fixes. So it's recommended to use our versions when available.\n\nThere are other settings which you can toggle:\n\n* **`max_seq_length = 2048`** – Controls context length. While Llama-3 supports 8192, we recommend 2048 for testing. Unsloth enables 4× longer context fine-tuning.\n* **`dtype = None`** – Defaults to None; use `torch.float16` or `torch.bfloat16` for newer GPUs.\n* **`load_in_4bit = True`** – Enables 4-bit quantization, reducing memory use 4× for fine-tuning. Disabling it enables LoRA 16-bit fine-tuning. You can also enable 16-bit LoRA with `load_in_16bit = True`\n* To enable full fine-tuning (FFT), set `full_finetuning = True`. For 8-bit fine-tuning, set `load_in_8bit = True`.\n* **Note:** Only one training method can be set to `True` at a time.\n\nWe recommend starting with QLoRA, as it is one of the most accessible and effective methods for training models. Our [dynamic 4-bit](https://unsloth.ai/blog/dynamic-4bit) quants, the accuracy loss for QLoRA compared to LoRA is now largely recovered.\n\nYou can also do [Text-to-speech (TTS)](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning), [reasoning (GRPO)](https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide), [vision](https://docs.unsloth.ai/basics/vision-fine-tuning), [reinforcement learning](https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide/reinforcement-learning-dpo-orpo-and-kto) (DPO, ORPO, KTO), [continued pretraining](https://docs.unsloth.ai/basics/continued-pretraining), text completion and other training methodologies with Unsloth.\n\nRead our detailed guide on choosing the right model:\n\n{% content-ref url=\"fine-tuning-llms-guide/what-model-should-i-use\" %}\n[what-model-should-i-use](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/what-model-should-i-use)\n{% endcontent-ref %}\n\nFor LLMs, datasets are collections of data that can be used to train our models. In order to be useful for training, text data needs to be in a format that can be tokenized.\n\n* You will need to create a dataset usually with 2 columns - question and answer. The quality and amount will largely reflect the end result of your fine-tune so it's imperative to get this part right.\n* You can [synthetically generate data](https://docs.unsloth.ai/get-started/datasets-guide#synthetic-data-generation) and structure your dataset (into QA pairs) using ChatGPT or local LLMs.\n* You can also use our new Synthetic Dataset notebook which automatically parses documents (PDFs, videos etc.), generates QA pairs and auto cleans data using local models like Llama 3.2. [Access the notebook here.](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Meta_Synthetic_Data_Llama3_2_\\(3B\\).ipynb)\n* Fine-tuning can learn from an existing repository of documents and continuously expand its knowledge base, but just dumping data alone won’t work as well. For optimal results, curate a well-structured dataset, ideally as question-answer pairs. This enhances learning, understanding, and response accuracy.\n* But, that's not always the case, e.g. if you are fine-tuning a LLM for code, just dumping all your code data can actually enable your model to yield significant performance improvements, even without structured formatting. So it really depends on your use case.\n\n***Read more about creating your dataset:***\n\n{% content-ref url=\"fine-tuning-llms-guide/datasets-guide\" %}\n[datasets-guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/datasets-guide)\n{% endcontent-ref %}\n\nFor most of our notebook examples, we utilize the [Alpaca dataset](https://docs.unsloth.ai/basics/tutorial-how-to-finetune-llama-3-and-use-in-ollama#id-6.-alpaca-dataset) however other notebooks like Vision will use different datasets which may need images in the answer ouput as well.\n\n## 4. Understand Training Hyperparameters\n\nLearn how to choose the right [hyperparameters](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide) using best practices from research and real-world experiments - and understand how each one affects your model's performance.\n\n**For a complete guide on how hyperparameters affect training, see:**\n\n{% content-ref url=\"fine-tuning-llms-guide/lora-hyperparameters-guide\" %}\n[lora-hyperparameters-guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide)\n{% endcontent-ref %}\n\n## 5. Installing + Requirements\n\nWe would recommend beginners to utilise our pre-made [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks) first as it's the easiest way to get started with guided steps. However, if installing locally is a must, you can install and use Unsloth via [docker](https://docs.unsloth.ai/get-started/install-and-update/docker \"mention\") or `pip install unsloth` - just make sure you have all the right requirements necessary. Also depending on the model and quantization you're using, you'll need enough VRAM and resources. See all the details here:\n\n{% content-ref url=\"fine-tuning-for-beginners/unsloth-requirements\" %}\n[unsloth-requirements](https://docs.unsloth.ai/get-started/fine-tuning-for-beginners/unsloth-requirements)\n{% endcontent-ref %}\n\nNext, you'll need to install Unsloth. Unsloth currently only supports Windows and Linux devices. Once you install Unsloth, you can copy and paste our notebooks and use them in your own local environment. We have many installation methods:\n\n{% content-ref url=\"install-and-update\" %}\n[install-and-update](https://docs.unsloth.ai/get-started/install-and-update)\n{% endcontent-ref %}\n\n## 6. Training + Evaluation\n\nOnce you have everything set, it's time to train! If something's not working, remember you can always change hyperparameters, your dataset etc.\n\nYou’ll see a log of numbers during training. This is the training loss, which shows how well the model is learning from your dataset. For many cases, a loss around 0.5 to 1.0 is a good sign, but it depends on your dataset and task. If the loss is not going down, you might need to adjust your settings. If the loss goes to 0, that could mean overfitting, so it's important to check validation too.\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-feb9b0f5763d41cecaec9a3a9cd227ad918f0ca7%2Fimage.png?alt=media\" alt=\"\" width=\"375\"><figcaption><p>The training loss will appear as numbers</p></figcaption></figure>\n\nWe generally recommend keeping the default settings unless you need longer training or larger batch sizes.\n\n* **`per_device_train_batch_size = 2`** – Increase for better GPU utilization but beware of slower training due to padding. Instead, increase `gradient_accumulation_steps` for smoother training.\n* **`gradient_accumulation_steps = 4`** – Simulates a larger batch size without increasing memory usage.\n* **`max_steps = 60`** – Speeds up training. For full runs, replace with `num_train_epochs = 1` (1–3 epochs recommended to avoid overfitting).\n* **`learning_rate = 2e-4`** – Lower for slower but more precise fine-tuning. Try values like `1e-4`, `5e-5`, or `2e-5`.\n\nIn order to evaluate, you could do manually evaluation by just chatting with the model and see if it's to your liking. You can also enable evaluation for Unsloth, but keep in mind it can be time-consuming depending on the dataset size. To speed up evaluation you can: reduce the evaluation dataset size or set `evaluation_steps = 100`.\n\nFor testing, you can also take 20% of your training data and use that for testing. If you already used all of the training data, then you have to manually evaluate it. You can also use automatic eval tools like EleutherAI’s [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness). Keep in mind that automated tools may not perfectly align with your evaluation criteria.\n\n## 7. Running + Saving the model\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-f2d5f23fa62ec89e06bf20fea433f9a1e42a2fe3%2Fimage.png?alt=media\" alt=\"\"><figcaption></figcaption></figure>\n\nNow let's run the model after we completed the training process! You can edit the yellow underlined part! In fact, because we created a multi turn chatbot, we can now also call the model as if it saw some conversations in the past like below:\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-cdf5d779635901dce7793df92531dbf3caf0fb0a%2Fimage%20(47).png?alt=media\" alt=\"\"><figcaption></figcaption></figure>\n\nReminder Unsloth itself provides **2x faster inference** natively as well, so always do not forget to call `FastLanguageModel.for_inference(model)`. If you want the model to output longer responses, set `max_new_tokens = 128` to some larger number like 256 or 1024. Notice you will have to wait longer for the result as well!\n\nFor saving and using your model in desired inference engines like Ollama, vLLM, Open WebUI, we can have more information here:\n\n{% content-ref url=\"../basics/inference-and-deployment\" %}\n[inference-and-deployment](https://docs.unsloth.ai/basics/inference-and-deployment)\n{% endcontent-ref %}\n\nWe can now save the finetuned model as a small 100MB file called a LoRA adapter like below. You can instead push to the Hugging Face hub as well if you want to upload your model! Remember to get a Hugging Face token via: <https://huggingface.co/settings/tokens> and add your token!\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-8c577103f7c4fe883cabaf35c8437307c6501686%2Fimage.png?alt=media\" alt=\"\"><figcaption></figcaption></figure>\n\nAfter saving the model, we can again use Unsloth to run the model itself! Use `FastLanguageModel` again to call it for inference!\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-1a1be852ca551240bdce47cf99e6ccd7d31c1326%2Fimage.png?alt=media\" alt=\"\"><figcaption></figcaption></figure>\n\nYou've successfully fine-tuned a language model and exported it to your desired inference engine with Unsloth!\n\nTo learn more about fine-tuning tips and tricks, head over to our blogs which provide tremendous and educational value: <https://unsloth.ai/blog/>\n\nIf you need any help on fine-tuning, you can also join our Discord server [here](https://discord.gg/unsloth) or [Reddit r/unsloth](https://www.reddit.com/r/unsloth/). Thanks for reading and hopefully this was helpful!\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-69482ba90d417f7bf98dddaf83795cdd3eb20efc%2Fsloth%20sparkling%20square.png?alt=media\" alt=\"\" width=\"188\"><figcaption></figcaption></figure>",
  "code_samples": [],
  "headings": [
    {
      "level": "h2",
      "text": "1. Understand Fine-tuning",
      "id": "1.-understand-fine-tuning"
    },
    {
      "level": "h2",
      "text": "2. Choose the Right Model + Method",
      "id": "2.-choose-the-right-model-+-method"
    },
    {
      "level": "h2",
      "text": "3. Your Dataset",
      "id": "3.-your-dataset"
    },
    {
      "level": "h2",
      "text": "4. Understand Training Hyperparameters",
      "id": "4.-understand-training-hyperparameters"
    },
    {
      "level": "h2",
      "text": "5. Installing + Requirements",
      "id": "5.-installing-+-requirements"
    },
    {
      "level": "h2",
      "text": "6. Training + Evaluation",
      "id": "6.-training-+-evaluation"
    },
    {
      "level": "h3",
      "text": "Evaluation",
      "id": "evaluation"
    },
    {
      "level": "h2",
      "text": "7. Running + Saving the model",
      "id": "7.-running-+-saving-the-model"
    },
    {
      "level": "h3",
      "text": "Saving the model",
      "id": "saving-the-model"
    },
    {
      "level": "h2",
      "text": "8. We're done!",
      "id": "8.-we're-done!"
    }
  ],
  "url": "llms-txt#fine-tuning-llms-guide",
  "links": []
}