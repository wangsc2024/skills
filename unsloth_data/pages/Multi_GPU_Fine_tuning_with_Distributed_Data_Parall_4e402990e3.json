{
  "title": "Multi-GPU Fine-tuning with Distributed Data Parallel (DDP)",
  "content": "Learn how to use the Unsloth CLI to train on multiple GPUs with Distributed Data Parallel (DDP)!\n\nLet‚Äôs assume we have multiple GPUs, and we want to fine-tune a model using all of them! To do so, the most straightforward strategy is to use Distributed Data Parallel (DDP), which creates one copy of the model on each GPU device, feeding each copy distinct samples from the dataset during training and aggregating their contributions to weight updates per optimizer step.\n\nWhy would we want to do this? Well, as we add more GPUs into the training process, we scale the number of samples our models train on per step, making each gradient update more stable and increasing our training throughput dramatically with each added GPU.\n\nHere‚Äôs a step-by-step guide on how to do this using Unsloth‚Äôs command-line interface (CLI)!\n\n**Note:** Unsloth DDP will work with any of your training scripts, not just via our CLI! More details below.\n\n#### Install Unsloth from source\n\nWe‚Äôll clone Unsloth from GitHub and install it. Please consider using a [virtual environment](https://docs.python.org/3/tutorial/venv.html); we like to use `uv venv ‚Äìpython 3.12 && source .venv/bin/activate`, but any virtual environment creation tooling will do.\n\n#### Choose target model and dataset for finetuning\n\nIn this demo, we will fine-tune [Qwen/Qwen3-8B](https://huggingface.co/Qwen/Qwen3-8B) on the [yahma/alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned) chat dataset. This is a Supervised Fine-Tuning (SFT) workload that is commonly used when attempting to adapt a base model to a desired conversational style, or improve the model‚Äôs performance on a downstream task.\n\n### Use the Unsloth CLI!\n\nFirst, let‚Äôs take a look at the help message built-in to the CLI (we‚Äôve abbreviated here with ‚Äú...‚Äù in various places for brevity):\n\n{% code expandable=\"true\" %}\n\nThis should give you a sense of what options are available for you to pass into the CLI for training your model!\n\nFor multi-GPU training (DDP in this case), we will use the [torchrun](https://docs.pytorch.org/docs/stable/elastic/run.html) launcher, which allows you to spin up multiple distributed training processes in single-node or multi-node settings. In our case, we will focus on the single-node (i.e., one machine) case with two H100 GPUs.\n\nLet‚Äôs also check our GPUs‚Äô status by using the `nvidia-smi` command-line tool:\n\n{% code expandable=\"true\" %}\n\nGreat! We have two H100 GPUs, as expected. Both are sitting at 0MiB memory usage as we‚Äôre currently not training anything, or have any model loaded into memory.\n\nTo start your training run, issue a command like the following:\n\n{% code expandable=\"true\" %}",
  "code_samples": [
    {
      "code": "git clone https://github.com/unslothai/unsloth.git\ncd unsloth\npip install .",
      "language": "bash"
    },
    {
      "code": "$ python unsloth-cli.py --help\nusage: unsloth-cli.py [-h] [--model_name MODEL_NAME] [--max_seq_length MAX_SEQ_LENGTH] [--dtype DTYPE]\n                      [--load_in_4bit] [--dataset DATASET] [--r R] [--lora_alpha LORA_ALPHA]\n                      [--lora_dropout LORA_DROPOUT] [--bias BIAS]\n                      [--use_gradient_checkpointing USE_GRADIENT_CHECKPOINTING]\n‚Ä¶\n\nü¶• Fine-tune your llm faster using unsloth!\n\noptions:\n  -h, --help            show this help message and exit\n\nü§ñ Model Options:\n  --model_name MODEL_NAME\n                        Model name to load\n  --max_seq_length MAX_SEQ_LENGTH\n                        Maximum sequence length, default is 2048. We auto support RoPE Scaling\n                        internally!\n‚Ä¶\n\nüß† LoRA Options:\n  These options are used to configure the LoRA model.\n\n  --r R                 Rank for Lora model, default is 16. (common values: 8, 16, 32, 64, 128)\n  --lora_alpha LORA_ALPHA\n                        LoRA alpha parameter, default is 16. (common values: 8, 16, 32, 64, 128)\n‚Ä¶\n\nüéì Training Options:\n  --per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE\n                        Batch size per device during training, default is 2.\n  --per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE\n                        Batch size per device during evaluation, default is 4.\n  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n                        Number of gradient accumulation steps, default is 4.\n‚Ä¶",
      "language": "bash"
    },
    {
      "code": "$ nvidia-smi\nMon Nov 24 12:53:00 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA H100 80GB HBM3          On  |   00000000:04:00.0 Off |                    0 |\n| N/A   32C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |\n|                                         |                        |             Disabled |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA H100 80GB HBM3          On  |   00000000:05:00.0 Off |                    0 |\n| N/A   30C    P0             68W /  700W |       0MiB /  81559MiB |      0%      Default |\n|                                         |                        |             Disabled |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+",
      "language": "bash"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "Use the Unsloth CLI!",
      "id": "use-the-unsloth-cli!"
    }
  ],
  "url": "llms-txt#multi-gpu-fine-tuning-with-distributed-data-parallel-(ddp)",
  "links": []
}