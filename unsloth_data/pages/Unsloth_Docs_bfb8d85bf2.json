{
  "title": "Unsloth Docs",
  "content": "Train your own model with Unsloth, an open-source framework for LLM fine-tuning and reinforcement learning.\n\nAt Unsloth, our mission is to make AI as accurate and accessible as possible. Train, run, evaluate and save gpt-oss, Llama, DeepSeek, TTS, Qwen, Mistral, Gemma LLMs 2x faster with 70% less VRAM.\n\nOur docs will guide you through running & training your own model locally.\n\n<a href=\"fine-tuning-for-beginners\" class=\"button primary\">Get started</a> <a href=\"https://github.com/unslothai/unsloth\" class=\"button secondary\">Our GitHub</a>\n\n<table data-view=\"cards\"><thead><tr><th></th><th></th><th data-hidden data-card-cover data-type=\"image\">Cover image</th><th data-hidden data-card-target data-type=\"content-ref\"></th></tr></thead><tbody><tr><td><strong>New 3x Faster Training</strong></td><td>Introducing our new Unsloth Triton kernels!</td><td><a href=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2FICSa2F6HWtYJgUWiArtd%2F3x%20faster%20training.png?alt=media&#x26;token=2498e2fa-a74e-4298-95eb-55b706f577a3\">3x faster training.png</a></td><td><a href=\"../new/3x-faster-training-packing\">3x-faster-training-packing</a></td></tr><tr><td><strong>Nemotron 3 Nano</strong></td><td>Run &#x26; fine-tune NVIDIA's new reasoning models. </td><td><a href=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2F5AeVpAiKFQAgLpA7caad%2Fnemotron%20nano%203%20promo.png?alt=media&#x26;token=e2f879a3-cf82-4253-8d62-9f0c0ac69375\">nemotron nano 3 promo.png</a></td><td><a href=\"../models/nemotron-3\">nemotron-3</a></td></tr><tr><td><strong>500K Context Fine-tuning</strong></td><td>You can now train with >500K context.</td><td><a href=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2F0dJ0Z6vfIeR4qfLniuEz%2F500k%20context.png?alt=media&#x26;token=ed144b31-4fef-4a5d-8896-632d8e83ef97\">500k context.png</a></td><td><a href=\"../new/500k-context-length-fine-tuning\">500k-context-length-fine-tuning</a></td></tr></tbody></table>\n\n{% columns %}\n{% column width=\"50%\" %}\n{% content-ref url=\"fine-tuning-llms-guide\" %}\n[fine-tuning-llms-guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide)\n{% endcontent-ref %}\n\n{% content-ref url=\"unsloth-notebooks\" %}\n[unsloth-notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks)\n{% endcontent-ref %}\n{% endcolumn %}\n\n{% column width=\"50%\" %}\n{% content-ref url=\"unsloth-model-catalog\" %}\n[unsloth-model-catalog](https://docs.unsloth.ai/get-started/unsloth-model-catalog)\n{% endcontent-ref %}\n\n{% content-ref url=\"../models/tutorials-how-to-fine-tune-and-run-llms\" %}\n[tutorials-how-to-fine-tune-and-run-llms](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n{% endcontent-ref %}\n{% endcolumn %}\n{% endcolumns %}\n\n* Unsloth streamlines local training, evaluation, saving, and deployment with Ollama, llama.cpp, and vLLM.\n* We directly collab with teams behind [gpt-oss](https://docs.unsloth.ai/new/gpt-oss-how-to-run-and-fine-tune#unsloth-fixes-for-gpt-oss), [Qwen3](https://www.reddit.com/r/LocalLLaMA/comments/1kaodxu/qwen3_unsloth_dynamic_ggufs_128k_context_bug_fixes/), [Llama 4](https://github.com/ggml-org/llama.cpp/pull/12889), [Mistral](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms/devstral-how-to-run-and-fine-tune), [Gemma 1‚Äì3](https://news.ycombinator.com/item?id=39671146) and [Phi-4](https://unsloth.ai/blog/phi4), where we‚Äôve **fixed critical bugs** that greatly improved model accuracy.\n* Unsloth is the only training framework to support all models: [vision](https://docs.unsloth.ai/basics/vision-fine-tuning), [TTS](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning), BERT, [RL](https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide) while remaining highly customizable with flexible chat templates, dataset formatting and ready-to-use notebooks.\n\n* Supports **full-finetuning**, pretraining, 4-bit, 16-bit and **8-bit** training.\n* Most efficient reinforcement learning (RL) library, using 80% less VRAM. Supports GRPO, GSPO etc.\n* Supports **all models**: [TTS,](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning) multimodal, [BERT](https://docs.unsloth.ai/get-started/unsloth-notebooks#other-important-notebooks) and more. Any model that works in transformers works in Unsloth.\n* **0% loss in accuracy** - no quantization or approximation methods - all exact.\n* [MultiGPU](https://docs.unsloth.ai/basics/multi-gpu-training-with-unsloth) works already but a much better version is coming!\n* Unsloth supports Linux, [Windows](https://docs.unsloth.ai/get-started/install-and-update/windows-installation), Colab, Kaggle, **NVIDIA** and [**AMD**](https://docs.unsloth.ai/new/fine-tuning-llms-on-amd-gpus-with-unsloth) & **Intel**. See:\n\n{% content-ref url=\"fine-tuning-for-beginners/unsloth-requirements\" %}\n[unsloth-requirements](https://docs.unsloth.ai/get-started/fine-tuning-for-beginners/unsloth-requirements)\n{% endcontent-ref %}\n\n**Install locally with pip (recommended)** for Linux or WSL devices:\n\nUse our official **Docker image**: `unsloth/unsloth`. Read our [**Docker guide**](https://docs.unsloth.ai/get-started/install-and-update/docker)**.**\n\nFor Windows install instructions, see [here](https://docs.unsloth.ai/get-started/install-and-update/windows-installation).\n\n{% content-ref url=\"install-and-update\" %}\n[install-and-update](https://docs.unsloth.ai/get-started/install-and-update)\n{% endcontent-ref %}\n\n### What is Fine-tuning and RL? Why?\n\n[**Fine-tuning** an LLM](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide) customizes its behavior, enhances domain knowledge, and optimizes performance for specific tasks. By fine-tuning a pre-trained model (e.g. Llama-3.1-8B) on a dataset, you can:\n\n* **Update Knowledge**: Introduce new domain-specific information.\n* **Customize Behavior**: Adjust the model‚Äôs tone, personality, or response style.\n* **Optimize for Tasks**: Improve accuracy and relevance for specific use cases.\n\n[**Reinforcement Learning (RL)**](https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide) is where an \"agent\" learns to make decisions by interacting with an environment and receiving **feedback** in the form of **rewards** or **penalties**.\n\n* **Action:** What the model generates (e.g. a sentence).\n* **Reward:** A signal indicating how good or bad the model's action was (e.g. did the response follow instructions? was it helpful?).\n* **Environment:** The scenario or task the model is working on (e.g. answering a user‚Äôs question).\n\n**Example use-cases of fine-tuning or RL:**\n\n* Train LLM to predict if a headline impacts a company positively or negatively.\n* Use historical customer interactions for more accurate and custom responses.\n* Train LLM on legal texts for contract analysis, case law research, and compliance.\n\nYou can think of a fine-tuned model as a specialized agent designed to do specific tasks more effectively and efficiently. **Fine-tuning can replicate all of RAG's capabilities**, but not vice versa.\n\n{% content-ref url=\"fine-tuning-for-beginners/faq-+-is-fine-tuning-right-for-me\" %}\n[faq-+-is-fine-tuning-right-for-me](https://docs.unsloth.ai/get-started/fine-tuning-for-beginners/faq-+-is-fine-tuning-right-for-me)\n{% endcontent-ref %}\n\n{% content-ref url=\"reinforcement-learning-rl-guide\" %}\n[reinforcement-learning-rl-guide](https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide)\n{% endcontent-ref %}\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-134302f2507d4313b9575917c9a43b0a0028856c%2Flarge%20sloth%20wave.png?alt=media\" alt=\"\" width=\"188\"><figcaption></figcaption></figure>",
  "code_samples": [
    {
      "code": "pip install unsloth",
      "language": "bash"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "ü¶• Why Unsloth?",
      "id": "ü¶•-why-unsloth?"
    },
    {
      "level": "h3",
      "text": "‚≠ê Key Features",
      "id": "‚≠ê-key-features"
    },
    {
      "level": "h3",
      "text": "Quickstart",
      "id": "quickstart"
    },
    {
      "level": "h3",
      "text": "What is Fine-tuning and RL? Why?",
      "id": "what-is-fine-tuning-and-rl?-why?"
    }
  ],
  "url": "llms-txt#unsloth-docs",
  "links": []
}