{
  "title": "AMD",
  "content": "Guide for Fine-tuning LLMs with Unsloth on AMD GPUs.\n\nUnsloth supports AMD Radeon RX, MI300X's (192GB) GPUs and more.\n\n{% stepper %}\n{% step %}\n**Make a new isolated environment (Optional)**\n\nTo not break any system packages, you can make an isolated pip environment. Reminder to check what Python version you have! It might be `pip3`, `pip3.13`, `python3`, `python.3.13` etc.\n\n{% code overflow=\"wrap\" %}\n\n{% endcode %}\n{% endstep %}\n\n{% step %}\n**Install PyTorch**\n\nInstall the latest PyTorch, TorchAO, Xformers from <https://pytorch.org/>\n\n{% code overflow=\"wrap\" %}\n\n{% endcode %}\n{% endstep %}\n\n{% step %}\n**Install Unsloth**\n\nInstall Unsloth's dedicated AMD branch\n\n{% code overflow=\"wrap\" %}\n\n{% endcode %}\n{% endstep %}\n{% endstepper %}\n\nAnd that's it! Try some examples in our [**Unsloth Notebooks**](https://docs.unsloth.ai/get-started/unsloth-notebooks) page!\n\n### :1234:Reinforcement Learning on AMD GPUs\n\nYou can use our :ledger:[gpt-oss RL auto win 2048](https://github.com/unslothai/notebooks/blob/main/nb/gpt_oss_\\(20B\\)_Reinforcement_Learning_2048_Game_BF16.ipynb) example on a MI300X (192GB) GPU. The goal is to play the 2048 game automatically and win it with RL. The LLM (gpt-oss 20b) auto devises a strategy to win the 2048 game, and we calculate a high reward for winning strategies, and low rewards for failing strategies.\n\n{% columns %}\n{% column %}\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-2bc5a2e25a51781fd945ab9e87e73821ed4eb6c9%2Fimage.png?alt=media\" alt=\"\"><figcaption></figcaption></figure>\n{% endcolumn %}\n\n{% column %}\nThe reward over time is increasing after around 300 steps or so!\n\nThe goal for RL is to maximize the average reward to win the 2048 game.\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-8d7ea897fd57156a796e4f74aa2e3b60afe9d405%2F2048%20Auto%20Win%20Game%20Reward.png?alt=media\" alt=\"\"><figcaption></figcaption></figure>\n{% endcolumn %}\n{% endcolumns %}\n\nWe used an AMD MI300X machine (192GB) to run the 2048 RL example with Unsloth, and it worked well!\n\n<div><figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-174890aa5f63632ebe6f3f212f1ced0d0e8dc381%2FScreenshot%202025-10-17%20052504.png?alt=media\" alt=\"\"><figcaption></figcaption></figure> <figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-f907ba596705496515fdfb39b49d649697317ca7%2FScreenshot%202025-10-17%20052641.png?alt=media\" alt=\"\"><figcaption></figcaption></figure></div>\n\nYou can also use our :ledger:[automatic kernel gen RL notebook](https://github.com/unslothai/notebooks/blob/main/nb/gpt_oss_\\(20B\\)_GRPO_BF16.ipynb) also with gpt-oss to auto create matrix multiplication kernels in Python. The notebook also devices multiple methods to counteract reward hacking.\n\n{% columns %}\n{% column width=\"50%\" %}\nThe prompt we used to auto create these kernels was:\n\n{% code overflow=\"wrap\" %}\n\npython\ndef matmul(A, B):\n    return ...\n`\n\n{% endcode %}\n{% endcolumn %}\n\n{% column width=\"50%\" %}\nThe RL process learns for example how to apply the Strassen algorithm for faster matrix multiplication inside of Python.\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-ddb993e5d2c986794ede1f2b0d08897469b78506%2Fimage%20(1)%20(1)%20(1)%20(1)%20(1)%20(1).png?alt=media\" alt=\"\" width=\"375\"><figcaption></figcaption></figure>\n{% endcolumn %}\n{% endcolumns %}\n\n### :tools:Troubleshooting\n\n**As of October 2025, bitsandbytes in AMD is under development** - you might get `HSA_STATUS_ERROR_EXCEPTION: An HSAIL operation resulted in a hardware exception` errors. We disabled bitsandbytes internally in Unsloth automatically until a fix is provided for versions `0.48.2.dev0` and above. This means `load_in_4bit = True` will instead use 16bit LoRA. Full finetuning also works via `full_finetuning = True`\n\nTo force 4bit, you need to specify the actual model name like `unsloth/gemma-3-4b-it-unsloth-bnb-4bit` and set `use_exact_model_name = True` as an extra argument within `FastLanguageModel.from_pretrained` etc.\n\nAMD GPUs also need the bitsandbytes `blocksize` to be 128 and not 64 - this also means our pre-quantized models (for example [unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct-bnb-4bit)) from [HuggingFace](https://huggingface.co/unsloth) for now will not work - we auto switch to downloading the full BF16 weights, then quantize on the fly if we detect an AMD GPU.\n\n### :books:AMD Free One-click notebooks\n\nAMD provides one-click notebooks equipped with **free 192GB VRAM MI300X GPUs** through their Dev Cloud. Train large models completely for free (no signup or credit card required):\n\n* [Qwen3 (32B)](https://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb/Qwen3_\\(32B\\)_A100-Reasoning-Conversational.ipynb)\n* [Llama 3.3 (70B)](https://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb/Llama3.3_\\(70B\\)_A100-Conversational.ipynb)\n* [Qwen3 (14B)](http://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb/Qwen3_\\(14B\\)-Reasoning-Conversational.ipynb)\n* [Mistral v0.3 (7B)](http://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_\\(7B\\)-Alpaca.ipynb)\n* [GPT OSS MXFP4 (20B)](http://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb/Kaggle-GPT_OSS_MXFP4_\\(20B\\)-Inference.ipynb) - Inference\n\nYou can use any Unsloth notebook by prepending ***<https://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb>*** in [unsloth-notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks \"mention\") by changing the link from <https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_(270M).ipynb> to <https://oneclickamd.ai/github/unslothai/notebooks/blob/main/nb/Gemma3_(270M).ipynb>\n\n{% columns %}\n{% column width=\"33.33333333333333%\" %}\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2F7NNi4jLKvmZoRnLel9Kg%2Fimage.png?alt=media&#x26;token=0379eda9-569c-4614-afb5-ffec463a7676\" alt=\"\"><figcaption></figcaption></figure>\n{% endcolumn %}\n\n{% column width=\"66.66666666666667%\" %}\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2FRfKS1GAW7BqL9lGNTcxh%2Fimage.png?alt=media&#x26;token=3a8aeb01-62a7-4d55-89a9-98526052e305\" alt=\"\"><figcaption></figcaption></figure>\n{% endcolumn %}\n{% endcolumns %}",
  "code_samples": [
    {
      "code": "apt install python3.10-venv python3.11-venv python3.12-venv python3.13-venv -y\n\npython -m venv unsloth_env\nsource unsloth_env/bin/activate",
      "language": "bash"
    },
    {
      "code": "pip install --upgrade torch==2.8.0 pytorch-triton-rocm torchvision torchaudio torchao==0.13.0 xformers --index-url https://download.pytorch.org/whl/rocm6.4",
      "language": "bash"
    },
    {
      "code": "pip install --no-deps unsloth unsloth-zoo\npip install --no-deps git+https://github.com/unslothai/unsloth-zoo.git\npip install \"unsloth[amd] @ git+https://github.com/unslothai/unsloth\"",
      "language": "bash"
    },
    {
      "code": "Create a new fast matrix multiplication function using only native Python code.\nYou are given a list of list of numbers.\nOutput your new function in backticks using the format below:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": ":1234:Reinforcement Learning on AMD GPUs",
      "id": ":1234:reinforcement-learning-on-amd-gpus"
    },
    {
      "level": "h3",
      "text": ":tools:Troubleshooting",
      "id": ":tools:troubleshooting"
    },
    {
      "level": "h3",
      "text": ":books:AMD Free One-click notebooks",
      "id": ":books:amd-free-one-click-notebooks"
    }
  ],
  "url": "llms-txt#amd",
  "links": []
}