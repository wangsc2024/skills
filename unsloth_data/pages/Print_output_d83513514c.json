{
  "title": "Print output",
  "content": "for output in model_outputs:\n    print(output.outputs[0].text)\npython\nfrom unsloth import FastVisionModel\nimport torch\nfrom transformers import AutoModel\nimport os\nos.environ[\"UNSLOTH_WARN_UNINITIALIZED\"] = '0'\n\nfrom huggingface_hub import snapshot_download\nsnapshot_download(\"unsloth/DeepSeek-OCR\", local_dir = \"deepseek_ocr\")\nmodel, tokenizer = FastVisionModel.from_pretrained(\n    \"./deepseek_ocr\",\n    load_in_4bit = False, # Use 4bit to reduce memory use. False for 16bit LoRA.\n    auto_model = AutoModel,\n    trust_remote_code = True,\n    unsloth_force_compile = True,\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n)\n\nprompt = \"<image>\\nFree OCR. \"\nimage_file = 'your_image.jpg'\noutput_path = 'your/output/dir'\nres = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = False)\n\n============================================================\nBaseline Model Performance\n============================================================\nNumber of samples: 200\nMean CER: 149.07%\nMedian CER: 80.00%\nStd Dev: 310.39%\nMin CER: 0.00%\nMax CER: 3500.00%\n============================================================\n\nBest Predictions (Lowest CER):\n\nSample 5024 (CER: 0.00%)\nReference:  Ú†ÙˆÙ† Ù‡Ø³ØªÛŒ Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯...\nPrediction: Ú†ÙˆÙ† Ù‡Ø³ØªÛŒ Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯...\n\nSample 3517 (CER: 0.00%)\nReference:  ØªÙˆ Ø§ÛŒØ±Ø§Ù† Ù‡ÛŒÚ†ÙˆÙ‚Øª Ø§Ø² Ø§ÛŒÙ†Ù‡Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø´Øª...\nPrediction: ØªÙˆ Ø§ÛŒØ±Ø§Ù† Ù‡ÛŒÚ†ÙˆÙ‚Øª Ø§Ø² Ø§ÛŒÙ†Ù‡Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø´Øª...\n\nSample 9949 (CER: 0.00%)\nReference:  Ú©Ø§Ø´ Ù…ÛŒØ¯ÙˆÙ†Ø³ØªÙ… Ù‡ÛŒÚ†ÛŒ Ø¨ÛŒØ®ÛŒØ§Ù„...\nPrediction: Ú©Ø§Ø´ Ù…ÛŒØ¯ÙˆÙ†Ø³ØªÙ… Ù‡ÛŒÚ†ÛŒ Ø¨ÛŒØ®ÛŒØ§Ù„...\n\nWorst Predictions (Highest CER):\n\nSample 11155 (CER: 3500.00%)\nReference:  Ø®Ø³Ùˆ...\nPrediction: \\[ \\text{CH}_3\\text{CH}_2\\text{CH}_2\\text{CH}_2\\text{CH}_2\\text{CH}_2\\text{CH}_2\\text{CH}_2\\text{CH}...\n\nSample 13366 (CER: 1900.00%)\nReference:  Ù…Ø´Ùˆ...\nPrediction: \\[\\begin{align*}\\underline{\\mathfrak{su}}_0\\end{align*}\\]...\n\nSample 10552 (CER: 1014.29%)\nReference:  Ù‡ÛŒÛŒÛŒÛŒÛŒÚ†...\nPrediction: e\n```\n\n{% column %}\n**DeepSeek-OCR Fine-tuned**\n\nWith 60 steps, we reduced CER from 149.07% to 60.43% (89% CER improvement)\n\n<pre><code><strong>============================================================\n</strong>Fine-tuned Model Performance\n============================================================\nNumber of samples: 200\nMean CER: 60.43%\nMedian CER: 50.00%\nStd Dev: 80.63%\nMin CER: 0.00%\nMax CER: 916.67%\n============================================================\n\nBest Predictions (Lowest CER):\n\nSample 301 (CER: 0.00%)\nReference:  Ø¨Ø§Ø´Ù‡ Ø¨Ø§Ø¨Ø§ ØªÙˆ Ù„Ø§Ú©Ú†Ø±ÛŒØŒ ØªÙˆ Ø®Ø§ØµØŒ ØªÙˆ Ø®ÙÙ†...\nPrediction: Ø¨Ø§Ø´Ù‡ Ø¨Ø§Ø¨Ø§ ØªÙˆ Ù„Ø§Ú©Ú†Ø±ÛŒØŒ ØªÙˆ Ø®Ø§ØµØŒ ØªÙˆ Ø®ÙÙ†...\n\nSample 2512 (CER: 0.00%)\nReference:  Ø§Ø² Ø´Ø®Øµ Ø­Ø§Ø¬ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø²Ù†Ø¬Ø¨ÛŒÙ„ÛŒ Ù…ÛŒÚ¯ÛŒØ±Ù†Ø´...\nPrediction: Ø§Ø² Ø´Ø®Øµ Ø­Ø§Ø¬ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø²Ù†Ø¬Ø¨ÛŒÙ„ÛŒ Ù…ÛŒÚ¯ÛŒØ±Ù†Ø´...\n\nSample 2713 (CER: 0.00%)\nReference:  Ù†Ù…ÛŒ Ø¯ÙˆÙ†Ù… ÙˆØ§Ù„Ø§ ØªØ­Ù…Ù„ Ù†Ù‚Ø¯ Ù†Ø¯Ø§Ø±Ù† Ø¸Ø§Ù‡Ø±Ø§...\nPrediction: Ù†Ù…ÛŒ Ø¯ÙˆÙ†Ù… ÙˆØ§Ù„Ø§ ØªØ­Ù…Ù„ Ù†Ù‚Ø¯ Ù†Ø¯Ø§Ø±Ù† Ø¸Ø§Ù‡Ø±Ø§...\n\nWorst Predictions (Highest CER):\n\nSample 14270 (CER: 916.67%)\nReference:  Û´Û³ÛµÛ¹Û´Û·Û´Û·Û³Û¸Û¹Û°...\nPrediction: Ù¾Ø±ÙˆÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±ÛŒÙ¾Ø±...\n\nSample 3919 (CER: 380.00%)\nReference:  Û·ÛµÛµÛ°Û·Û±Û°Û¶ÛµÛ¹...\nPrediction: ÙˆØ§Ø¯ÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆ...\n\nSample 3718 (CER: 333.33%)\nReference:  Û³Û²Û¶Û·Û²Û²Û¶ÛµÛµÛ¸Û´Û¶...\nPrediction: Ù¾ÙÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾ÙØ³ÙˆÙ¾Ù...\n</code></pre>\n\n{% endcolumn %}\n{% endcolumns %}\n\nAn example from the 200K Persian dataset we used (you may use your own), showing the image on the left and the corresponding text on the right.\n\n<figure><img src=\"https://3215535692-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxhOjnexMCB3dmuQFQ2Zq%2Fuploads%2Fgit-blob-2afa75f90055db094d5cae1c635b200c05e97aac%2FScreenshot%202025-11-04%20at%206.10.16%E2%80%AFAM.png?alt=media\" alt=\"\" width=\"563\"><figcaption></figcaption></figure>",
  "code_samples": [
    {
      "code": "{% endcode %}\n\n### ğŸ¦¥ Unsloth: Run DeepSeek-OCR Tutorial\n\n1. Obtain the latest `unsloth` via `pip install --upgrade unsloth` . If you already have Unsloth, update it via `pip install --upgrade --force-reinstall --no-deps --no-cache-dir unsloth unsloth_zoo`\n2. Then use the code below to run DeepSeek-OCR:\n\n{% code overflow=\"wrap\" %}",
      "language": "unknown"
    },
    {
      "code": "{% endcode %}\n\n## ğŸ¦¥ **Fine-tuning DeepSeek-OCR**\n\nUnsloth supports fine-tuning of DeepSeek-OCR. Since the default model isn't runnable on the latest `transformers` version, we added changes from the [Stranger Vision HF](https://huggingface.co/strangervisionhf) team, to then enable inference. As usual, Unsloth trains DeepSeek-OCR 1.4x faster with 40% less VRAM and 5x longer context lengths - no accuracy degradation.\\\n\\\nWe created two free DeepSeek-OCR Colab notebooks (with and without eval):\n\n* DeepSeek-OCR: [Fine-tuning only notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Deepseek_OCR_\\(3B\\).ipynb)\n* DeepSeek-OCR: [Fine-tuning + Evaluation notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Deepseek_OCR_\\(3B\\)-Eval.ipynb) (A100)\n\nFine-tuning DeepSeek-OCR on a 200K sample Persian dataset resulted in substantial gains in Persian text detection and understanding. We evaluated the base model against our fine-tuned version on 200 Persian transcript samples, observing an **88.26% absolute improvement** in Character Error Rate (CER). After only 60 training steps (batch size = 8), the mean CER decreased from **149.07%** to a mean of **60.81%**. This means the fine-tuned model is **57%** more accurate at understanding Persian.\n\nYou can replace the Persian dataset with your own to improve DeepSeek-OCR for other use-cases.\\\n\\\nFor replica-table eval results, use our eval notebook above. For detailed eval results, see below:\n\n### Fine-tuned Evaluation Results:\n\n{% columns fullWidth=\"true\" %}\n{% column %}\n**DeepSeek-OCR Baseline**\n\nMean Baseline Model Performance: 149.07% CER for this eval set!",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "ğŸ¦¥ Unsloth: Run DeepSeek-OCR Tutorial",
      "id": "ğŸ¦¥-unsloth:-run-deepseek-ocr-tutorial"
    },
    {
      "level": "h2",
      "text": "ğŸ¦¥ **Fine-tuning DeepSeek-OCR**",
      "id": "ğŸ¦¥-**fine-tuning-deepseek-ocr**"
    },
    {
      "level": "h3",
      "text": "Fine-tuned Evaluation Results:",
      "id": "fine-tuned-evaluation-results:"
    }
  ],
  "url": "llms-txt#print-output",
  "links": []
}