# 深度學習技術 - 參考索引

## 核心架構

### CNN (卷積神經網路)
- [CS231n - CNN for Visual Recognition](https://cs231n.github.io/convolutional-networks/)
- [IBM - What are CNNs](https://www.ibm.com/think/topics/convolutional-neural-networks)
- [Stanford CS 230 CNN Cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)

### RNN / LSTM
- [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [神經網路類型比較](https://medium.com/@savindufernando/comparing-cnn-rnn-and-transformer-models-in-simple-terms-a859fe42a299)

### Transformer
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Attention Is All You Need 論文](https://arxiv.org/abs/1706.03762)
- [Codecademy Transformer 架構](https://www.codecademy.com/article/transformer-architecture-self-attention-mechanism)

## 優化技術

### Dropout
- [GeeksforGeeks - Dropout](https://www.geeksforgeeks.org/deep-learning/dropout-regularization-in-deep-learning/)
- [Dropout 變體](https://www.mdpi.com/2079-9292/12/14/3106)

### Batch Normalization
- [LearnOpenCV - BN & Dropout](https://learnopencv.com/batch-normalization-and-dropout-as-regularizers/)
- [CMU 深度學習課程](https://deeplearning.cs.cmu.edu/F20/document/slides/lec8.optimizersandregularizers.pdf)

## 學習資源

### 課程
- [Dive into Deep Learning](https://d2l.ai/)
- [CS231n Stanford](https://cs231n.github.io/)
- [fast.ai](https://www.fast.ai/)

### 框架文檔
- [PyTorch](https://pytorch.org/docs/)
- [TensorFlow](https://www.tensorflow.org/api_docs)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

## 經典論文

- Attention Is All You Need (Transformer)
- Deep Residual Learning (ResNet)
- BERT: Pre-training of Deep Bidirectional Transformers
- ImageNet Classification with Deep CNNs (AlexNet)
