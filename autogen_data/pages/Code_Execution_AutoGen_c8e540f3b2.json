{
  "url": "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/code-execution-groupchat.html",
  "title": "Code Execution — AutoGen",
  "content": "In this section we explore creating custom agents to handle code generation and execution. These tasks can be handled using the provided Agent implementations found here AssistantAgent(), CodeExecutorAgent(); but this guide will show you how to implement custom, lightweight agents that can replace their functionality. This simple example implements two agents that create a plot of Tesla’s and Nvidia’s stock returns.\n\nWe first define the agent classes and their respective procedures for handling messages. We create two agent classes: Assistant and Executor. The Assistant agent writes code and the Executor agent executes the code. We also create a Message data class, which defines the messages that are passed between the agents.\n\nCode generated in this example is run within a Docker container. Please ensure Docker is installed and running prior to running the example. Local code execution is available (LocalCommandLineCodeExecutor) but is not recommended due to the risk of running LLM generated code in your local environment.\n\nYou might have already noticed, the agents’ logic, whether it is using model or code executor, is completely decoupled from how messages are delivered. This is the core idea: the framework provides a communication infrastructure, and the agents are responsible for their own logic. We call the communication infrastructure an Agent Runtime.\n\nAgent runtime is a key concept of this framework. Besides delivering messages, it also manages agents’ lifecycle. So the creation of agents are handled by the runtime.\n\nThe following code shows how to register and run the agents using SingleThreadedAgentRuntime, a local embedded agent runtime implementation.\n\nFrom the agent’s output, we can see the plot of Tesla’s and Nvidia’s stock returns has been created.\n\nAutoGen also supports a distributed agent runtime, which can host agents running on different processes or machines, with different identities, languages and dependencies.\n\nTo learn how to use agent runtime, communication, message handling, and subscription, please continue reading the sections following this quick start.",
  "headings": [
    {
      "level": "h1",
      "text": "Code Execution#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "import re\nfrom dataclasses import dataclass\nfrom typing import List\n\nfrom autogen_core import DefaultTopicId, MessageContext, RoutedAgent, default_subscription, message_handler\nfrom autogen_core.code_executor import CodeBlock, CodeExecutor\nfrom autogen_core.models import (\n    AssistantMessage,\n    ChatCompletionClient,\n    LLMMessage,\n    SystemMessage,\n    UserMessage,\n)\n\n\n@dataclass\nclass Message:\n    content: str\n\n\n@default_subscription\nclass Assistant(RoutedAgent):\n    def __init__(self, model_client: ChatCompletionClient) -> None:\n        super().__init__(\"An assistant agent.\")\n        self._model_client = model_client\n        self._chat_history: List[LLMMessage] = [\n            SystemMessage(\n                content=\"\"\"Write Python script in markdown block, and it will be executed.\nAlways save figures to file in the current directory. Do not use plt.show(). All code required to complete this task must be contained within a single response.\"\"\",\n            )\n        ]\n\n    @message_handler\n    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n        self._chat_history.append(UserMessage(content=message.content, source=\"user\"))\n        result = await self._model_client.create(self._chat_history)\n        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))  # type: ignore\n        await self.publish_message(Message(content=result.content), DefaultTopicId())  # type: ignore\n\n\ndef extract_markdown_code_blocks(markdown_text: str) -> List[CodeBlock]:\n    pattern = re.compile(r\"```(?:\\s*([\\w\\+\\-]+))?\\n([\\s\\S]*?)```\")\n    matches = pattern.findall(markdown_text)\n    code_blocks: List[CodeBlock] = []\n    for match in matches:\n        language = match[0].strip() if match[0] else \"\"\n        code_content = match[1]\n        code_blocks.append(CodeBlock(code=code_content, language=language))\n    return code_blocks\n\n\n@default_subscription\nclass Executor(RoutedAgent):\n    def __init__(self, code_executor: CodeExecutor) -> None:\n        super().__init__(\"An executor agent.\")\n        self._code_executor = code_executor\n\n    @message_handler\n    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n        code_blocks = extract_markdown_code_blocks(message.content)\n        if code_blocks:\n            result = await self._code_executor.execute_code_blocks(\n                code_blocks, cancellation_token=ctx.cancellation_token\n            )\n            print(f\"\\n{'-'*80}\\nExecutor:\\n{result.output}\")\n            await self.publish_message(Message(content=result.output), DefaultTopicId())",
      "language": "python"
    },
    {
      "code": "import re\nfrom dataclasses import dataclass\nfrom typing import List\n\nfrom autogen_core import DefaultTopicId, MessageContext, RoutedAgent, default_subscription, message_handler\nfrom autogen_core.code_executor import CodeBlock, CodeExecutor\nfrom autogen_core.models import (\n    AssistantMessage,\n    ChatCompletionClient,\n    LLMMessage,\n    SystemMessage,\n    UserMessage,\n)\n\n\n@dataclass\nclass Message:\n    content: str\n\n\n@default_subscription\nclass Assistant(RoutedAgent):\n    def __init__(self, model_client: ChatCompletionClient) -> None:\n        super().__init__(\"An assistant agent.\")\n        self._model_client = model_client\n        self._chat_history: List[LLMMessage] = [\n            SystemMessage(\n                content=\"\"\"Write Python script in markdown block, and it will be executed.\nAlways save figures to file in the current directory. Do not use plt.show(). All code required to complete this task must be contained within a single response.\"\"\",\n            )\n        ]\n\n    @message_handler\n    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n        self._chat_history.append(UserMessage(content=message.content, source=\"user\"))\n        result = await self._model_client.create(self._chat_history)\n        print(f\"\\n{'-'*80}\\nAssistant:\\n{result.content}\")\n        self._chat_history.append(AssistantMessage(content=result.content, source=\"assistant\"))  # type: ignore\n        await self.publish_message(Message(content=result.content), DefaultTopicId())  # type: ignore\n\n\ndef extract_markdown_code_blocks(markdown_text: str) -> List[CodeBlock]:\n    pattern = re.compile(r\"```(?:\\s*([\\w\\+\\-]+))?\\n([\\s\\S]*?)```\")\n    matches = pattern.findall(markdown_text)\n    code_blocks: List[CodeBlock] = []\n    for match in matches:\n        language = match[0].strip() if match[0] else \"\"\n        code_content = match[1]\n        code_blocks.append(CodeBlock(code=code_content, language=language))\n    return code_blocks\n\n\n@default_subscription\nclass Executor(RoutedAgent):\n    def __init__(self, code_executor: CodeExecutor) -> None:\n        super().__init__(\"An executor agent.\")\n        self._code_executor = code_executor\n\n    @message_handler\n    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n        code_blocks = extract_markdown_code_blocks(message.content)\n        if code_blocks:\n            result = await self._code_executor.execute_code_blocks(\n                code_blocks, cancellation_token=ctx.cancellation_token\n            )\n            print(f\"\\n{'-'*80}\\nExecutor:\\n{result.output}\")\n            await self.publish_message(Message(content=result.output), DefaultTopicId())",
      "language": "python"
    },
    {
      "code": "import tempfile\n\nfrom autogen_core import SingleThreadedAgentRuntime\nfrom autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nwork_dir = tempfile.mkdtemp()\n\n# Create an local embedded runtime.\nruntime = SingleThreadedAgentRuntime()\n\nasync with DockerCommandLineCodeExecutor(work_dir=work_dir) as executor:  # type: ignore[syntax]\n    # Register the assistant and executor agents by providing\n    # their agent types, the factory functions for creating instance and subscriptions.\n    model_client = OpenAIChatCompletionClient(\n        model=\"gpt-4o\",\n        # api_key=\"YOUR_API_KEY\"\n    )\n    await Assistant.register(\n        runtime,\n        \"assistant\",\n        lambda: Assistant(model_client=model_client),\n    )\n    await Executor.register(runtime, \"executor\", lambda: Executor(executor))\n\n    # Start the runtime and publish a message to the assistant.\n    runtime.start()\n    await runtime.publish_message(\n        Message(\"Create a plot of NVIDA vs TSLA stock returns YTD from 2024-01-01.\"), DefaultTopicId()\n    )\n\n    # Wait for the runtime to stop when idle.\n    await runtime.stop_when_idle()\n    # Close the connection to the model client.\n    await model_client.close()",
      "language": "python"
    },
    {
      "code": "import tempfile\n\nfrom autogen_core import SingleThreadedAgentRuntime\nfrom autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nwork_dir = tempfile.mkdtemp()\n\n# Create an local embedded runtime.\nruntime = SingleThreadedAgentRuntime()\n\nasync with DockerCommandLineCodeExecutor(work_dir=work_dir) as executor:  # type: ignore[syntax]\n    # Register the assistant and executor agents by providing\n    # their agent types, the factory functions for creating instance and subscriptions.\n    model_client = OpenAIChatCompletionClient(\n        model=\"gpt-4o\",\n        # api_key=\"YOUR_API_KEY\"\n    )\n    await Assistant.register(\n        runtime,\n        \"assistant\",\n        lambda: Assistant(model_client=model_client),\n    )\n    await Executor.register(runtime, \"executor\", lambda: Executor(executor))\n\n    # Start the runtime and publish a message to the assistant.\n    runtime.start()\n    await runtime.publish_message(\n        Message(\"Create a plot of NVIDA vs TSLA stock returns YTD from 2024-01-01.\"), DefaultTopicId()\n    )\n\n    # Wait for the runtime to stop when idle.\n    await runtime.stop_when_idle()\n    # Close the connection to the model client.\n    await model_client.close()",
      "language": "python"
    },
    {
      "code": "--------------------------------------------------------------------------------\nAssistant:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# Define the ticker symbols for NVIDIA and Tesla\ntickers = ['NVDA', 'TSLA']\n\n# Download the stock data from Yahoo Finance starting from 2024-01-01\nstart_date = '2024-01-01'\nend_date = pd.to_datetime('today').strftime('%Y-%m-%d')\n\n# Download the adjusted closing prices\nstock_data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n\n# Calculate the daily returns\nreturns = stock_data.pct_change().dropna()\n\n# Plot the cumulative returns for each stock\ncumulative_returns = (1 + returns).cumprod()\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_returns.index, cumulative_returns['NVDA'], label='NVIDIA', color='green')\nplt.plot(cumulative_returns.index, cumulative_returns['TSLA'], label='Tesla', color='red')\nplt.title('NVIDIA vs Tesla Stock Returns YTD (2024)')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Return')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n# Save the plot to a file\nplt.savefig('nvidia_vs_tesla_ytd_returns.png')\n```\n\n--------------------------------------------------------------------------------\nExecutor:\nTraceback (most recent call last):\n  File \"/workspace/tmp_code_fd7395dcad4fbb74d40c981411db604e78e1a17783ca1fab3aaec34ff2c3fdf0.python\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n\n\n--------------------------------------------------------------------------------\nAssistant:\nIt seems like the necessary libraries are not available in your environment. However, since I can't install packages or check the environment directly from here, you'll need to make sure that the appropriate packages are installed in your working environment. Once the modules are available, the script provided will execute properly.\n\nHere's how you can install the required packages using pip (make sure to run these commands in your terminal or command prompt):\n\n```bash\npip install pandas matplotlib yfinance\n```\n\nLet me provide you the script again for reference:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# Define the ticker symbols for NVIDIA and Tesla\ntickers = ['NVDA', 'TSLA']\n\n# Download the stock data from Yahoo Finance starting from 2024-01-01\nstart_date = '2024-01-01'\nend_date = pd.to_datetime('today').strftime('%Y-%m-%d')\n\n# Download the adjusted closing prices\nstock_data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n\n# Calculate the daily returns\nreturns = stock_data.pct_change().dropna()\n\n# Plot the cumulative returns for each stock\ncumulative_returns = (1 + returns).cumprod()\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_returns.index, cumulative_returns['NVDA'], label='NVIDIA', color='green')\nplt.plot(cumulative_returns.index, cumulative_returns['TSLA'], label='Tesla', color='red')\nplt.title('NVIDIA vs Tesla Stock Returns YTD (2024)')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Return')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n# Save the plot to a file\nplt.savefig('nvidia_vs_tesla_ytd_returns.png')\n```\n\nMake sure to install the packages in the environment where you run this script. Feel free to ask if you have further questions or issues!\n\n--------------------------------------------------------------------------------\nExecutor:\n[*********************100%***********************]  2 of 2 completed\n\n\n--------------------------------------------------------------------------------\nAssistant:\nIt looks like the data fetching process completed successfully. You should now have a plot saved as `nvidia_vs_tesla_ytd_returns.png` in your current directory. If you have any additional questions or need further assistance, feel free to ask!",
      "language": "julia"
    },
    {
      "code": "--------------------------------------------------------------------------------\nAssistant:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# Define the ticker symbols for NVIDIA and Tesla\ntickers = ['NVDA', 'TSLA']\n\n# Download the stock data from Yahoo Finance starting from 2024-01-01\nstart_date = '2024-01-01'\nend_date = pd.to_datetime('today').strftime('%Y-%m-%d')\n\n# Download the adjusted closing prices\nstock_data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n\n# Calculate the daily returns\nreturns = stock_data.pct_change().dropna()\n\n# Plot the cumulative returns for each stock\ncumulative_returns = (1 + returns).cumprod()\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_returns.index, cumulative_returns['NVDA'], label='NVIDIA', color='green')\nplt.plot(cumulative_returns.index, cumulative_returns['TSLA'], label='Tesla', color='red')\nplt.title('NVIDIA vs Tesla Stock Returns YTD (2024)')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Return')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n# Save the plot to a file\nplt.savefig('nvidia_vs_tesla_ytd_returns.png')\n```\n\n--------------------------------------------------------------------------------\nExecutor:\nTraceback (most recent call last):\n  File \"/workspace/tmp_code_fd7395dcad4fbb74d40c981411db604e78e1a17783ca1fab3aaec34ff2c3fdf0.python\", line 1, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n\n\n--------------------------------------------------------------------------------\nAssistant:\nIt seems like the necessary libraries are not available in your environment. However, since I can't install packages or check the environment directly from here, you'll need to make sure that the appropriate packages are installed in your working environment. Once the modules are available, the script provided will execute properly.\n\nHere's how you can install the required packages using pip (make sure to run these commands in your terminal or command prompt):\n\n```bash\npip install pandas matplotlib yfinance\n```\n\nLet me provide you the script again for reference:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n# Define the ticker symbols for NVIDIA and Tesla\ntickers = ['NVDA', 'TSLA']\n\n# Download the stock data from Yahoo Finance starting from 2024-01-01\nstart_date = '2024-01-01'\nend_date = pd.to_datetime('today').strftime('%Y-%m-%d')\n\n# Download the adjusted closing prices\nstock_data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n\n# Calculate the daily returns\nreturns = stock_data.pct_change().dropna()\n\n# Plot the cumulative returns for each stock\ncumulative_returns = (1 + returns).cumprod()\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_returns.index, cumulative_returns['NVDA'], label='NVIDIA', color='green')\nplt.plot(cumulative_returns.index, cumulative_returns['TSLA'], label='Tesla', color='red')\nplt.title('NVIDIA vs Tesla Stock Returns YTD (2024)')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Return')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n# Save the plot to a file\nplt.savefig('nvidia_vs_tesla_ytd_returns.png')\n```\n\nMake sure to install the packages in the environment where you run this script. Feel free to ask if you have further questions or issues!\n\n--------------------------------------------------------------------------------\nExecutor:\n[*********************100%***********************]  2 of 2 completed\n\n\n--------------------------------------------------------------------------------\nAssistant:\nIt looks like the data fetching process completed successfully. You should now have a plot saved as `nvidia_vs_tesla_ytd_returns.png` in your current directory. If you have any additional questions or need further assistance, feel free to ask!",
      "language": "julia"
    },
    {
      "code": "from IPython.display import Image\n\nImage(filename=f\"{work_dir}/nvidia_vs_tesla_ytd_returns.png\")  # type: ignore",
      "language": "sql"
    },
    {
      "code": "from IPython.display import Image\n\nImage(filename=f\"{work_dir}/nvidia_vs_tesla_ytd_returns.png\")  # type: ignore",
      "language": "sql"
    }
  ],
  "patterns": [],
  "links": [
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/code-execution-groupchat.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/installation.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/quickstart.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/core-concepts/agent-and-multi-agent-application.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/core-concepts/architecture.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/core-concepts/application-stack.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/core-concepts/agent-identity-and-lifecycle.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/core-concepts/topic-and-subscription.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/agent-and-agent-runtime.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/message-and-communication.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/logging.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/telemetry.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/distributed-agent-runtime.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/component-config.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/components/model-clients.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/components/model-context.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/components/tools.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/components/workbench.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/components/command-line-code-executors.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/intro.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/concurrent-agents.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/sequential-workflow.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/group-chat.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/handoffs.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/mixture-of-agents.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/multi-agent-debate.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/reflection.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/azure-openai-with-aad-auth.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/termination-with-intervention.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/tool-use-with-intervention.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/extracting-results-with-an-agent.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/openai-assistant-agent.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/langgraph-agent.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/llamaindex-agent.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/local-llms-ollama-litellm.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/instrumenting.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/topic-subscription-scenarios.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/structured-output-agent.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/cookbook/llm-usage-logger.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/faqs.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html"
  ]
}