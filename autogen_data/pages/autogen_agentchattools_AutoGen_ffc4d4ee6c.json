{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
  "title": "autogen_agentchat.tools — AutoGen",
  "content": "Bases: TaskRunnerTool, Component[AgentToolConfig]\n\nTool that can be used to run a task using an agent.\n\nThe tool returns the result of the task execution as a TaskResult object.\n\nWhen using AgentTool, you must disable parallel tool calls in the model client configuration to avoid concurrency issues. Agents cannot run concurrently as they maintain internal state that would conflict with parallel execution. For example, set parallel_tool_calls=False for OpenAIChatCompletionClient and AzureOpenAIChatCompletionClient.\n\nagent (BaseChatAgent) – The agent to be used for running the task.\n\nreturn_value_as_last_message (bool) – Whether to use the last message content of the task result as the return value of the tool in return_value_as_string(). If set to True, the last message content will be returned as a string. If set to False, the tool will return all messages in the task result as a string concatenated together, with each message prefixed by its source (e.g., “writer: …”, “assistant: …”).\n\nalias of AgentToolConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: TaskRunnerTool, Component[TeamToolConfig]\n\nTool that can be used to run a task.\n\nThe tool returns the result of the task execution as a TaskResult object.\n\nWhen using TeamTool, you must disable parallel tool calls in the model client configuration to avoid concurrency issues. Teams cannot run concurrently as they maintain internal state that would conflict with parallel execution. For example, set parallel_tool_calls=False for OpenAIChatCompletionClient and AzureOpenAIChatCompletionClient.\n\nteam (BaseGroupChat) – The team to be used for running the task.\n\nname (str) – The name of the tool.\n\ndescription (str) – The description of the tool.\n\nreturn_value_as_last_message (bool) – Whether to use the last message content of the task result as the return value of the tool in return_value_as_string(). If set to True, the last message content will be returned as a string. If set to False, the tool will return all messages in the task result as a string concatenated together, with each message prefixed by its source (e.g., “writer: …”, “assistant: …”).\n\nalias of TeamToolConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nautogen_agentchat.teams",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_agentchat.tools#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "import asyncio\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.tools import AgentTool\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n    writer = AssistantAgent(\n        name=\"writer\",\n        description=\"A writer agent for generating text.\",\n        model_client=model_client,\n        system_message=\"Write well.\",\n    )\n    writer_tool = AgentTool(agent=writer)\n\n    # Create model client with parallel tool calls disabled for the main agent\n    main_model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\", parallel_tool_calls=False)\n    assistant = AssistantAgent(\n        name=\"assistant\",\n        model_client=main_model_client,\n        tools=[writer_tool],\n        system_message=\"You are a helpful assistant.\",\n    )\n    await Console(assistant.run_stream(task=\"Write a poem about the sea.\"))\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.tools import AgentTool\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n    writer = AssistantAgent(\n        name=\"writer\",\n        description=\"A writer agent for generating text.\",\n        model_client=model_client,\n        system_message=\"Write well.\",\n    )\n    writer_tool = AgentTool(agent=writer)\n\n    # Create model client with parallel tool calls disabled for the main agent\n    main_model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\", parallel_tool_calls=False)\n    assistant = AssistantAgent(\n        name=\"assistant\",\n        model_client=main_model_client,\n        tools=[writer_tool],\n        system_message=\"You are a helpful assistant.\",\n    )\n    await Console(assistant.run_stream(task=\"Write a poem about the sea.\"))\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "from autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.conditions import SourceMatchTermination\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.tools import TeamTool\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n\nasync def main() -> None:\n    # Disable parallel tool calls when using TeamTool\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n\n    writer = AssistantAgent(name=\"writer\", model_client=model_client, system_message=\"You are a helpful assistant.\")\n    reviewer = AssistantAgent(\n        name=\"reviewer\", model_client=model_client, system_message=\"You are a critical reviewer.\"\n    )\n    summarizer = AssistantAgent(\n        name=\"summarizer\",\n        model_client=model_client,\n        system_message=\"You combine the review and produce a revised response.\",\n    )\n    team = RoundRobinGroupChat(\n        [writer, reviewer, summarizer], termination_condition=SourceMatchTermination(sources=[\"summarizer\"])\n    )\n\n    # Create a TeamTool that uses the team to run tasks, returning the last message as the result.\n    tool = TeamTool(\n        team=team,\n        name=\"writing_team\",\n        description=\"A tool for writing tasks.\",\n        return_value_as_last_message=True,\n    )\n\n    # Create model client with parallel tool calls disabled for the main agent\n    main_model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\", parallel_tool_calls=False)\n    main_agent = AssistantAgent(\n        name=\"main_agent\",\n        model_client=main_model_client,\n        system_message=\"You are a helpful assistant that can use the writing tool.\",\n        tools=[tool],\n    )\n    # For handling each events manually.\n    # async for message in main_agent.run_stream(\n    #     task=\"Write a short story about a robot learning to love.\",\n    # ):\n    #     print(message)\n    # Use Console to display the messages in a more readable format.\n    await Console(\n        main_agent.run_stream(\n            task=\"Write a short story about a robot learning to love.\",\n        )\n    )\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "from autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.conditions import SourceMatchTermination\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.tools import TeamTool\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n\nasync def main() -> None:\n    # Disable parallel tool calls when using TeamTool\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n\n    writer = AssistantAgent(name=\"writer\", model_client=model_client, system_message=\"You are a helpful assistant.\")\n    reviewer = AssistantAgent(\n        name=\"reviewer\", model_client=model_client, system_message=\"You are a critical reviewer.\"\n    )\n    summarizer = AssistantAgent(\n        name=\"summarizer\",\n        model_client=model_client,\n        system_message=\"You combine the review and produce a revised response.\",\n    )\n    team = RoundRobinGroupChat(\n        [writer, reviewer, summarizer], termination_condition=SourceMatchTermination(sources=[\"summarizer\"])\n    )\n\n    # Create a TeamTool that uses the team to run tasks, returning the last message as the result.\n    tool = TeamTool(\n        team=team,\n        name=\"writing_team\",\n        description=\"A tool for writing tasks.\",\n        return_value_as_last_message=True,\n    )\n\n    # Create model client with parallel tool calls disabled for the main agent\n    main_model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\", parallel_tool_calls=False)\n    main_agent = AssistantAgent(\n        name=\"main_agent\",\n        model_client=main_model_client,\n        system_message=\"You are a helpful assistant that can use the writing tool.\",\n        tools=[tool],\n    )\n    # For handling each events manually.\n    # async for message in main_agent.run_stream(\n    #     task=\"Write a short story about a robot learning to love.\",\n    # ):\n    #     print(message)\n    # Use Console to display the messages in a more readable format.\n    await Console(\n        main_agent.run_stream(\n            task=\"Write a short story about a robot learning to love.\",\n        )\n    )\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())",
      "language": "python"
    }
  ],
  "patterns": [],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}