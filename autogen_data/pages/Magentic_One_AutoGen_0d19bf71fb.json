{
  "url": "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/magentic-one.html",
  "title": "Magentic-One — AutoGen",
  "content": "Magentic-One is a generalist multi-agent system for solving open-ended web and file-based tasks across a variety of domains. It represents a significant step forward for multi-agent systems, achieving competitive performance on a number of agentic benchmarks (see the technical report for full details).\n\nWhen originally released in November 2024 Magentic-One was implemented directly on the autogen-core library. We have now ported Magentic-One to use autogen-agentchat, providing a more modular and easier to use interface.\n\nTo this end, the Magentic-One orchestrator MagenticOneGroupChat is now simply an AgentChat team, supporting all standard AgentChat agents and features. Likewise, Magentic-One’s MultimodalWebSurfer, FileSurfer, and MagenticOneCoderAgent agents are now broadly available as AgentChat agents, to be used in any AgentChat workflows.\n\nLastly, there is a helper class, MagenticOne, which bundles all of this together as it was in the paper with minimal configuration.\n\nFind additional information about Magentic-one in our blog post and technical report.\n\nExample: The figure above illustrates Magentic-One multi-agent team completing a complex task from the GAIA benchmark. Magentic-One’s Orchestrator agent creates a plan, delegates tasks to other agents, and tracks progress towards the goal, dynamically revising the plan as needed. The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer agent to operate a web browser, or a Coder or Computer Terminal agent to write or execute code, respectively.\n\nUsing Magentic-One involves interacting with a digital world designed for humans, which carries inherent risks. To minimize these risks, consider the following precautions:\n\nUse Containers: Run all tasks in docker containers to isolate the agents and prevent direct system attacks.\n\nVirtual Environment: Use a virtual environment to run the agents and prevent them from accessing sensitive data.\n\nMonitor Logs: Closely monitor logs during and after execution to detect and mitigate risky behavior.\n\nHuman Oversight: Run the examples with a human in the loop to supervise the agents and prevent unintended consequences.\n\nLimit Access: Restrict the agents’ access to the internet and other resources to prevent unauthorized actions.\n\nSafeguard Data: Ensure that the agents do not have access to sensitive data or resources that could be compromised. Do not share sensitive information with the agents. Be aware that agents may occasionally attempt risky actions, such as recruiting humans for help or accepting cookie agreements without human involvement. Always ensure agents are monitored and operate within a controlled environment to prevent unintended consequences. Moreover, be cautious that Magentic-One may be susceptible to prompt injection attacks from webpages.\n\nInstall the required packages:\n\nIf you haven’t done so already, go through the AgentChat tutorial to learn about the concepts of AgentChat.\n\nThen, you can try swapping out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat.\n\nTo use a different model, see Models for more information.\n\nOr, use the Magentic-One agents in a team:\n\nThe example code may download files from the internet, execute code, and interact with web pages. Ensure you are in a safe environment before running the example code.\n\nOr, use the MagenticOne helper class with all the agents bundled together:\n\nMagentic-One work is based on a multi-agent architecture where a lead Orchestrator agent is responsible for high-level planning, directing other agents and tracking task progress. The Orchestrator begins by creating a plan to tackle the task, gathering needed facts and educated guesses in a Task Ledger that is maintained. At each step of its plan, the Orchestrator creates a Progress Ledger where it self-reflects on task progress and checks whether the task is completed. If the task is not yet completed, it assigns one of Magentic-One other agents a subtask to complete. After the assigned agent completes its subtask, the Orchestrator updates the Progress Ledger and continues in this way until the task is complete. If the Orchestrator finds that progress is not being made for enough steps, it can update the Task Ledger and create a new plan. This is illustrated in the figure above; the Orchestrator work is thus divided into an outer loop where it updates the Task Ledger and an inner loop to update the Progress Ledger.\n\nOverall, Magentic-One consists of the following agents:\n\nOrchestrator: the lead agent responsible for task decomposition and planning, directing other agents in executing subtasks, tracking overall progress, and taking corrective actions as needed\n\nWebSurfer: This is an LLM-based agent that is proficient in commanding and managing the state of a Chromium-based web browser. With each incoming request, the WebSurfer performs an action on the browser then reports on the new state of the web page The action space of the WebSurfer includes navigation (e.g. visiting a URL, performing a web search); web page actions (e.g., clicking and typing); and reading actions (e.g., summarizing or answering questions). The WebSurfer relies on the accessibility tree of the browser and on set-of-marks prompting to perform its actions.\n\nFileSurfer: This is an LLM-based agent that commands a markdown-based file preview application to read local files of most types. The FileSurfer can also perform common navigation tasks such as listing the contents of directories and navigating a folder structure.\n\nCoder: This is an LLM-based agent specialized through its system prompt for writing code, analyzing information collected from the other agents, or creating new artifacts.\n\nComputerTerminal: Finally, ComputerTerminal provides the team with access to a console shell where the Coder’s programs can be executed, and where new programming libraries can be installed.\n\nTogether, Magentic-One’s agents provide the Orchestrator with the tools and capabilities that it needs to solve a broad variety of open-ended problems, as well as the ability to autonomously adapt to, and act in, dynamic and ever-changing web and file-system environments.\n\nWhile the default multimodal LLM we use for all agents is GPT-4o, Magentic-One is model agnostic and can incorporate heterogonous models to support different capabilities or meet different cost requirements when getting tasks done. For example, it can use different LLMs and SLMs and their specialized versions to power different agents. We recommend a strong reasoning model for the Orchestrator agent such as GPT-4o. In a different configuration of Magentic-One, we also experiment with using OpenAI o1-preview for the outer loop of the Orchestrator and for the Coder, while other agents continue to use GPT-4o.\n\nGraphFlow (Workflows)",
  "headings": [
    {
      "level": "h1",
      "text": "Magentic-One#",
      "id": ""
    },
    {
      "level": "h2",
      "text": "Getting started#",
      "id": ""
    },
    {
      "level": "h2",
      "text": "Architecture#",
      "id": ""
    },
    {
      "level": "h2",
      "text": "Citation#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "pip install \"autogen-agentchat\" \"autogen-ext[magentic-one,openai]\"\n\n# If using the MultimodalWebSurfer, you also need to install playwright dependencies:\nplaywright install --with-deps chromium",
      "language": "julia"
    },
    {
      "code": "pip install \"autogen-agentchat\" \"autogen-ext[magentic-one,openai]\"\n\n# If using the MultimodalWebSurfer, you also need to install playwright dependencies:\nplaywright install --with-deps chromium",
      "language": "julia"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.teams import MagenticOneGroupChat\nfrom autogen_agentchat.ui import Console\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n\n    assistant = AssistantAgent(\n        \"Assistant\",\n        model_client=model_client,\n    )\n    team = MagenticOneGroupChat([assistant], model_client=model_client)\n    await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\"))\n    await model_client.close()\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.teams import MagenticOneGroupChat\nfrom autogen_agentchat.ui import Console\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n\n    assistant = AssistantAgent(\n        \"Assistant\",\n        model_client=model_client,\n    )\n    team = MagenticOneGroupChat([assistant], model_client=model_client)\n    await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\"))\n    await model_client.close()\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_agentchat.teams import MagenticOneGroupChat\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.agents.web_surfer import MultimodalWebSurfer\n# from autogen_ext.agents.file_surfer import FileSurfer\n# from autogen_ext.agents.magentic_one import MagenticOneCoderAgent\n# from autogen_agentchat.agents import CodeExecutorAgent\n# from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n\n    surfer = MultimodalWebSurfer(\n        \"WebSurfer\",\n        model_client=model_client,\n    )\n\n    team = MagenticOneGroupChat([surfer], model_client=model_client)\n    await Console(team.run_stream(task=\"What is the UV index in Melbourne today?\"))\n\n    # # Note: you can also use  other agents in the team\n    # team = MagenticOneGroupChat([surfer, file_surfer, coder, terminal], model_client=model_client)\n    # file_surfer = FileSurfer( \"FileSurfer\",model_client=model_client)\n    # coder = MagenticOneCoderAgent(\"Coder\",model_client=model_client)\n    # terminal = CodeExecutorAgent(\"ComputerTerminal\",code_executor=LocalCommandLineCodeExecutor())\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_agentchat.teams import MagenticOneGroupChat\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.agents.web_surfer import MultimodalWebSurfer\n# from autogen_ext.agents.file_surfer import FileSurfer\n# from autogen_ext.agents.magentic_one import MagenticOneCoderAgent\n# from autogen_agentchat.agents import CodeExecutorAgent\n# from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n\n    surfer = MultimodalWebSurfer(\n        \"WebSurfer\",\n        model_client=model_client,\n    )\n\n    team = MagenticOneGroupChat([surfer], model_client=model_client)\n    await Console(team.run_stream(task=\"What is the UV index in Melbourne today?\"))\n\n    # # Note: you can also use  other agents in the team\n    # team = MagenticOneGroupChat([surfer, file_surfer, coder, terminal], model_client=model_client)\n    # file_surfer = FileSurfer( \"FileSurfer\",model_client=model_client)\n    # coder = MagenticOneCoderAgent(\"Coder\",model_client=model_client)\n    # terminal = CodeExecutorAgent(\"ComputerTerminal\",code_executor=LocalCommandLineCodeExecutor())\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.teams.magentic_one import MagenticOne\nfrom autogen_agentchat.ui import Console\nfrom autogen_agentchat.agents import ApprovalRequest, ApprovalResponse\n\n\ndef approval_func(request: ApprovalRequest) -> ApprovalResponse:\n    \"\"\"Simple approval function that requests user input before code execution.\"\"\"\n    print(f\"Code to execute:\\n{request.code}\")\n    user_input = input(\"Do you approve this code execution? (y/n): \").strip().lower()\n    if user_input == 'y':\n        return ApprovalResponse(approved=True, reason=\"User approved the code execution\")\n    else:\n        return ApprovalResponse(approved=False, reason=\"User denied the code execution\")\n\n\nasync def example_usage():\n    client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n    # Enable code execution approval for security\n    m1 = MagenticOne(client=client, approval_func=approval_func)\n    task = \"Write a Python script to fetch data from an API.\"\n    result = await Console(m1.run_stream(task=task))\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(example_usage())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.teams.magentic_one import MagenticOne\nfrom autogen_agentchat.ui import Console\nfrom autogen_agentchat.agents import ApprovalRequest, ApprovalResponse\n\n\ndef approval_func(request: ApprovalRequest) -> ApprovalResponse:\n    \"\"\"Simple approval function that requests user input before code execution.\"\"\"\n    print(f\"Code to execute:\\n{request.code}\")\n    user_input = input(\"Do you approve this code execution? (y/n): \").strip().lower()\n    if user_input == 'y':\n        return ApprovalResponse(approved=True, reason=\"User approved the code execution\")\n    else:\n        return ApprovalResponse(approved=False, reason=\"User denied the code execution\")\n\n\nasync def example_usage():\n    client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n    # Enable code execution approval for security\n    m1 = MagenticOne(client=client, approval_func=approval_func)\n    task = \"Write a Python script to fetch data from an API.\"\n    result = await Console(m1.run_stream(task=task))\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(example_usage())",
      "language": "python"
    },
    {
      "code": "@misc{fourney2024magenticonegeneralistmultiagentsolving,\n      title={Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks},\n      author={Adam Fourney and Gagan Bansal and Hussein Mozannar and Cheng Tan and Eduardo Salinas and Erkang and Zhu and Friederike Niedtner and Grace Proebsting and Griffin Bassman and Jack Gerrits and Jacob Alber and Peter Chang and Ricky Loynd and Robert West and Victor Dibia and Ahmed Awadallah and Ece Kamar and Rafah Hosn and Saleema Amershi},\n      year={2024},\n      eprint={2411.04468},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2411.04468},\n}",
      "language": "css"
    },
    {
      "code": "@misc{fourney2024magenticonegeneralistmultiagentsolving,\n      title={Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks},\n      author={Adam Fourney and Gagan Bansal and Hussein Mozannar and Cheng Tan and Eduardo Salinas and Erkang and Zhu and Friederike Niedtner and Grace Proebsting and Griffin Bassman and Jack Gerrits and Jacob Alber and Peter Chang and Ricky Loynd and Robert West and Victor Dibia and Ahmed Awadallah and Ece Kamar and Rafah Hosn and Saleema Amershi},\n      year={2024},\n      eprint={2411.04468},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2411.04468},\n}",
      "language": "css"
    }
  ],
  "patterns": [
    {
      "description": "AgentChat Magentic-One Magentic-One# Magentic-One is a generalist multi-agent system for solving open-ended web and file-based tasks across a variety of domains. It represents a significant step forward for multi-agent systems, achieving competitive performance on a number of agentic benchmarks (see the technical report for full details). When originally released in November 2024 Magentic-One was implemented directly on the autogen-core library. We have now ported Magentic-One to use autogen-agentchat, providing a more modular and easier to use interface. To this end, the Magentic-One orchestrator MagenticOneGroupChat is now simply an AgentChat team, supporting all standard AgentChat agents and features. Likewise, Magentic-One’s MultimodalWebSurfer, FileSurfer, and MagenticOneCoderAgent agents are now broadly available as AgentChat agents, to be used in any AgentChat workflows. Lastly, there is a helper class, MagenticOne, which bundles all of this together as it was in the paper with minimal configuration. Find additional information about Magentic-one in our blog post and technical report. Example: The figure above illustrates Magentic-One multi-agent team completing a complex task from the GAIA benchmark. Magentic-One’s Orchestrator agent creates a plan, delegates tasks to other agents, and tracks progress towards the goal, dynamically revising the plan as needed. The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer agent to operate a web browser, or a Coder or Computer Terminal agent to write or execute code, respectively. Caution Using Magentic-One involves interacting with a digital world designed for humans, which carries inherent risks. To minimize these risks, consider the following precautions: Use Containers: Run all tasks in docker containers to isolate the agents and prevent direct system attacks. Virtual Environment: Use a virtual environment to run the agents and prevent them from accessing sensitive data. Monitor Logs: Closely monitor logs during and after execution to detect and mitigate risky behavior. Human Oversight: Run the examples with a human in the loop to supervise the agents and prevent unintended consequences. Limit Access: Restrict the agents’ access to the internet and other resources to prevent unauthorized actions. Safeguard Data: Ensure that the agents do not have access to sensitive data or resources that could be compromised. Do not share sensitive information with the agents. Be aware that agents may occasionally attempt risky actions, such as recruiting humans for help or accepting cookie agreements without human involvement. Always ensure agents are monitored and operate within a controlled environment to prevent unintended consequences. Moreover, be cautious that Magentic-One may be susceptible to prompt injection attacks from webpages. Getting started# Install the required packages: pip install \"autogen-agentchat\" \"autogen-ext[magentic-one,openai]\" # If using the MultimodalWebSurfer, you also need to install playwright dependencies: playwright install --with-deps chromium If you haven’t done so already, go through the AgentChat tutorial to learn about the concepts of AgentChat. Then, you can try swapping out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat. For example: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.teams import MagenticOneGroupChat from autogen_agentchat.ui import Console async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") assistant = AssistantAgent( \"Assistant\", model_client=model_client, ) team = MagenticOneGroupChat([assistant], model_client=model_client) await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\")) await model_client.close() asyncio.run(main()) To use a different model, see Models for more information. Or, use the Magentic-One agents in a team: Caution The example code may download files from the internet, execute code, and interact with web pages. Ensure you are in a safe environment before running the example code. import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_agentchat.teams import MagenticOneGroupChat from autogen_agentchat.ui import Console from autogen_ext.agents.web_surfer import MultimodalWebSurfer # from autogen_ext.agents.file_surfer import FileSurfer # from autogen_ext.agents.magentic_one import MagenticOneCoderAgent # from autogen_agentchat.agents import CodeExecutorAgent # from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") surfer = MultimodalWebSurfer( \"WebSurfer\", model_client=model_client, ) team = MagenticOneGroupChat([surfer], model_client=model_client) await Console(team.run_stream(task=\"What is the UV index in Melbourne today?\")) # # Note: you can also use other agents in the team # team = MagenticOneGroupChat([surfer, file_surfer, coder, terminal], model_client=model_client) # file_surfer = FileSurfer( \"FileSurfer\",model_client=model_client) # coder = MagenticOneCoderAgent(\"Coder\",model_client=model_client) # terminal = CodeExecutorAgent(\"ComputerTerminal\",code_executor=LocalCommandLineCodeExecutor()) asyncio.run(main()) Or, use the MagenticOne helper class with all the agents bundled together: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.teams.magentic_one import MagenticOne from autogen_agentchat.ui import Console from autogen_agentchat.agents import ApprovalRequest, ApprovalResponse def approval_func(request: ApprovalRequest) -> ApprovalResponse: \"\"\"Simple approval function that requests user input before code execution.\"\"\" print(f\"Code to execute:\\n{request.code}\") user_input = input(\"Do you approve this code execution? (y/n): \").strip().lower() if user_input == 'y': return ApprovalResponse(approved=True, reason=\"User approved the code execution\") else: return ApprovalResponse(approved=False, reason=\"User denied the code execution\") async def example_usage(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # Enable code execution approval for security m1 = MagenticOne(client=client, approval_func=approval_func) task = \"Write a Python script to fetch data from an API.\" result = await Console(m1.run_stream(task=task)) print(result) if __name__ == \"__main__\": asyncio.run(example_usage()) Architecture# Magentic-One work is based on a multi-agent architecture where a lead Orchestrator agent is responsible for high-level planning, directing other agents and tracking task progress. The Orchestrator begins by creating a plan to tackle the task, gathering needed facts and educated guesses in a Task Ledger that is maintained. At each step of its plan, the Orchestrator creates a Progress Ledger where it self-reflects on task progress and checks whether the task is completed. If the task is not yet completed, it assigns one of Magentic-One other agents a subtask to complete. After the assigned agent completes its subtask, the Orchestrator updates the Progress Ledger and continues in this way until the task is complete. If the Orchestrator finds that progress is not being made for enough steps, it can update the Task Ledger and create a new plan. This is illustrated in the figure above; the Orchestrator work is thus divided into an outer loop where it updates the Task Ledger and an inner loop to update the Progress Ledger. Overall, Magentic-One consists of the following agents: Orchestrator: the lead agent responsible for task decomposition and planning, directing other agents in executing subtasks, tracking overall progress, and taking corrective actions as needed WebSurfer: This is an LLM-based agent that is proficient in commanding and managing the state of a Chromium-based web browser. With each incoming request, the WebSurfer performs an action on the browser then reports on the new state of the web page The action space of the WebSurfer includes navigation (e.g. visiting a URL, performing a web search); web page actions (e.g., clicking and typing); and reading actions (e.g., summarizing or answering questions). The WebSurfer relies on the accessibility tree of the browser and on set-of-marks prompting to perform its actions. FileSurfer: This is an LLM-based agent that commands a markdown-based file preview application to read local files of most types. The FileSurfer can also perform common navigation tasks such as listing the contents of directories and navigating a folder structure. Coder: This is an LLM-based agent specialized through its system prompt for writing code, analyzing information collected from the other agents, or creating new artifacts. ComputerTerminal: Finally, ComputerTerminal provides the team with access to a console shell where the Coder’s programs can be executed, and where new programming libraries can be installed. Together, Magentic-One’s agents provide the Orchestrator with the tools and capabilities that it needs to solve a broad variety of open-ended problems, as well as the ability to autonomously adapt to, and act in, dynamic and ever-changing web and file-system environments. While the default multimodal LLM we use for all agents is GPT-4o, Magentic-One is model agnostic and can incorporate heterogonous models to support different capabilities or meet different cost requirements when getting tasks done. For example, it can use different LLMs and SLMs and their specialized versions to power different agents. We recommend a strong reasoning model for the Orchestrator agent such as GPT-4o. In a different configuration of Magentic-One, we also experiment with using OpenAI o1-preview for the outer loop of the Orchestrator and for the Coder, while other agents continue to use GPT-4o. Citation# @misc{fourney2024magenticonegeneralistmultiagentsolving, title={Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks}, author={Adam Fourney and Gagan Bansal and Hussein Mozannar and Cheng Tan and Eduardo Salinas and Erkang and Zhu and Friederike Niedtner and Grace Proebsting and Griffin Bassman and Jack Gerrits and Jacob Alber and Peter Chang and Ricky Loynd and Robert West and Victor Dibia and Ahmed Awadallah and Ece Kamar and Rafah Hosn and Saleema Amershi}, year={2024}, eprint={2411.04468}, archivePrefix={arXiv}, primaryClass={cs.AI}, url={https://arxiv.org/abs/2411.04468}, } previous Swarm next GraphFlow (Workflows) On this page Getting started Architecture Citation Edit on GitHub Show Source",
      "code": "autogen-core"
    },
    {
      "description": "AgentChat Magentic-One Magentic-One# Magentic-One is a generalist multi-agent system for solving open-ended web and file-based tasks across a variety of domains. It represents a significant step forward for multi-agent systems, achieving competitive performance on a number of agentic benchmarks (see the technical report for full details). When originally released in November 2024 Magentic-One was implemented directly on the autogen-core library. We have now ported Magentic-One to use autogen-agentchat, providing a more modular and easier to use interface. To this end, the Magentic-One orchestrator MagenticOneGroupChat is now simply an AgentChat team, supporting all standard AgentChat agents and features. Likewise, Magentic-One’s MultimodalWebSurfer, FileSurfer, and MagenticOneCoderAgent agents are now broadly available as AgentChat agents, to be used in any AgentChat workflows. Lastly, there is a helper class, MagenticOne, which bundles all of this together as it was in the paper with minimal configuration. Find additional information about Magentic-one in our blog post and technical report. Example: The figure above illustrates Magentic-One multi-agent team completing a complex task from the GAIA benchmark. Magentic-One’s Orchestrator agent creates a plan, delegates tasks to other agents, and tracks progress towards the goal, dynamically revising the plan as needed. The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer agent to operate a web browser, or a Coder or Computer Terminal agent to write or execute code, respectively. Caution Using Magentic-One involves interacting with a digital world designed for humans, which carries inherent risks. To minimize these risks, consider the following precautions: Use Containers: Run all tasks in docker containers to isolate the agents and prevent direct system attacks. Virtual Environment: Use a virtual environment to run the agents and prevent them from accessing sensitive data. Monitor Logs: Closely monitor logs during and after execution to detect and mitigate risky behavior. Human Oversight: Run the examples with a human in the loop to supervise the agents and prevent unintended consequences. Limit Access: Restrict the agents’ access to the internet and other resources to prevent unauthorized actions. Safeguard Data: Ensure that the agents do not have access to sensitive data or resources that could be compromised. Do not share sensitive information with the agents. Be aware that agents may occasionally attempt risky actions, such as recruiting humans for help or accepting cookie agreements without human involvement. Always ensure agents are monitored and operate within a controlled environment to prevent unintended consequences. Moreover, be cautious that Magentic-One may be susceptible to prompt injection attacks from webpages. Getting started# Install the required packages: pip install \"autogen-agentchat\" \"autogen-ext[magentic-one,openai]\" # If using the MultimodalWebSurfer, you also need to install playwright dependencies: playwright install --with-deps chromium If you haven’t done so already, go through the AgentChat tutorial to learn about the concepts of AgentChat. Then, you can try swapping out a autogen_agentchat.teams.SelectorGroupChat with MagenticOneGroupChat. For example: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.teams import MagenticOneGroupChat from autogen_agentchat.ui import Console async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") assistant = AssistantAgent( \"Assistant\", model_client=model_client, ) team = MagenticOneGroupChat([assistant], model_client=model_client) await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\")) await model_client.close() asyncio.run(main()) To use a different model, see Models for more information. Or, use the Magentic-One agents in a team: Caution The example code may download files from the internet, execute code, and interact with web pages. Ensure you are in a safe environment before running the example code. import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_agentchat.teams import MagenticOneGroupChat from autogen_agentchat.ui import Console from autogen_ext.agents.web_surfer import MultimodalWebSurfer # from autogen_ext.agents.file_surfer import FileSurfer # from autogen_ext.agents.magentic_one import MagenticOneCoderAgent # from autogen_agentchat.agents import CodeExecutorAgent # from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") surfer = MultimodalWebSurfer( \"WebSurfer\", model_client=model_client, ) team = MagenticOneGroupChat([surfer], model_client=model_client) await Console(team.run_stream(task=\"What is the UV index in Melbourne today?\")) # # Note: you can also use other agents in the team # team = MagenticOneGroupChat([surfer, file_surfer, coder, terminal], model_client=model_client) # file_surfer = FileSurfer( \"FileSurfer\",model_client=model_client) # coder = MagenticOneCoderAgent(\"Coder\",model_client=model_client) # terminal = CodeExecutorAgent(\"ComputerTerminal\",code_executor=LocalCommandLineCodeExecutor()) asyncio.run(main()) Or, use the MagenticOne helper class with all the agents bundled together: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.teams.magentic_one import MagenticOne from autogen_agentchat.ui import Console from autogen_agentchat.agents import ApprovalRequest, ApprovalResponse def approval_func(request: ApprovalRequest) -> ApprovalResponse: \"\"\"Simple approval function that requests user input before code execution.\"\"\" print(f\"Code to execute:\\n{request.code}\") user_input = input(\"Do you approve this code execution? (y/n): \").strip().lower() if user_input == 'y': return ApprovalResponse(approved=True, reason=\"User approved the code execution\") else: return ApprovalResponse(approved=False, reason=\"User denied the code execution\") async def example_usage(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # Enable code execution approval for security m1 = MagenticOne(client=client, approval_func=approval_func) task = \"Write a Python script to fetch data from an API.\" result = await Console(m1.run_stream(task=task)) print(result) if __name__ == \"__main__\": asyncio.run(example_usage()) Architecture# Magentic-One work is based on a multi-agent architecture where a lead Orchestrator agent is responsible for high-level planning, directing other agents and tracking task progress. The Orchestrator begins by creating a plan to tackle the task, gathering needed facts and educated guesses in a Task Ledger that is maintained. At each step of its plan, the Orchestrator creates a Progress Ledger where it self-reflects on task progress and checks whether the task is completed. If the task is not yet completed, it assigns one of Magentic-One other agents a subtask to complete. After the assigned agent completes its subtask, the Orchestrator updates the Progress Ledger and continues in this way until the task is complete. If the Orchestrator finds that progress is not being made for enough steps, it can update the Task Ledger and create a new plan. This is illustrated in the figure above; the Orchestrator work is thus divided into an outer loop where it updates the Task Ledger and an inner loop to update the Progress Ledger. Overall, Magentic-One consists of the following agents: Orchestrator: the lead agent responsible for task decomposition and planning, directing other agents in executing subtasks, tracking overall progress, and taking corrective actions as needed WebSurfer: This is an LLM-based agent that is proficient in commanding and managing the state of a Chromium-based web browser. With each incoming request, the WebSurfer performs an action on the browser then reports on the new state of the web page The action space of the WebSurfer includes navigation (e.g. visiting a URL, performing a web search); web page actions (e.g., clicking and typing); and reading actions (e.g., summarizing or answering questions). The WebSurfer relies on the accessibility tree of the browser and on set-of-marks prompting to perform its actions. FileSurfer: This is an LLM-based agent that commands a markdown-based file preview application to read local files of most types. The FileSurfer can also perform common navigation tasks such as listing the contents of directories and navigating a folder structure. Coder: This is an LLM-based agent specialized through its system prompt for writing code, analyzing information collected from the other agents, or creating new artifacts. ComputerTerminal: Finally, ComputerTerminal provides the team with access to a console shell where the Coder’s programs can be executed, and where new programming libraries can be installed. Together, Magentic-One’s agents provide the Orchestrator with the tools and capabilities that it needs to solve a broad variety of open-ended problems, as well as the ability to autonomously adapt to, and act in, dynamic and ever-changing web and file-system environments. While the default multimodal LLM we use for all agents is GPT-4o, Magentic-One is model agnostic and can incorporate heterogonous models to support different capabilities or meet different cost requirements when getting tasks done. For example, it can use different LLMs and SLMs and their specialized versions to power different agents. We recommend a strong reasoning model for the Orchestrator agent such as GPT-4o. In a different configuration of Magentic-One, we also experiment with using OpenAI o1-preview for the outer loop of the Orchestrator and for the Coder, while other agents continue to use GPT-4o. Citation# @misc{fourney2024magenticonegeneralistmultiagentsolving, title={Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks}, author={Adam Fourney and Gagan Bansal and Hussein Mozannar and Cheng Tan and Eduardo Salinas and Erkang and Zhu and Friederike Niedtner and Grace Proebsting and Griffin Bassman and Jack Gerrits and Jacob Alber and Peter Chang and Ricky Loynd and Robert West and Victor Dibia and Ahmed Awadallah and Ece Kamar and Rafah Hosn and Saleema Amershi}, year={2024}, eprint={2411.04468}, archivePrefix={arXiv}, primaryClass={cs.AI}, url={https://arxiv.org/abs/2411.04468}, } previous Swarm next GraphFlow (Workflows)",
      "code": "autogen-core"
    },
    {
      "description": "Example: The figure above illustrates Magentic-One multi-agent team completing a complex task from the GAIA benchmark. Magentic-One’s Orchestrator agent creates a plan, delegates tasks to other agents, and tracks progress towards the goal, dynamically revising the plan as needed. The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer agent to operate a web browser, or a Coder or Computer Terminal agent to write or execute code, respectively.",
      "code": "pip install \"autogen-agentchat\" \"autogen-ext[magentic-one,openai]\"\n\n# If using the MultimodalWebSurfer, you also need to install playwright dependencies:\nplaywright install --with-deps chromium"
    },
    {
      "description": "For example:",
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.teams import MagenticOneGroupChat\nfrom autogen_agentchat.ui import Console\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n\n    assistant = AssistantAgent(\n        \"Assistant\",\n        model_client=model_client,\n    )\n    team = MagenticOneGroupChat([assistant], model_client=model_client)\n    await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\"))\n    await model_client.close()\n\n\nasyncio.run(main())"
    }
  ],
  "links": [
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/magentic-one.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/installation.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/quickstart.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/models.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/messages.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/teams.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/human-in-the-loop.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/termination.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/state.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/custom-agents.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/selector-group-chat.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/swarm.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/graph-flow.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/memory.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/logging.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/serialize-components.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tracing.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/travel-planning.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/company-research.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/literature-review.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html"
  ]
}