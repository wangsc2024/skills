{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
  "title": "autogen_ext.models.anthropic — AutoGen",
  "content": "Bases: BaseAnthropicChatCompletionClient, Component[AnthropicClientConfigurationConfigModel]\n\nChat completion client for Anthropic’s Claude models.\n\nmodel (str) – The Claude model to use (e.g., “claude-3-sonnet-20240229”, “claude-3-opus-20240229”)\n\napi_key (str, optional) – Anthropic API key. Required if not in environment variables.\n\nbase_url (str, optional) – Override the default API endpoint.\n\nmax_tokens (int, optional) – Maximum tokens in the response. Default is 4096.\n\ntemperature (float, optional) – Controls randomness. Lower is more deterministic. Default is 1.0.\n\ntop_p (float, optional) – Controls diversity via nucleus sampling. Default is 1.0.\n\ntop_k (int, optional) – Controls diversity via top-k sampling. Default is -1 (disabled).\n\nmodel_info (ModelInfo, optional) – The capabilities of the model. Required if using a custom model.\n\nTo use this client, you must install the Anthropic extension:\n\nTo load the client from a configuration:\n\nThe logical type of the component.\n\nalias of AnthropicClientConfigurationConfigModel\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: BaseAnthropicChatCompletionClient, Component[AnthropicBedrockClientConfigurationConfigModel]\n\nChat completion client for Anthropic’s Claude models on AWS Bedrock.\n\nmodel (str) – The Claude model to use (e.g., “claude-3-sonnet-20240229”, “claude-3-opus-20240229”)\n\napi_key (str, optional) – Anthropic API key. Required if not in environment variables.\n\nbase_url (str, optional) – Override the default API endpoint.\n\nmax_tokens (int, optional) – Maximum tokens in the response. Default is 4096.\n\ntemperature (float, optional) – Controls randomness. Lower is more deterministic. Default is 1.0.\n\ntop_p (float, optional) – Controls diversity via nucleus sampling. Default is 1.0.\n\ntop_k (int, optional) – Controls diversity via top-k sampling. Default is -1 (disabled).\n\nmodel_info (ModelInfo, optional) – The capabilities of the model. Required if using a custom model.\n\nbedrock_info (BedrockInfo, optional) – The capabilities of the model in bedrock. Required if using a model from AWS bedrock.\n\nTo use this client, you must install the Anthropic extension:\n\nThe logical type of the component.\n\nalias of AnthropicBedrockClientConfigurationConfigModel\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: ChatCompletionClient\n\nCreates a single response from the model.\n\nmessages (Sequence[LLMMessage]) – The messages to send to the model.\n\ntools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to [].\n\ntool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”.\n\njson_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt.\n\nextra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}.\n\ncancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None.\n\nCreateResult – The result of the model call.\n\nCreates an AsyncGenerator that yields a stream of completions based on the provided messages and tools.\n\nEstimate the number of tokens used by messages and tools.\n\nNote: This is an estimation based on common tokenization patterns and may not perfectly match Anthropic’s exact token counting for Claude models.\n\nCalculate the remaining tokens based on the model’s token limit.\n\nBases: BaseAnthropicClientConfiguration\n\nBases: AnthropicClientConfiguration\n\nBases: BaseAnthropicClientConfigurationConfigModel\n\nShow JSON schema{ \"title\": \"AnthropicClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"tools\": { \"anyOf\": [ { \"items\": { \"type\": \"object\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tools\" }, \"tool_choice\": { \"anyOf\": [ { \"enum\": [ \"auto\", \"any\", \"none\" ], \"type\": \"string\" }, { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tool Choice\" } }, \"$defs\": { \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] }\n\ntool_choice (Literal['auto', 'any', 'none'] | Dict[str, Any] | None)\n\ntools (List[Dict[str, Any]] | None)\n\nBases: AnthropicClientConfigurationConfigModel\n\nShow JSON schema{ \"title\": \"AnthropicBedrockClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"tools\": { \"anyOf\": [ { \"items\": { \"type\": \"object\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tools\" }, \"tool_choice\": { \"anyOf\": [ { \"enum\": [ \"auto\", \"any\", \"none\" ], \"type\": \"string\" }, { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tool Choice\" }, \"bedrock_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/BedrockInfoConfigModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"BedrockInfoConfigModel\": { \"properties\": { \"aws_access_key\": { \"format\": \"password\", \"title\": \"Aws Access Key\", \"type\": \"string\", \"writeOnly\": true }, \"aws_session_token\": { \"format\": \"password\", \"title\": \"Aws Session Token\", \"type\": \"string\", \"writeOnly\": true }, \"aws_region\": { \"title\": \"Aws Region\", \"type\": \"string\" }, \"aws_secret_key\": { \"format\": \"password\", \"title\": \"Aws Secret Key\", \"type\": \"string\", \"writeOnly\": true } }, \"required\": [ \"aws_access_key\", \"aws_session_token\", \"aws_region\", \"aws_secret_key\" ], \"title\": \"BedrockInfoConfigModel\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] }\n\nbedrock_info (autogen_ext.models.anthropic.config.BedrockInfoConfigModel | None)\n\nShow JSON schema{ \"title\": \"CreateArgumentsConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] }\n\nmax_tokens (int | None)\n\nmetadata (Dict[str, str] | None)\n\nresponse_format (autogen_ext.models.anthropic.config.ResponseFormat | None)\n\nstop_sequences (List[str] | None)\n\ntemperature (float | None)\n\nthinking (autogen_ext.models.anthropic.config.ThinkingConfigModel | None)\n\nBedrockInfo is a dictionary that contains information about a bedrock’s properties. It is expected to be used in the bedrock_info property of a model client.\n\nAccess key for the aws account to gain bedrock model access\n\nAccess secret key for the aws account to gain bedrock model access\n\naws session token for the aws account to gain bedrock model access\n\naws region for the aws account to gain bedrock model access\n\nautogen_ext.memory.redis\n\nautogen_ext.models.azure",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_ext.models.anthropic#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "pip install \"autogen-ext[anthropic]\"",
      "language": "unknown"
    },
    {
      "code": "pip install \"autogen-ext[anthropic]\"",
      "language": "unknown"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.anthropic import AnthropicChatCompletionClient\nfrom autogen_core.models import UserMessage\n\n\nasync def main():\n    anthropic_client = AnthropicChatCompletionClient(\n        model=\"claude-3-sonnet-20240229\",\n        api_key=\"your-api-key\",  # Optional if ANTHROPIC_API_KEY is set in environment\n    )\n\n    result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.anthropic import AnthropicChatCompletionClient\nfrom autogen_core.models import UserMessage\n\n\nasync def main():\n    anthropic_client = AnthropicChatCompletionClient(\n        model=\"claude-3-sonnet-20240229\",\n        api_key=\"your-api-key\",  # Optional if ANTHROPIC_API_KEY is set in environment\n    )\n\n    result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "from autogen_core.models import ChatCompletionClient\n\nconfig = {\n    \"provider\": \"AnthropicChatCompletionClient\",\n    \"config\": {\"model\": \"claude-3-sonnet-20240229\"},\n}\n\nclient = ChatCompletionClient.load_component(config)",
      "language": "json"
    },
    {
      "code": "from autogen_core.models import ChatCompletionClient\n\nconfig = {\n    \"provider\": \"AnthropicChatCompletionClient\",\n    \"config\": {\"model\": \"claude-3-sonnet-20240229\"},\n}\n\nclient = ChatCompletionClient.load_component(config)",
      "language": "json"
    },
    {
      "code": "pip install \"autogen-ext[anthropic]\"",
      "language": "unknown"
    },
    {
      "code": "pip install \"autogen-ext[anthropic]\"",
      "language": "unknown"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo\nfrom autogen_core.models import UserMessage, ModelInfo\n\n\nasync def main():\n    anthropic_client = AnthropicBedrockChatCompletionClient(\n        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        temperature=0.1,\n        model_info=ModelInfo(\n            vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True\n        ),\n        bedrock_info=BedrockInfo(\n            aws_access_key=\"<aws_access_key>\",\n            aws_secret_key=\"<aws_secret_key>\",\n            aws_session_token=\"<aws_session_token>\",\n            aws_region=\"<aws_region>\",\n        ),\n    )\n\n    result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo\nfrom autogen_core.models import UserMessage, ModelInfo\n\n\nasync def main():\n    anthropic_client = AnthropicBedrockChatCompletionClient(\n        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        temperature=0.1,\n        model_info=ModelInfo(\n            vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True\n        ),\n        bedrock_info=BedrockInfo(\n            aws_access_key=\"<aws_access_key>\",\n            aws_secret_key=\"<aws_secret_key>\",\n            aws_session_token=\"<aws_session_token>\",\n            aws_region=\"<aws_region>\",\n        ),\n    )\n\n    result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "{\n   \"title\": \"AnthropicClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 4096,\n         \"title\": \"Max Tokens\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 1.0,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"top_k\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top K\"\n      },\n      \"stop_sequences\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop Sequences\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"metadata\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Metadata\"\n      },\n      \"thinking\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ThinkingConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"base_url\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Base Url\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"tools\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"object\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tools\"\n      },\n      \"tool_choice\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"auto\",\n                  \"any\",\n                  \"none\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tool Choice\"\n      }\n   },\n   \"$defs\": {\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"ThinkingConfigModel\": {\n         \"description\": \"Configuration for thinking mode.\",\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"enabled\",\n                  \"disabled\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"budget_tokens\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Budget Tokens\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ThinkingConfigModel\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AnthropicClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 4096,\n         \"title\": \"Max Tokens\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 1.0,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"top_k\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top K\"\n      },\n      \"stop_sequences\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop Sequences\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"metadata\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Metadata\"\n      },\n      \"thinking\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ThinkingConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"base_url\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Base Url\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"tools\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"object\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tools\"\n      },\n      \"tool_choice\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"auto\",\n                  \"any\",\n                  \"none\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tool Choice\"\n      }\n   },\n   \"$defs\": {\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"ThinkingConfigModel\": {\n         \"description\": \"Configuration for thinking mode.\",\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"enabled\",\n                  \"disabled\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"budget_tokens\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Budget Tokens\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ThinkingConfigModel\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AnthropicBedrockClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 4096,\n         \"title\": \"Max Tokens\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 1.0,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"top_k\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top K\"\n      },\n      \"stop_sequences\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop Sequences\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"metadata\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Metadata\"\n      },\n      \"thinking\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ThinkingConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"base_url\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Base Url\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"tools\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"object\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tools\"\n      },\n      \"tool_choice\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"auto\",\n                  \"any\",\n                  \"none\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tool Choice\"\n      },\n      \"bedrock_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/BedrockInfoConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      }\n   },\n   \"$defs\": {\n      \"BedrockInfoConfigModel\": {\n         \"properties\": {\n            \"aws_access_key\": {\n               \"format\": \"password\",\n               \"title\": \"Aws Access Key\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            \"aws_session_token\": {\n               \"format\": \"password\",\n               \"title\": \"Aws Session Token\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            \"aws_region\": {\n               \"title\": \"Aws Region\",\n               \"type\": \"string\"\n            },\n            \"aws_secret_key\": {\n               \"format\": \"password\",\n               \"title\": \"Aws Secret Key\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            }\n         },\n         \"required\": [\n            \"aws_access_key\",\n            \"aws_session_token\",\n            \"aws_region\",\n            \"aws_secret_key\"\n         ],\n         \"title\": \"BedrockInfoConfigModel\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"ThinkingConfigModel\": {\n         \"description\": \"Configuration for thinking mode.\",\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"enabled\",\n                  \"disabled\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"budget_tokens\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Budget Tokens\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ThinkingConfigModel\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AnthropicBedrockClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 4096,\n         \"title\": \"Max Tokens\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 1.0,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"top_k\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top K\"\n      },\n      \"stop_sequences\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop Sequences\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"metadata\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Metadata\"\n      },\n      \"thinking\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ThinkingConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"base_url\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Base Url\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"tools\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"object\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tools\"\n      },\n      \"tool_choice\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"auto\",\n                  \"any\",\n                  \"none\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Tool Choice\"\n      },\n      \"bedrock_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/BedrockInfoConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      }\n   },\n   \"$defs\": {\n      \"BedrockInfoConfigModel\": {\n         \"properties\": {\n            \"aws_access_key\": {\n               \"format\": \"password\",\n               \"title\": \"Aws Access Key\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            \"aws_session_token\": {\n               \"format\": \"password\",\n               \"title\": \"Aws Session Token\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            \"aws_region\": {\n               \"title\": \"Aws Region\",\n               \"type\": \"string\"\n            },\n            \"aws_secret_key\": {\n               \"format\": \"password\",\n               \"title\": \"Aws Secret Key\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            }\n         },\n         \"required\": [\n            \"aws_access_key\",\n            \"aws_session_token\",\n            \"aws_region\",\n            \"aws_secret_key\"\n         ],\n         \"title\": \"BedrockInfoConfigModel\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"ThinkingConfigModel\": {\n         \"description\": \"Configuration for thinking mode.\",\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"enabled\",\n                  \"disabled\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"budget_tokens\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Budget Tokens\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ThinkingConfigModel\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"CreateArgumentsConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 4096,\n         \"title\": \"Max Tokens\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 1.0,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"top_k\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top K\"\n      },\n      \"stop_sequences\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop Sequences\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"metadata\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Metadata\"\n      },\n      \"thinking\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ThinkingConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      }\n   },\n   \"$defs\": {\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"ThinkingConfigModel\": {\n         \"description\": \"Configuration for thinking mode.\",\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"enabled\",\n                  \"disabled\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"budget_tokens\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Budget Tokens\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ThinkingConfigModel\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"CreateArgumentsConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 4096,\n         \"title\": \"Max Tokens\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": 1.0,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"top_k\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top K\"\n      },\n      \"stop_sequences\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop Sequences\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"metadata\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Metadata\"\n      },\n      \"thinking\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ThinkingConfigModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      }\n   },\n   \"$defs\": {\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"ThinkingConfigModel\": {\n         \"description\": \"Configuration for thinking mode.\",\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"enabled\",\n                  \"disabled\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"budget_tokens\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Budget Tokens\"\n            }\n         },\n         \"required\": [\n            \"type\"\n         ],\n         \"title\": \"ThinkingConfigModel\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    }
  ],
  "patterns": [
    {
      "description": "API Reference autogen_ext.models.anthropic autogen_ext.models.anthropic# class AnthropicChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseAnthropicChatCompletionClient, Component[AnthropicClientConfigurationConfigModel] Chat completion client for Anthropic’s Claude models. Parameters: model (str) – The Claude model to use (e.g., “claude-3-sonnet-20240229”, “claude-3-opus-20240229”) api_key (str, optional) – Anthropic API key. Required if not in environment variables. base_url (str, optional) – Override the default API endpoint. max_tokens (int, optional) – Maximum tokens in the response. Default is 4096. temperature (float, optional) – Controls randomness. Lower is more deterministic. Default is 1.0. top_p (float, optional) – Controls diversity via nucleus sampling. Default is 1.0. top_k (int, optional) – Controls diversity via top-k sampling. Default is -1 (disabled). model_info (ModelInfo, optional) – The capabilities of the model. Required if using a custom model. To use this client, you must install the Anthropic extension: pip install \"autogen-ext[anthropic]\" Example: import asyncio from autogen_ext.models.anthropic import AnthropicChatCompletionClient from autogen_core.models import UserMessage async def main(): anthropic_client = AnthropicChatCompletionClient( model=\"claude-3-sonnet-20240229\", api_key=\"your-api-key\", # Optional if ANTHROPIC_API_KEY is set in environment ) result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")]) # type: ignore print(result) if __name__ == \"__main__\": asyncio.run(main()) To load the client from a configuration: from autogen_core.models import ChatCompletionClient config = { \"provider\": \"AnthropicChatCompletionClient\", \"config\": {\"model\": \"claude-3-sonnet-20240229\"}, } client = ChatCompletionClient.load_component(config) component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of AnthropicClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.anthropic.AnthropicChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → AnthropicClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: AnthropicClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class AnthropicBedrockChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseAnthropicChatCompletionClient, Component[AnthropicBedrockClientConfigurationConfigModel] Chat completion client for Anthropic’s Claude models on AWS Bedrock. Parameters: model (str) – The Claude model to use (e.g., “claude-3-sonnet-20240229”, “claude-3-opus-20240229”) api_key (str, optional) – Anthropic API key. Required if not in environment variables. base_url (str, optional) – Override the default API endpoint. max_tokens (int, optional) – Maximum tokens in the response. Default is 4096. temperature (float, optional) – Controls randomness. Lower is more deterministic. Default is 1.0. top_p (float, optional) – Controls diversity via nucleus sampling. Default is 1.0. top_k (int, optional) – Controls diversity via top-k sampling. Default is -1 (disabled). model_info (ModelInfo, optional) – The capabilities of the model. Required if using a custom model. bedrock_info (BedrockInfo, optional) – The capabilities of the model in bedrock. Required if using a model from AWS bedrock. To use this client, you must install the Anthropic extension: pip install \"autogen-ext[anthropic]\" Example: import asyncio from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo from autogen_core.models import UserMessage, ModelInfo async def main(): anthropic_client = AnthropicBedrockChatCompletionClient( model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", temperature=0.1, model_info=ModelInfo( vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True ), bedrock_info=BedrockInfo( aws_access_key=\"<aws_access_key>\", aws_secret_key=\"<aws_secret_key>\", aws_session_token=\"<aws_session_token>\", aws_region=\"<aws_region>\", ), ) result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")]) # type: ignore print(result) if __name__ == \"__main__\": asyncio.run(main()) component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of AnthropicBedrockClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.anthropic.AnthropicBedrockChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → AnthropicBedrockClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: AnthropicBedrockClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class BaseAnthropicChatCompletionClient(client: Any, *, create_args: Dict[str, Any], model_info: ModelInfo | None = None)[source]# Bases: ChatCompletionClient async create(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → CreateResult[source]# Creates a single response from the model. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: CreateResult – The result of the model call. async create_stream(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None, max_consecutive_empty_chunk_tolerance: int = 0) → AsyncGenerator[str | CreateResult, None][source]# Creates an AsyncGenerator that yields a stream of completions based on the provided messages and tools. async close() → None[source]# count_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# Estimate the number of tokens used by messages and tools. Note: This is an estimation based on common tokenization patterns and may not perfectly match Anthropic’s exact token counting for Claude models. remaining_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# Calculate the remaining tokens based on the model’s token limit. actual_usage() → RequestUsage[source]# total_usage() → RequestUsage[source]# property capabilities: ModelCapabilities# property model_info: ModelInfo# class AnthropicClientConfiguration[source]# Bases: BaseAnthropicClientConfiguration tools: List[Dict[str, Any]] | None# tool_choice: Literal['auto', 'any', 'none'] | Dict[str, Any] | None# model: str# max_tokens: int | None# temperature: float | None# top_p: float | None# top_k: int | None# stop_sequences: List[str] | None# response_format: ResponseFormat | None# metadata: Dict[str, str] | None# thinking: ThinkingConfig | None# api_key: str# base_url: str | None# model_capabilities: ModelCapabilities# model_info: ModelInfo# timeout: float | None# max_retries: int | None# default_headers: Dict[str, str] | None# class AnthropicBedrockClientConfiguration[source]# Bases: AnthropicClientConfiguration bedrock_info: BedrockInfo# model: str# max_tokens: int | None# temperature: float | None# top_p: float | None# top_k: int | None# stop_sequences: List[str] | None# response_format: ResponseFormat | None# metadata: Dict[str, str] | None# thinking: ThinkingConfig | None# api_key: str# base_url: str | None# model_capabilities: ModelCapabilities# model_info: ModelInfo# timeout: float | None# max_retries: int | None# default_headers: Dict[str, str] | None# tools: List[Dict[str, Any]] | None# tool_choice: Literal['auto', 'any', 'none'] | Dict[str, Any] | None# pydantic model AnthropicClientConfigurationConfigModel[source]# Bases: BaseAnthropicClientConfigurationConfigModel Show JSON schema{ \"title\": \"AnthropicClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"tools\": { \"anyOf\": [ { \"items\": { \"type\": \"object\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tools\" }, \"tool_choice\": { \"anyOf\": [ { \"enum\": [ \"auto\", \"any\", \"none\" ], \"type\": \"string\" }, { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tool Choice\" } }, \"$defs\": { \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: tool_choice (Literal['auto', 'any', 'none'] | Dict[str, Any] | None) tools (List[Dict[str, Any]] | None) field tools: List[Dict[str, Any]] | None = None# field tool_choice: Literal['auto', 'any', 'none'] | Dict[str, Any] | None = None# pydantic model AnthropicBedrockClientConfigurationConfigModel[source]# Bases: AnthropicClientConfigurationConfigModel Show JSON schema{ \"title\": \"AnthropicBedrockClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"tools\": { \"anyOf\": [ { \"items\": { \"type\": \"object\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tools\" }, \"tool_choice\": { \"anyOf\": [ { \"enum\": [ \"auto\", \"any\", \"none\" ], \"type\": \"string\" }, { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tool Choice\" }, \"bedrock_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/BedrockInfoConfigModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"BedrockInfoConfigModel\": { \"properties\": { \"aws_access_key\": { \"format\": \"password\", \"title\": \"Aws Access Key\", \"type\": \"string\", \"writeOnly\": true }, \"aws_session_token\": { \"format\": \"password\", \"title\": \"Aws Session Token\", \"type\": \"string\", \"writeOnly\": true }, \"aws_region\": { \"title\": \"Aws Region\", \"type\": \"string\" }, \"aws_secret_key\": { \"format\": \"password\", \"title\": \"Aws Secret Key\", \"type\": \"string\", \"writeOnly\": true } }, \"required\": [ \"aws_access_key\", \"aws_session_token\", \"aws_region\", \"aws_secret_key\" ], \"title\": \"BedrockInfoConfigModel\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: bedrock_info (autogen_ext.models.anthropic.config.BedrockInfoConfigModel | None) field bedrock_info: BedrockInfoConfigModel | None = None# pydantic model CreateArgumentsConfigModel[source]# Bases: BaseModel Show JSON schema{ \"title\": \"CreateArgumentsConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: max_tokens (int | None) metadata (Dict[str, str] | None) model (str) response_format (autogen_ext.models.anthropic.config.ResponseFormat | None) stop_sequences (List[str] | None) temperature (float | None) thinking (autogen_ext.models.anthropic.config.ThinkingConfigModel | None) top_k (int | None) top_p (float | None) field model: str [Required]# field max_tokens: int | None = 4096# field temperature: float | None = 1.0# field top_p: float | None = None# field top_k: int | None = None# field stop_sequences: List[str] | None = None# field response_format: ResponseFormat | None = None# field metadata: Dict[str, str] | None = None# field thinking: ThinkingConfigModel | None = None# class BedrockInfo[source]# Bases: TypedDict BedrockInfo is a dictionary that contains information about a bedrock’s properties. It is expected to be used in the bedrock_info property of a model client. aws_access_key: Required[str]# Access key for the aws account to gain bedrock model access aws_secret_key: Required[str]# Access secret key for the aws account to gain bedrock model access aws_session_token: Required[str]# aws session token for the aws account to gain bedrock model access aws_region: Required[str]# aws region for the aws account to gain bedrock model access previous autogen_ext.memory.redis next autogen_ext.models.azure On this page AnthropicChatCompletionClient AnthropicChatCompletionClient.component_type AnthropicChatCompletionClient.component_config_schema AnthropicChatCompletionClient.component_provider_override AnthropicChatCompletionClient._to_config() AnthropicChatCompletionClient._from_config() AnthropicBedrockChatCompletionClient AnthropicBedrockChatCompletionClient.component_type AnthropicBedrockChatCompletionClient.component_config_schema AnthropicBedrockChatCompletionClient.component_provider_override AnthropicBedrockChatCompletionClient._to_config() AnthropicBedrockChatCompletionClient._from_config() BaseAnthropicChatCompletionClient BaseAnthropicChatCompletionClient.create() BaseAnthropicChatCompletionClient.create_stream() BaseAnthropicChatCompletionClient.close() BaseAnthropicChatCompletionClient.count_tokens() BaseAnthropicChatCompletionClient.remaining_tokens() BaseAnthropicChatCompletionClient.actual_usage() BaseAnthropicChatCompletionClient.total_usage() BaseAnthropicChatCompletionClient.capabilities BaseAnthropicChatCompletionClient.model_info AnthropicClientConfiguration AnthropicClientConfiguration.tools AnthropicClientConfiguration.tool_choice AnthropicClientConfiguration.model AnthropicClientConfiguration.max_tokens AnthropicClientConfiguration.temperature AnthropicClientConfiguration.top_p AnthropicClientConfiguration.top_k AnthropicClientConfiguration.stop_sequences AnthropicClientConfiguration.response_format AnthropicClientConfiguration.metadata AnthropicClientConfiguration.thinking AnthropicClientConfiguration.api_key AnthropicClientConfiguration.base_url AnthropicClientConfiguration.model_capabilities AnthropicClientConfiguration.model_info AnthropicClientConfiguration.timeout AnthropicClientConfiguration.max_retries AnthropicClientConfiguration.default_headers AnthropicBedrockClientConfiguration AnthropicBedrockClientConfiguration.bedrock_info AnthropicBedrockClientConfiguration.model AnthropicBedrockClientConfiguration.max_tokens AnthropicBedrockClientConfiguration.temperature AnthropicBedrockClientConfiguration.top_p AnthropicBedrockClientConfiguration.top_k AnthropicBedrockClientConfiguration.stop_sequences AnthropicBedrockClientConfiguration.response_format AnthropicBedrockClientConfiguration.metadata AnthropicBedrockClientConfiguration.thinking AnthropicBedrockClientConfiguration.api_key AnthropicBedrockClientConfiguration.base_url AnthropicBedrockClientConfiguration.model_capabilities AnthropicBedrockClientConfiguration.model_info AnthropicBedrockClientConfiguration.timeout AnthropicBedrockClientConfiguration.max_retries AnthropicBedrockClientConfiguration.default_headers AnthropicBedrockClientConfiguration.tools AnthropicBedrockClientConfiguration.tool_choice AnthropicClientConfigurationConfigModel AnthropicClientConfigurationConfigModel.tools AnthropicClientConfigurationConfigModel.tool_choice AnthropicBedrockClientConfigurationConfigModel AnthropicBedrockClientConfigurationConfigModel.bedrock_info CreateArgumentsConfigModel CreateArgumentsConfigModel.model CreateArgumentsConfigModel.max_tokens CreateArgumentsConfigModel.temperature CreateArgumentsConfigModel.top_p CreateArgumentsConfigModel.top_k CreateArgumentsConfigModel.stop_sequences CreateArgumentsConfigModel.response_format CreateArgumentsConfigModel.metadata CreateArgumentsConfigModel.thinking BedrockInfo BedrockInfo.aws_access_key BedrockInfo.aws_secret_key BedrockInfo.aws_session_token BedrockInfo.aws_region Edit on GitHub Show Source",
      "code": "BaseAnthropicChatCompletionClient"
    },
    {
      "description": "API Reference autogen_ext.models.anthropic autogen_ext.models.anthropic# class AnthropicChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseAnthropicChatCompletionClient, Component[AnthropicClientConfigurationConfigModel] Chat completion client for Anthropic’s Claude models. Parameters: model (str) – The Claude model to use (e.g., “claude-3-sonnet-20240229”, “claude-3-opus-20240229”) api_key (str, optional) – Anthropic API key. Required if not in environment variables. base_url (str, optional) – Override the default API endpoint. max_tokens (int, optional) – Maximum tokens in the response. Default is 4096. temperature (float, optional) – Controls randomness. Lower is more deterministic. Default is 1.0. top_p (float, optional) – Controls diversity via nucleus sampling. Default is 1.0. top_k (int, optional) – Controls diversity via top-k sampling. Default is -1 (disabled). model_info (ModelInfo, optional) – The capabilities of the model. Required if using a custom model. To use this client, you must install the Anthropic extension: pip install \"autogen-ext[anthropic]\" Example: import asyncio from autogen_ext.models.anthropic import AnthropicChatCompletionClient from autogen_core.models import UserMessage async def main(): anthropic_client = AnthropicChatCompletionClient( model=\"claude-3-sonnet-20240229\", api_key=\"your-api-key\", # Optional if ANTHROPIC_API_KEY is set in environment ) result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")]) # type: ignore print(result) if __name__ == \"__main__\": asyncio.run(main()) To load the client from a configuration: from autogen_core.models import ChatCompletionClient config = { \"provider\": \"AnthropicChatCompletionClient\", \"config\": {\"model\": \"claude-3-sonnet-20240229\"}, } client = ChatCompletionClient.load_component(config) component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of AnthropicClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.anthropic.AnthropicChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → AnthropicClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: AnthropicClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class AnthropicBedrockChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseAnthropicChatCompletionClient, Component[AnthropicBedrockClientConfigurationConfigModel] Chat completion client for Anthropic’s Claude models on AWS Bedrock. Parameters: model (str) – The Claude model to use (e.g., “claude-3-sonnet-20240229”, “claude-3-opus-20240229”) api_key (str, optional) – Anthropic API key. Required if not in environment variables. base_url (str, optional) – Override the default API endpoint. max_tokens (int, optional) – Maximum tokens in the response. Default is 4096. temperature (float, optional) – Controls randomness. Lower is more deterministic. Default is 1.0. top_p (float, optional) – Controls diversity via nucleus sampling. Default is 1.0. top_k (int, optional) – Controls diversity via top-k sampling. Default is -1 (disabled). model_info (ModelInfo, optional) – The capabilities of the model. Required if using a custom model. bedrock_info (BedrockInfo, optional) – The capabilities of the model in bedrock. Required if using a model from AWS bedrock. To use this client, you must install the Anthropic extension: pip install \"autogen-ext[anthropic]\" Example: import asyncio from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo from autogen_core.models import UserMessage, ModelInfo async def main(): anthropic_client = AnthropicBedrockChatCompletionClient( model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", temperature=0.1, model_info=ModelInfo( vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True ), bedrock_info=BedrockInfo( aws_access_key=\"<aws_access_key>\", aws_secret_key=\"<aws_secret_key>\", aws_session_token=\"<aws_session_token>\", aws_region=\"<aws_region>\", ), ) result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")]) # type: ignore print(result) if __name__ == \"__main__\": asyncio.run(main()) component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of AnthropicBedrockClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.anthropic.AnthropicBedrockChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → AnthropicBedrockClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: AnthropicBedrockClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class BaseAnthropicChatCompletionClient(client: Any, *, create_args: Dict[str, Any], model_info: ModelInfo | None = None)[source]# Bases: ChatCompletionClient async create(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → CreateResult[source]# Creates a single response from the model. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: CreateResult – The result of the model call. async create_stream(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None, max_consecutive_empty_chunk_tolerance: int = 0) → AsyncGenerator[str | CreateResult, None][source]# Creates an AsyncGenerator that yields a stream of completions based on the provided messages and tools. async close() → None[source]# count_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# Estimate the number of tokens used by messages and tools. Note: This is an estimation based on common tokenization patterns and may not perfectly match Anthropic’s exact token counting for Claude models. remaining_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# Calculate the remaining tokens based on the model’s token limit. actual_usage() → RequestUsage[source]# total_usage() → RequestUsage[source]# property capabilities: ModelCapabilities# property model_info: ModelInfo# class AnthropicClientConfiguration[source]# Bases: BaseAnthropicClientConfiguration tools: List[Dict[str, Any]] | None# tool_choice: Literal['auto', 'any', 'none'] | Dict[str, Any] | None# model: str# max_tokens: int | None# temperature: float | None# top_p: float | None# top_k: int | None# stop_sequences: List[str] | None# response_format: ResponseFormat | None# metadata: Dict[str, str] | None# thinking: ThinkingConfig | None# api_key: str# base_url: str | None# model_capabilities: ModelCapabilities# model_info: ModelInfo# timeout: float | None# max_retries: int | None# default_headers: Dict[str, str] | None# class AnthropicBedrockClientConfiguration[source]# Bases: AnthropicClientConfiguration bedrock_info: BedrockInfo# model: str# max_tokens: int | None# temperature: float | None# top_p: float | None# top_k: int | None# stop_sequences: List[str] | None# response_format: ResponseFormat | None# metadata: Dict[str, str] | None# thinking: ThinkingConfig | None# api_key: str# base_url: str | None# model_capabilities: ModelCapabilities# model_info: ModelInfo# timeout: float | None# max_retries: int | None# default_headers: Dict[str, str] | None# tools: List[Dict[str, Any]] | None# tool_choice: Literal['auto', 'any', 'none'] | Dict[str, Any] | None# pydantic model AnthropicClientConfigurationConfigModel[source]# Bases: BaseAnthropicClientConfigurationConfigModel Show JSON schema{ \"title\": \"AnthropicClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"tools\": { \"anyOf\": [ { \"items\": { \"type\": \"object\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tools\" }, \"tool_choice\": { \"anyOf\": [ { \"enum\": [ \"auto\", \"any\", \"none\" ], \"type\": \"string\" }, { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tool Choice\" } }, \"$defs\": { \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: tool_choice (Literal['auto', 'any', 'none'] | Dict[str, Any] | None) tools (List[Dict[str, Any]] | None) field tools: List[Dict[str, Any]] | None = None# field tool_choice: Literal['auto', 'any', 'none'] | Dict[str, Any] | None = None# pydantic model AnthropicBedrockClientConfigurationConfigModel[source]# Bases: AnthropicClientConfigurationConfigModel Show JSON schema{ \"title\": \"AnthropicBedrockClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"tools\": { \"anyOf\": [ { \"items\": { \"type\": \"object\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tools\" }, \"tool_choice\": { \"anyOf\": [ { \"enum\": [ \"auto\", \"any\", \"none\" ], \"type\": \"string\" }, { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Tool Choice\" }, \"bedrock_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/BedrockInfoConfigModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"BedrockInfoConfigModel\": { \"properties\": { \"aws_access_key\": { \"format\": \"password\", \"title\": \"Aws Access Key\", \"type\": \"string\", \"writeOnly\": true }, \"aws_session_token\": { \"format\": \"password\", \"title\": \"Aws Session Token\", \"type\": \"string\", \"writeOnly\": true }, \"aws_region\": { \"title\": \"Aws Region\", \"type\": \"string\" }, \"aws_secret_key\": { \"format\": \"password\", \"title\": \"Aws Secret Key\", \"type\": \"string\", \"writeOnly\": true } }, \"required\": [ \"aws_access_key\", \"aws_session_token\", \"aws_region\", \"aws_secret_key\" ], \"title\": \"BedrockInfoConfigModel\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: bedrock_info (autogen_ext.models.anthropic.config.BedrockInfoConfigModel | None) field bedrock_info: BedrockInfoConfigModel | None = None# pydantic model CreateArgumentsConfigModel[source]# Bases: BaseModel Show JSON schema{ \"title\": \"CreateArgumentsConfigModel\", \"type\": \"object\", \"properties\": { \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": 4096, \"title\": \"Max Tokens\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": 1.0, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"top_k\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top K\" }, \"stop_sequences\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop Sequences\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"metadata\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Metadata\" }, \"thinking\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ThinkingConfigModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\" ], \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"type\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"ThinkingConfigModel\": { \"description\": \"Configuration for thinking mode.\", \"properties\": { \"type\": { \"enum\": [ \"enabled\", \"disabled\" ], \"title\": \"Type\", \"type\": \"string\" }, \"budget_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Budget Tokens\" } }, \"required\": [ \"type\" ], \"title\": \"ThinkingConfigModel\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: max_tokens (int | None) metadata (Dict[str, str] | None) model (str) response_format (autogen_ext.models.anthropic.config.ResponseFormat | None) stop_sequences (List[str] | None) temperature (float | None) thinking (autogen_ext.models.anthropic.config.ThinkingConfigModel | None) top_k (int | None) top_p (float | None) field model: str [Required]# field max_tokens: int | None = 4096# field temperature: float | None = 1.0# field top_p: float | None = None# field top_k: int | None = None# field stop_sequences: List[str] | None = None# field response_format: ResponseFormat | None = None# field metadata: Dict[str, str] | None = None# field thinking: ThinkingConfigModel | None = None# class BedrockInfo[source]# Bases: TypedDict BedrockInfo is a dictionary that contains information about a bedrock’s properties. It is expected to be used in the bedrock_info property of a model client. aws_access_key: Required[str]# Access key for the aws account to gain bedrock model access aws_secret_key: Required[str]# Access secret key for the aws account to gain bedrock model access aws_session_token: Required[str]# aws session token for the aws account to gain bedrock model access aws_region: Required[str]# aws region for the aws account to gain bedrock model access previous autogen_ext.memory.redis next autogen_ext.models.azure",
      "code": "BaseAnthropicChatCompletionClient"
    },
    {
      "description": "Example:",
      "code": "import asyncio\nfrom autogen_ext.models.anthropic import AnthropicChatCompletionClient\nfrom autogen_core.models import UserMessage\n\n\nasync def main():\n    anthropic_client = AnthropicChatCompletionClient(\n        model=\"claude-3-sonnet-20240229\",\n        api_key=\"your-api-key\",  # Optional if ANTHROPIC_API_KEY is set in environment\n    )\n\n    result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
    },
    {
      "description": "Example:",
      "code": "import asyncio\nfrom autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo\nfrom autogen_core.models import UserMessage, ModelInfo\n\n\nasync def main():\n    anthropic_client = AnthropicBedrockChatCompletionClient(\n        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        temperature=0.1,\n        model_info=ModelInfo(\n            vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True\n        ),\n        bedrock_info=BedrockInfo(\n            aws_access_key=\"<aws_access_key>\",\n            aws_secret_key=\"<aws_secret_key>\",\n            aws_session_token=\"<aws_session_token>\",\n            aws_region=\"<aws_region>\",\n        ),\n    )\n\n    result = await anthropic_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
    }
  ],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}