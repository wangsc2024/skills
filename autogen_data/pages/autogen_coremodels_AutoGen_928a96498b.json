{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
  "title": "autogen_core.models — AutoGen",
  "content": "Bases: ComponentBase[BaseModel], ABC\n\nCreates a single response from the model.\n\nmessages (Sequence[LLMMessage]) – The messages to send to the model.\n\ntools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to [].\n\ntool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”.\n\njson_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt.\n\nextra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}.\n\ncancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None.\n\nCreateResult – The result of the model call.\n\nCreates a stream of string chunks from the model ending with a CreateResult.\n\nmessages (Sequence[LLMMessage]) – The messages to send to the model.\n\ntools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to [].\n\ntool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”.\n\njson_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt.\n\nWhether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt.\n\nextra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}.\n\ncancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None.\n\nAsyncGenerator[Union[str, CreateResult], None] – A generator that yields string chunks and ends with a CreateResult.\n\nSystem message contains instructions for the model coming from the developer.\n\nOpen AI is moving away from using ‘system’ role in favor of ‘developer’ role. See Model Spec for more details. However, the ‘system’ role is still allowed in their API and will be automatically converted to ‘developer’ role on the server side. So, you can use SystemMessage for developer messages.\n\nShow JSON schema{ \"title\": \"SystemMessage\", \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n Open AI is moving away from using 'system' role in favor of 'developer' role.\\n See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n on the server side.\\n So, you can use `SystemMessage` for developer messages.\", \"type\": \"object\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"type\": { \"const\": \"SystemMessage\", \"default\": \"SystemMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\" ] }\n\ntype (Literal['SystemMessage'])\n\nThe content of the message.\n\nUser message contains input from end users, or a catch-all for data provided to the model.\n\nShow JSON schema{ \"title\": \"UserMessage\", \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\", \"type\": \"object\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"anyOf\": [ { \"type\": \"string\" }, {} ] }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"UserMessage\", \"default\": \"UserMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\", \"source\" ] }\n\ncontent (str | List[str | autogen_core._image.Image])\n\ntype (Literal['UserMessage'])\n\nThe content of the message.\n\nThe name of the agent that sent this message.\n\nAssistant message are sampled from the language model.\n\nShow JSON schema{ \"title\": \"AssistantMessage\", \"description\": \"Assistant message are sampled from the language model.\", \"type\": \"object\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"AssistantMessage\", \"default\": \"AssistantMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"$defs\": { \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" } }, \"required\": [ \"content\", \"source\" ] }\n\ncontent (str | List[autogen_core._types.FunctionCall])\n\ntype (Literal['AssistantMessage'])\n\nThe content of the message.\n\nThe reasoning text for the completion if available. Used for reasoning model and additional text content besides function calls.\n\nThe name of the agent that sent this message.\n\nFunction execution result contains the output of a function call.\n\nShow JSON schema{ \"title\": \"FunctionExecutionResult\", \"description\": \"Function execution result contains the output of a function call.\", \"type\": \"object\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ] }\n\nis_error (bool | None)\n\nThe output of the function call.\n\n(New in v0.4.8) The name of the function that was called.\n\nThe ID of the function call. Note this ID may be empty for some models.\n\nWhether the function call resulted in an error.\n\nFunction execution result message contains the output of multiple function calls.\n\nShow JSON schema{ \"title\": \"FunctionExecutionResultMessage\", \"description\": \"Function execution result message contains the output of multiple function calls.\", \"type\": \"object\", \"properties\": { \"content\": { \"items\": { \"$ref\": \"#/$defs/FunctionExecutionResult\" }, \"title\": \"Content\", \"type\": \"array\" }, \"type\": { \"const\": \"FunctionExecutionResultMessage\", \"default\": \"FunctionExecutionResultMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"$defs\": { \"FunctionExecutionResult\": { \"description\": \"Function execution result contains the output of a function call.\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ], \"title\": \"FunctionExecutionResult\", \"type\": \"object\" } }, \"required\": [ \"content\" ] }\n\ncontent (List[autogen_core.models._types.FunctionExecutionResult])\n\ntype (Literal['FunctionExecutionResultMessage'])\n\nCreate result contains the output of a model completion.\n\nShow JSON schema{ \"title\": \"CreateResult\", \"description\": \"Create result contains the output of a model completion.\", \"type\": \"object\", \"properties\": { \"finish_reason\": { \"enum\": [ \"stop\", \"length\", \"function_calls\", \"content_filter\", \"unknown\" ], \"title\": \"Finish Reason\", \"type\": \"string\" }, \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"usage\": { \"$ref\": \"#/$defs/RequestUsage\" }, \"cached\": { \"title\": \"Cached\", \"type\": \"boolean\" }, \"logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/ChatCompletionTokenLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logprobs\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" } }, \"$defs\": { \"ChatCompletionTokenLogprob\": { \"properties\": { \"token\": { \"title\": \"Token\", \"type\": \"string\" }, \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"top_logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/TopLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top Logprobs\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"token\", \"logprob\" ], \"title\": \"ChatCompletionTokenLogprob\", \"type\": \"object\" }, \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" }, \"RequestUsage\": { \"properties\": { \"prompt_tokens\": { \"title\": \"Prompt Tokens\", \"type\": \"integer\" }, \"completion_tokens\": { \"title\": \"Completion Tokens\", \"type\": \"integer\" } }, \"required\": [ \"prompt_tokens\", \"completion_tokens\" ], \"title\": \"RequestUsage\", \"type\": \"object\" }, \"TopLogprob\": { \"properties\": { \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"logprob\" ], \"title\": \"TopLogprob\", \"type\": \"object\" } }, \"required\": [ \"finish_reason\", \"content\", \"usage\", \"cached\" ] }\n\ncontent (str | List[autogen_core._types.FunctionCall])\n\nfinish_reason (Literal['stop', 'length', 'function_calls', 'content_filter', 'unknown'])\n\nlogprobs (List[autogen_core.models._types.ChatCompletionTokenLogprob] | None)\n\nusage (autogen_core.models._types.RequestUsage)\n\nThe reason the model finished generating the completion.\n\nThe output of the model completion.\n\nThe usage of tokens in the prompt and completion.\n\nWhether the completion was generated from a cached response.\n\nThe logprobs of the tokens in the completion.\n\nThe reasoning text for the completion if available. Used for reasoning models and additional text content besides function calls.\n\nShow JSON schema{ \"title\": \"ChatCompletionTokenLogprob\", \"type\": \"object\", \"properties\": { \"token\": { \"title\": \"Token\", \"type\": \"string\" }, \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"top_logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/TopLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top Logprobs\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"$defs\": { \"TopLogprob\": { \"properties\": { \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"logprob\" ], \"title\": \"TopLogprob\", \"type\": \"object\" } }, \"required\": [ \"token\", \"logprob\" ] }\n\nbytes (List[int] | None)\n\ntop_logprobs (List[autogen_core.models._types.TopLogprob] | None)\n\nA model family is a group of models that share similar characteristics from a capabilities perspective. This is different to discrete supported features such as vision, function calling, and JSON output.\n\nThis namespace class holds constants for the model families that AutoGen understands. Other families definitely exist and can be represented by a string, however, AutoGen will treat them as unknown.\n\nalias of Literal[‘gpt-5’, ‘gpt-41’, ‘gpt-45’, ‘gpt-4o’, ‘o1’, ‘o3’, ‘o4’, ‘gpt-4’, ‘gpt-35’, ‘r1’, ‘gemini-1.5-flash’, ‘gemini-1.5-pro’, ‘gemini-2.0-flash’, ‘gemini-2.5-pro’, ‘gemini-2.5-flash’, ‘claude-3-haiku’, ‘claude-3-sonnet’, ‘claude-3-opus’, ‘claude-3-5-haiku’, ‘claude-3-5-sonnet’, ‘claude-3-7-sonnet’, ‘claude-4-opus’, ‘claude-4-sonnet’, ‘llama-3.3-8b’, ‘llama-3.3-70b’, ‘llama-4-scout’, ‘llama-4-maverick’, ‘codestral’, ‘open-codestral-mamba’, ‘mistral’, ‘ministral’, ‘pixtral’, ‘unknown’]\n\nModelInfo is a dictionary that contains information about a model’s properties. It is expected to be used in the model_info property of a model client.\n\nWe are expecting this to grow over time as we add more features.\n\nTrue if the model supports vision, aka image input, otherwise False.\n\nTrue if the model supports function calling, otherwise False.\n\nthis is different to structured json.\n\nTrue if the model supports json output, otherwise False. Note\n\nModel family should be one of the constants from ModelFamily or a string representing an unknown model family.\n\nTrue if the model supports structured output, otherwise False. This is different to json_output.\n\nTrue if the model supports multiple, non-consecutive system messages, otherwise False.\n\nValidates the model info dictionary.\n\nValueError – If the model info dictionary is missing required fields.\n\nautogen_core.model_context\n\nautogen_core.tool_agent",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_core.models#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "{\n   \"title\": \"SystemMessage\",\n   \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n    Open AI is moving away from using 'system' role in favor of 'developer' role.\\n    See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n    However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n    on the server side.\\n    So, you can use `SystemMessage` for developer messages.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"title\": \"Content\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"SystemMessage\",\n         \"default\": \"SystemMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"required\": [\n      \"content\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"SystemMessage\",\n   \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n    Open AI is moving away from using 'system' role in favor of 'developer' role.\\n    See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n    However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n    on the server side.\\n    So, you can use `SystemMessage` for developer messages.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"title\": \"Content\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"SystemMessage\",\n         \"default\": \"SystemMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"required\": [\n      \"content\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"UserMessage\",\n   \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"anyOf\": [\n                     {\n                        \"type\": \"string\"\n                     },\n                     {}\n                  ]\n               },\n               \"type\": \"array\"\n            }\n         ],\n         \"title\": \"Content\"\n      },\n      \"source\": {\n         \"title\": \"Source\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"UserMessage\",\n         \"default\": \"UserMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"required\": [\n      \"content\",\n      \"source\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"UserMessage\",\n   \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"anyOf\": [\n                     {\n                        \"type\": \"string\"\n                     },\n                     {}\n                  ]\n               },\n               \"type\": \"array\"\n            }\n         ],\n         \"title\": \"Content\"\n      },\n      \"source\": {\n         \"title\": \"Source\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"UserMessage\",\n         \"default\": \"UserMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"required\": [\n      \"content\",\n      \"source\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AssistantMessage\",\n   \"description\": \"Assistant message are sampled from the language model.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/FunctionCall\"\n               },\n               \"type\": \"array\"\n            }\n         ],\n         \"title\": \"Content\"\n      },\n      \"thought\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Thought\"\n      },\n      \"source\": {\n         \"title\": \"Source\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"AssistantMessage\",\n         \"default\": \"AssistantMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"$defs\": {\n      \"FunctionCall\": {\n         \"properties\": {\n            \"id\": {\n               \"title\": \"Id\",\n               \"type\": \"string\"\n            },\n            \"arguments\": {\n               \"title\": \"Arguments\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"id\",\n            \"arguments\",\n            \"name\"\n         ],\n         \"title\": \"FunctionCall\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"content\",\n      \"source\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AssistantMessage\",\n   \"description\": \"Assistant message are sampled from the language model.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/FunctionCall\"\n               },\n               \"type\": \"array\"\n            }\n         ],\n         \"title\": \"Content\"\n      },\n      \"thought\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Thought\"\n      },\n      \"source\": {\n         \"title\": \"Source\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"AssistantMessage\",\n         \"default\": \"AssistantMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"$defs\": {\n      \"FunctionCall\": {\n         \"properties\": {\n            \"id\": {\n               \"title\": \"Id\",\n               \"type\": \"string\"\n            },\n            \"arguments\": {\n               \"title\": \"Arguments\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"id\",\n            \"arguments\",\n            \"name\"\n         ],\n         \"title\": \"FunctionCall\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"content\",\n      \"source\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"FunctionExecutionResult\",\n   \"description\": \"Function execution result contains the output of a function call.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"title\": \"Content\",\n         \"type\": \"string\"\n      },\n      \"name\": {\n         \"title\": \"Name\",\n         \"type\": \"string\"\n      },\n      \"call_id\": {\n         \"title\": \"Call Id\",\n         \"type\": \"string\"\n      },\n      \"is_error\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Is Error\"\n      }\n   },\n   \"required\": [\n      \"content\",\n      \"name\",\n      \"call_id\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"FunctionExecutionResult\",\n   \"description\": \"Function execution result contains the output of a function call.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"title\": \"Content\",\n         \"type\": \"string\"\n      },\n      \"name\": {\n         \"title\": \"Name\",\n         \"type\": \"string\"\n      },\n      \"call_id\": {\n         \"title\": \"Call Id\",\n         \"type\": \"string\"\n      },\n      \"is_error\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Is Error\"\n      }\n   },\n   \"required\": [\n      \"content\",\n      \"name\",\n      \"call_id\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"FunctionExecutionResultMessage\",\n   \"description\": \"Function execution result message contains the output of multiple function calls.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"items\": {\n            \"$ref\": \"#/$defs/FunctionExecutionResult\"\n         },\n         \"title\": \"Content\",\n         \"type\": \"array\"\n      },\n      \"type\": {\n         \"const\": \"FunctionExecutionResultMessage\",\n         \"default\": \"FunctionExecutionResultMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"$defs\": {\n      \"FunctionExecutionResult\": {\n         \"description\": \"Function execution result contains the output of a function call.\",\n         \"properties\": {\n            \"content\": {\n               \"title\": \"Content\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"call_id\": {\n               \"title\": \"Call Id\",\n               \"type\": \"string\"\n            },\n            \"is_error\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Is Error\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"name\",\n            \"call_id\"\n         ],\n         \"title\": \"FunctionExecutionResult\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"content\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"FunctionExecutionResultMessage\",\n   \"description\": \"Function execution result message contains the output of multiple function calls.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"content\": {\n         \"items\": {\n            \"$ref\": \"#/$defs/FunctionExecutionResult\"\n         },\n         \"title\": \"Content\",\n         \"type\": \"array\"\n      },\n      \"type\": {\n         \"const\": \"FunctionExecutionResultMessage\",\n         \"default\": \"FunctionExecutionResultMessage\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      }\n   },\n   \"$defs\": {\n      \"FunctionExecutionResult\": {\n         \"description\": \"Function execution result contains the output of a function call.\",\n         \"properties\": {\n            \"content\": {\n               \"title\": \"Content\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"call_id\": {\n               \"title\": \"Call Id\",\n               \"type\": \"string\"\n            },\n            \"is_error\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Is Error\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"name\",\n            \"call_id\"\n         ],\n         \"title\": \"FunctionExecutionResult\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"content\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"CreateResult\",\n   \"description\": \"Create result contains the output of a model completion.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"finish_reason\": {\n         \"enum\": [\n            \"stop\",\n            \"length\",\n            \"function_calls\",\n            \"content_filter\",\n            \"unknown\"\n         ],\n         \"title\": \"Finish Reason\",\n         \"type\": \"string\"\n      },\n      \"content\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/FunctionCall\"\n               },\n               \"type\": \"array\"\n            }\n         ],\n         \"title\": \"Content\"\n      },\n      \"usage\": {\n         \"$ref\": \"#/$defs/RequestUsage\"\n      },\n      \"cached\": {\n         \"title\": \"Cached\",\n         \"type\": \"boolean\"\n      },\n      \"logprobs\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/ChatCompletionTokenLogprob\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logprobs\"\n      },\n      \"thought\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Thought\"\n      }\n   },\n   \"$defs\": {\n      \"ChatCompletionTokenLogprob\": {\n         \"properties\": {\n            \"token\": {\n               \"title\": \"Token\",\n               \"type\": \"string\"\n            },\n            \"logprob\": {\n               \"title\": \"Logprob\",\n               \"type\": \"number\"\n            },\n            \"top_logprobs\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"$ref\": \"#/$defs/TopLogprob\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Top Logprobs\"\n            },\n            \"bytes\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"type\": \"integer\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Bytes\"\n            }\n         },\n         \"required\": [\n            \"token\",\n            \"logprob\"\n         ],\n         \"title\": \"ChatCompletionTokenLogprob\",\n         \"type\": \"object\"\n      },\n      \"FunctionCall\": {\n         \"properties\": {\n            \"id\": {\n               \"title\": \"Id\",\n               \"type\": \"string\"\n            },\n            \"arguments\": {\n               \"title\": \"Arguments\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"id\",\n            \"arguments\",\n            \"name\"\n         ],\n         \"title\": \"FunctionCall\",\n         \"type\": \"object\"\n      },\n      \"RequestUsage\": {\n         \"properties\": {\n            \"prompt_tokens\": {\n               \"title\": \"Prompt Tokens\",\n               \"type\": \"integer\"\n            },\n            \"completion_tokens\": {\n               \"title\": \"Completion Tokens\",\n               \"type\": \"integer\"\n            }\n         },\n         \"required\": [\n            \"prompt_tokens\",\n            \"completion_tokens\"\n         ],\n         \"title\": \"RequestUsage\",\n         \"type\": \"object\"\n      },\n      \"TopLogprob\": {\n         \"properties\": {\n            \"logprob\": {\n               \"title\": \"Logprob\",\n               \"type\": \"number\"\n            },\n            \"bytes\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"type\": \"integer\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Bytes\"\n            }\n         },\n         \"required\": [\n            \"logprob\"\n         ],\n         \"title\": \"TopLogprob\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"finish_reason\",\n      \"content\",\n      \"usage\",\n      \"cached\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"CreateResult\",\n   \"description\": \"Create result contains the output of a model completion.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"finish_reason\": {\n         \"enum\": [\n            \"stop\",\n            \"length\",\n            \"function_calls\",\n            \"content_filter\",\n            \"unknown\"\n         ],\n         \"title\": \"Finish Reason\",\n         \"type\": \"string\"\n      },\n      \"content\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/FunctionCall\"\n               },\n               \"type\": \"array\"\n            }\n         ],\n         \"title\": \"Content\"\n      },\n      \"usage\": {\n         \"$ref\": \"#/$defs/RequestUsage\"\n      },\n      \"cached\": {\n         \"title\": \"Cached\",\n         \"type\": \"boolean\"\n      },\n      \"logprobs\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/ChatCompletionTokenLogprob\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logprobs\"\n      },\n      \"thought\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Thought\"\n      }\n   },\n   \"$defs\": {\n      \"ChatCompletionTokenLogprob\": {\n         \"properties\": {\n            \"token\": {\n               \"title\": \"Token\",\n               \"type\": \"string\"\n            },\n            \"logprob\": {\n               \"title\": \"Logprob\",\n               \"type\": \"number\"\n            },\n            \"top_logprobs\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"$ref\": \"#/$defs/TopLogprob\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Top Logprobs\"\n            },\n            \"bytes\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"type\": \"integer\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Bytes\"\n            }\n         },\n         \"required\": [\n            \"token\",\n            \"logprob\"\n         ],\n         \"title\": \"ChatCompletionTokenLogprob\",\n         \"type\": \"object\"\n      },\n      \"FunctionCall\": {\n         \"properties\": {\n            \"id\": {\n               \"title\": \"Id\",\n               \"type\": \"string\"\n            },\n            \"arguments\": {\n               \"title\": \"Arguments\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"id\",\n            \"arguments\",\n            \"name\"\n         ],\n         \"title\": \"FunctionCall\",\n         \"type\": \"object\"\n      },\n      \"RequestUsage\": {\n         \"properties\": {\n            \"prompt_tokens\": {\n               \"title\": \"Prompt Tokens\",\n               \"type\": \"integer\"\n            },\n            \"completion_tokens\": {\n               \"title\": \"Completion Tokens\",\n               \"type\": \"integer\"\n            }\n         },\n         \"required\": [\n            \"prompt_tokens\",\n            \"completion_tokens\"\n         ],\n         \"title\": \"RequestUsage\",\n         \"type\": \"object\"\n      },\n      \"TopLogprob\": {\n         \"properties\": {\n            \"logprob\": {\n               \"title\": \"Logprob\",\n               \"type\": \"number\"\n            },\n            \"bytes\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"type\": \"integer\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Bytes\"\n            }\n         },\n         \"required\": [\n            \"logprob\"\n         ],\n         \"title\": \"TopLogprob\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"finish_reason\",\n      \"content\",\n      \"usage\",\n      \"cached\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"ChatCompletionTokenLogprob\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"token\": {\n         \"title\": \"Token\",\n         \"type\": \"string\"\n      },\n      \"logprob\": {\n         \"title\": \"Logprob\",\n         \"type\": \"number\"\n      },\n      \"top_logprobs\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/TopLogprob\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top Logprobs\"\n      },\n      \"bytes\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Bytes\"\n      }\n   },\n   \"$defs\": {\n      \"TopLogprob\": {\n         \"properties\": {\n            \"logprob\": {\n               \"title\": \"Logprob\",\n               \"type\": \"number\"\n            },\n            \"bytes\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"type\": \"integer\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Bytes\"\n            }\n         },\n         \"required\": [\n            \"logprob\"\n         ],\n         \"title\": \"TopLogprob\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"token\",\n      \"logprob\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"ChatCompletionTokenLogprob\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"token\": {\n         \"title\": \"Token\",\n         \"type\": \"string\"\n      },\n      \"logprob\": {\n         \"title\": \"Logprob\",\n         \"type\": \"number\"\n      },\n      \"top_logprobs\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"$ref\": \"#/$defs/TopLogprob\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top Logprobs\"\n      },\n      \"bytes\": {\n         \"anyOf\": [\n            {\n               \"items\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Bytes\"\n      }\n   },\n   \"$defs\": {\n      \"TopLogprob\": {\n         \"properties\": {\n            \"logprob\": {\n               \"title\": \"Logprob\",\n               \"type\": \"number\"\n            },\n            \"bytes\": {\n               \"anyOf\": [\n                  {\n                     \"items\": {\n                        \"type\": \"integer\"\n                     },\n                     \"type\": \"array\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Bytes\"\n            }\n         },\n         \"required\": [\n            \"logprob\"\n         ],\n         \"title\": \"TopLogprob\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"token\",\n      \"logprob\"\n   ]\n}",
      "language": "json"
    }
  ],
  "patterns": [
    {
      "description": "API Reference autogen_core.models autogen_core.models# class ModelCapabilities(**kwargs)[source]# Bases: TypedDict vision: Required[bool]# function_calling: Required[bool]# json_output: Required[bool]# class ChatCompletionClient[source]# Bases: ComponentBase[BaseModel], ABC abstract async create(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → CreateResult[source]# Creates a single response from the model. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: CreateResult – The result of the model call. abstract create_stream(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → AsyncGenerator[str | CreateResult, None][source]# Creates a stream of string chunks from the model ending with a CreateResult. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: AsyncGenerator[Union[str, CreateResult], None] – A generator that yields string chunks and ends with a CreateResult. abstract async close() → None[source]# abstract actual_usage() → RequestUsage[source]# abstract total_usage() → RequestUsage[source]# abstract count_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# abstract remaining_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# abstract property capabilities: ModelCapabilities# abstract property model_info: ModelInfo# pydantic model SystemMessage[source]# Bases: BaseModel System message contains instructions for the model coming from the developer. Note Open AI is moving away from using ‘system’ role in favor of ‘developer’ role. See Model Spec for more details. However, the ‘system’ role is still allowed in their API and will be automatically converted to ‘developer’ role on the server side. So, you can use SystemMessage for developer messages. Show JSON schema{ \"title\": \"SystemMessage\", \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n Open AI is moving away from using 'system' role in favor of 'developer' role.\\n See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n on the server side.\\n So, you can use `SystemMessage` for developer messages.\", \"type\": \"object\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"type\": { \"const\": \"SystemMessage\", \"default\": \"SystemMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\" ] } Fields: content (str) type (Literal['SystemMessage']) field content: str [Required]# The content of the message. field type: Literal['SystemMessage'] = 'SystemMessage'# pydantic model UserMessage[source]# Bases: BaseModel User message contains input from end users, or a catch-all for data provided to the model. Show JSON schema{ \"title\": \"UserMessage\", \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\", \"type\": \"object\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"anyOf\": [ { \"type\": \"string\" }, {} ] }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"UserMessage\", \"default\": \"UserMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\", \"source\" ] } Fields: content (str | List[str | autogen_core._image.Image]) source (str) type (Literal['UserMessage']) field content: str | List[str | Image] [Required]# The content of the message. field source: str [Required]# The name of the agent that sent this message. field type: Literal['UserMessage'] = 'UserMessage'# pydantic model AssistantMessage[source]# Bases: BaseModel Assistant message are sampled from the language model. Show JSON schema{ \"title\": \"AssistantMessage\", \"description\": \"Assistant message are sampled from the language model.\", \"type\": \"object\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"AssistantMessage\", \"default\": \"AssistantMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"$defs\": { \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" } }, \"required\": [ \"content\", \"source\" ] } Fields: content (str | List[autogen_core._types.FunctionCall]) source (str) thought (str | None) type (Literal['AssistantMessage']) field content: str | List[FunctionCall] [Required]# The content of the message. field thought: str | None = None# The reasoning text for the completion if available. Used for reasoning model and additional text content besides function calls. field source: str [Required]# The name of the agent that sent this message. field type: Literal['AssistantMessage'] = 'AssistantMessage'# pydantic model FunctionExecutionResult[source]# Bases: BaseModel Function execution result contains the output of a function call. Show JSON schema{ \"title\": \"FunctionExecutionResult\", \"description\": \"Function execution result contains the output of a function call.\", \"type\": \"object\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ] } Fields: call_id (str) content (str) is_error (bool | None) name (str) field content: str [Required]# The output of the function call. field name: str [Required]# (New in v0.4.8) The name of the function that was called. field call_id: str [Required]# The ID of the function call. Note this ID may be empty for some models. field is_error: bool | None = None# Whether the function call resulted in an error. pydantic model FunctionExecutionResultMessage[source]# Bases: BaseModel Function execution result message contains the output of multiple function calls. Show JSON schema{ \"title\": \"FunctionExecutionResultMessage\", \"description\": \"Function execution result message contains the output of multiple function calls.\", \"type\": \"object\", \"properties\": { \"content\": { \"items\": { \"$ref\": \"#/$defs/FunctionExecutionResult\" }, \"title\": \"Content\", \"type\": \"array\" }, \"type\": { \"const\": \"FunctionExecutionResultMessage\", \"default\": \"FunctionExecutionResultMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"$defs\": { \"FunctionExecutionResult\": { \"description\": \"Function execution result contains the output of a function call.\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ], \"title\": \"FunctionExecutionResult\", \"type\": \"object\" } }, \"required\": [ \"content\" ] } Fields: content (List[autogen_core.models._types.FunctionExecutionResult]) type (Literal['FunctionExecutionResultMessage']) field content: List[FunctionExecutionResult] [Required]# field type: Literal['FunctionExecutionResultMessage'] = 'FunctionExecutionResultMessage'# class RequestUsage(prompt_tokens: int, completion_tokens: int)[source]# Bases: object prompt_tokens: int# completion_tokens: int# pydantic model CreateResult[source]# Bases: BaseModel Create result contains the output of a model completion. Show JSON schema{ \"title\": \"CreateResult\", \"description\": \"Create result contains the output of a model completion.\", \"type\": \"object\", \"properties\": { \"finish_reason\": { \"enum\": [ \"stop\", \"length\", \"function_calls\", \"content_filter\", \"unknown\" ], \"title\": \"Finish Reason\", \"type\": \"string\" }, \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"usage\": { \"$ref\": \"#/$defs/RequestUsage\" }, \"cached\": { \"title\": \"Cached\", \"type\": \"boolean\" }, \"logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/ChatCompletionTokenLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logprobs\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" } }, \"$defs\": { \"ChatCompletionTokenLogprob\": { \"properties\": { \"token\": { \"title\": \"Token\", \"type\": \"string\" }, \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"top_logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/TopLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top Logprobs\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"token\", \"logprob\" ], \"title\": \"ChatCompletionTokenLogprob\", \"type\": \"object\" }, \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" }, \"RequestUsage\": { \"properties\": { \"prompt_tokens\": { \"title\": \"Prompt Tokens\", \"type\": \"integer\" }, \"completion_tokens\": { \"title\": \"Completion Tokens\", \"type\": \"integer\" } }, \"required\": [ \"prompt_tokens\", \"completion_tokens\" ], \"title\": \"RequestUsage\", \"type\": \"object\" }, \"TopLogprob\": { \"properties\": { \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"logprob\" ], \"title\": \"TopLogprob\", \"type\": \"object\" } }, \"required\": [ \"finish_reason\", \"content\", \"usage\", \"cached\" ] } Fields: cached (bool) content (str | List[autogen_core._types.FunctionCall]) finish_reason (Literal['stop', 'length', 'function_calls', 'content_filter', 'unknown']) logprobs (List[autogen_core.models._types.ChatCompletionTokenLogprob] | None) thought (str | None) usage (autogen_core.models._types.RequestUsage) field finish_reason: Literal['stop', 'length', 'function_calls', 'content_filter', 'unknown'] [Required]# The reason the model finished generating the completion. field content: str | List[FunctionCall] [Required]# The output of the model completion. field usage: RequestUsage [Required]# The usage of tokens in the prompt and completion. field cached: bool [Required]# Whether the completion was generated from a cached response. field logprobs: List[ChatCompletionTokenLogprob] | None = None# The logprobs of the tokens in the completion. field thought: str | None = None# The reasoning text for the completion if available. Used for reasoning models and additional text content besides function calls. class TopLogprob(logprob: float, bytes: List[int] | None = None)[source]# Bases: object logprob: float# bytes: List[int] | None = None# pydantic model ChatCompletionTokenLogprob[source]# Bases: BaseModel Show JSON schema{ \"title\": \"ChatCompletionTokenLogprob\", \"type\": \"object\", \"properties\": { \"token\": { \"title\": \"Token\", \"type\": \"string\" }, \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"top_logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/TopLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top Logprobs\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"$defs\": { \"TopLogprob\": { \"properties\": { \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"logprob\" ], \"title\": \"TopLogprob\", \"type\": \"object\" } }, \"required\": [ \"token\", \"logprob\" ] } Fields: bytes (List[int] | None) logprob (float) token (str) top_logprobs (List[autogen_core.models._types.TopLogprob] | None) field token: str [Required]# field logprob: float [Required]# field top_logprobs: List[TopLogprob] | None = None# field bytes: List[int] | None = None# class ModelFamily(*args: Any, **kwargs: Any)[source]# Bases: object A model family is a group of models that share similar characteristics from a capabilities perspective. This is different to discrete supported features such as vision, function calling, and JSON output. This namespace class holds constants for the model families that AutoGen understands. Other families definitely exist and can be represented by a string, however, AutoGen will treat them as unknown. GPT_5 = 'gpt-5'# GPT_41 = 'gpt-41'# GPT_45 = 'gpt-45'# GPT_4O = 'gpt-4o'# O1 = 'o1'# O3 = 'o3'# O4 = 'o4'# GPT_4 = 'gpt-4'# GPT_35 = 'gpt-35'# R1 = 'r1'# GEMINI_1_5_FLASH = 'gemini-1.5-flash'# GEMINI_1_5_PRO = 'gemini-1.5-pro'# GEMINI_2_0_FLASH = 'gemini-2.0-flash'# GEMINI_2_5_PRO = 'gemini-2.5-pro'# GEMINI_2_5_FLASH = 'gemini-2.5-flash'# CLAUDE_3_HAIKU = 'claude-3-haiku'# CLAUDE_3_SONNET = 'claude-3-sonnet'# CLAUDE_3_OPUS = 'claude-3-opus'# CLAUDE_3_5_HAIKU = 'claude-3-5-haiku'# CLAUDE_3_5_SONNET = 'claude-3-5-sonnet'# CLAUDE_3_7_SONNET = 'claude-3-7-sonnet'# CLAUDE_4_OPUS = 'claude-4-opus'# CLAUDE_4_SONNET = 'claude-4-sonnet'# LLAMA_3_3_8B = 'llama-3.3-8b'# LLAMA_3_3_70B = 'llama-3.3-70b'# LLAMA_4_SCOUT = 'llama-4-scout'# LLAMA_4_MAVERICK = 'llama-4-maverick'# CODESRAL = 'codestral'# OPEN_CODESRAL_MAMBA = 'open-codestral-mamba'# MISTRAL = 'mistral'# MINISTRAL = 'ministral'# PIXTRAL = 'pixtral'# UNKNOWN = 'unknown'# ANY# alias of Literal[‘gpt-5’, ‘gpt-41’, ‘gpt-45’, ‘gpt-4o’, ‘o1’, ‘o3’, ‘o4’, ‘gpt-4’, ‘gpt-35’, ‘r1’, ‘gemini-1.5-flash’, ‘gemini-1.5-pro’, ‘gemini-2.0-flash’, ‘gemini-2.5-pro’, ‘gemini-2.5-flash’, ‘claude-3-haiku’, ‘claude-3-sonnet’, ‘claude-3-opus’, ‘claude-3-5-haiku’, ‘claude-3-5-sonnet’, ‘claude-3-7-sonnet’, ‘claude-4-opus’, ‘claude-4-sonnet’, ‘llama-3.3-8b’, ‘llama-3.3-70b’, ‘llama-4-scout’, ‘llama-4-maverick’, ‘codestral’, ‘open-codestral-mamba’, ‘mistral’, ‘ministral’, ‘pixtral’, ‘unknown’] static is_claude(family: str) → bool[source]# static is_gemini(family: str) → bool[source]# static is_openai(family: str) → bool[source]# static is_llama(family: str) → bool[source]# static is_mistral(family: str) → bool[source]# class ModelInfo[source]# Bases: TypedDict ModelInfo is a dictionary that contains information about a model’s properties. It is expected to be used in the model_info property of a model client. We are expecting this to grow over time as we add more features. vision: Required[bool]# True if the model supports vision, aka image input, otherwise False. function_calling: Required[bool]# True if the model supports function calling, otherwise False. json_output: Required[bool]# this is different to structured json. Type: True if the model supports json output, otherwise False. Note family: Required[Literal['gpt-5', 'gpt-41', 'gpt-45', 'gpt-4o', 'o1', 'o3', 'o4', 'gpt-4', 'gpt-35', 'r1', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-2.0-flash', 'gemini-2.5-pro', 'gemini-2.5-flash', 'claude-3-haiku', 'claude-3-sonnet', 'claude-3-opus', 'claude-3-5-haiku', 'claude-3-5-sonnet', 'claude-3-7-sonnet', 'claude-4-opus', 'claude-4-sonnet', 'llama-3.3-8b', 'llama-3.3-70b', 'llama-4-scout', 'llama-4-maverick', 'codestral', 'open-codestral-mamba', 'mistral', 'ministral', 'pixtral', 'unknown'] | str]# Model family should be one of the constants from ModelFamily or a string representing an unknown model family. structured_output: Required[bool]# True if the model supports structured output, otherwise False. This is different to json_output. multiple_system_messages: bool | None# True if the model supports multiple, non-consecutive system messages, otherwise False. validate_model_info(model_info: ModelInfo) → None[source]# Validates the model info dictionary. Raises: ValueError – If the model info dictionary is missing required fields. previous autogen_core.model_context next autogen_core.tool_agent On this page ModelCapabilities ModelCapabilities.vision ModelCapabilities.function_calling ModelCapabilities.json_output ChatCompletionClient ChatCompletionClient.create() ChatCompletionClient.create_stream() ChatCompletionClient.close() ChatCompletionClient.actual_usage() ChatCompletionClient.total_usage() ChatCompletionClient.count_tokens() ChatCompletionClient.remaining_tokens() ChatCompletionClient.capabilities ChatCompletionClient.model_info SystemMessage SystemMessage.content SystemMessage.type UserMessage UserMessage.content UserMessage.source UserMessage.type AssistantMessage AssistantMessage.content AssistantMessage.thought AssistantMessage.source AssistantMessage.type FunctionExecutionResult FunctionExecutionResult.content FunctionExecutionResult.name FunctionExecutionResult.call_id FunctionExecutionResult.is_error FunctionExecutionResultMessage FunctionExecutionResultMessage.content FunctionExecutionResultMessage.type RequestUsage RequestUsage.prompt_tokens RequestUsage.completion_tokens CreateResult CreateResult.finish_reason CreateResult.content CreateResult.usage CreateResult.cached CreateResult.logprobs CreateResult.thought TopLogprob TopLogprob.logprob TopLogprob.bytes ChatCompletionTokenLogprob ChatCompletionTokenLogprob.token ChatCompletionTokenLogprob.logprob ChatCompletionTokenLogprob.top_logprobs ChatCompletionTokenLogprob.bytes ModelFamily ModelFamily.GPT_5 ModelFamily.GPT_41 ModelFamily.GPT_45 ModelFamily.GPT_4O ModelFamily.O1 ModelFamily.O3 ModelFamily.O4 ModelFamily.GPT_4 ModelFamily.GPT_35 ModelFamily.R1 ModelFamily.GEMINI_1_5_FLASH ModelFamily.GEMINI_1_5_PRO ModelFamily.GEMINI_2_0_FLASH ModelFamily.GEMINI_2_5_PRO ModelFamily.GEMINI_2_5_FLASH ModelFamily.CLAUDE_3_HAIKU ModelFamily.CLAUDE_3_SONNET ModelFamily.CLAUDE_3_OPUS ModelFamily.CLAUDE_3_5_HAIKU ModelFamily.CLAUDE_3_5_SONNET ModelFamily.CLAUDE_3_7_SONNET ModelFamily.CLAUDE_4_OPUS ModelFamily.CLAUDE_4_SONNET ModelFamily.LLAMA_3_3_8B ModelFamily.LLAMA_3_3_70B ModelFamily.LLAMA_4_SCOUT ModelFamily.LLAMA_4_MAVERICK ModelFamily.CODESRAL ModelFamily.OPEN_CODESRAL_MAMBA ModelFamily.MISTRAL ModelFamily.MINISTRAL ModelFamily.PIXTRAL ModelFamily.UNKNOWN ModelFamily.ANY ModelFamily.is_claude() ModelFamily.is_gemini() ModelFamily.is_openai() ModelFamily.is_llama() ModelFamily.is_mistral() ModelInfo ModelInfo.vision ModelInfo.function_calling ModelInfo.json_output ModelInfo.family ModelInfo.structured_output ModelInfo.multiple_system_messages validate_model_info() Edit on GitHub Show Source",
      "code": "TypedDict"
    },
    {
      "description": "API Reference autogen_core.models autogen_core.models# class ModelCapabilities(**kwargs)[source]# Bases: TypedDict vision: Required[bool]# function_calling: Required[bool]# json_output: Required[bool]# class ChatCompletionClient[source]# Bases: ComponentBase[BaseModel], ABC abstract async create(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → CreateResult[source]# Creates a single response from the model. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: CreateResult – The result of the model call. abstract create_stream(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → AsyncGenerator[str | CreateResult, None][source]# Creates a stream of string chunks from the model ending with a CreateResult. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: AsyncGenerator[Union[str, CreateResult], None] – A generator that yields string chunks and ends with a CreateResult. abstract async close() → None[source]# abstract actual_usage() → RequestUsage[source]# abstract total_usage() → RequestUsage[source]# abstract count_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# abstract remaining_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# abstract property capabilities: ModelCapabilities# abstract property model_info: ModelInfo# pydantic model SystemMessage[source]# Bases: BaseModel System message contains instructions for the model coming from the developer. Note Open AI is moving away from using ‘system’ role in favor of ‘developer’ role. See Model Spec for more details. However, the ‘system’ role is still allowed in their API and will be automatically converted to ‘developer’ role on the server side. So, you can use SystemMessage for developer messages. Show JSON schema{ \"title\": \"SystemMessage\", \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n Open AI is moving away from using 'system' role in favor of 'developer' role.\\n See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n on the server side.\\n So, you can use `SystemMessage` for developer messages.\", \"type\": \"object\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"type\": { \"const\": \"SystemMessage\", \"default\": \"SystemMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\" ] } Fields: content (str) type (Literal['SystemMessage']) field content: str [Required]# The content of the message. field type: Literal['SystemMessage'] = 'SystemMessage'# pydantic model UserMessage[source]# Bases: BaseModel User message contains input from end users, or a catch-all for data provided to the model. Show JSON schema{ \"title\": \"UserMessage\", \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\", \"type\": \"object\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"anyOf\": [ { \"type\": \"string\" }, {} ] }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"UserMessage\", \"default\": \"UserMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\", \"source\" ] } Fields: content (str | List[str | autogen_core._image.Image]) source (str) type (Literal['UserMessage']) field content: str | List[str | Image] [Required]# The content of the message. field source: str [Required]# The name of the agent that sent this message. field type: Literal['UserMessage'] = 'UserMessage'# pydantic model AssistantMessage[source]# Bases: BaseModel Assistant message are sampled from the language model. Show JSON schema{ \"title\": \"AssistantMessage\", \"description\": \"Assistant message are sampled from the language model.\", \"type\": \"object\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"AssistantMessage\", \"default\": \"AssistantMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"$defs\": { \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" } }, \"required\": [ \"content\", \"source\" ] } Fields: content (str | List[autogen_core._types.FunctionCall]) source (str) thought (str | None) type (Literal['AssistantMessage']) field content: str | List[FunctionCall] [Required]# The content of the message. field thought: str | None = None# The reasoning text for the completion if available. Used for reasoning model and additional text content besides function calls. field source: str [Required]# The name of the agent that sent this message. field type: Literal['AssistantMessage'] = 'AssistantMessage'# pydantic model FunctionExecutionResult[source]# Bases: BaseModel Function execution result contains the output of a function call. Show JSON schema{ \"title\": \"FunctionExecutionResult\", \"description\": \"Function execution result contains the output of a function call.\", \"type\": \"object\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ] } Fields: call_id (str) content (str) is_error (bool | None) name (str) field content: str [Required]# The output of the function call. field name: str [Required]# (New in v0.4.8) The name of the function that was called. field call_id: str [Required]# The ID of the function call. Note this ID may be empty for some models. field is_error: bool | None = None# Whether the function call resulted in an error. pydantic model FunctionExecutionResultMessage[source]# Bases: BaseModel Function execution result message contains the output of multiple function calls. Show JSON schema{ \"title\": \"FunctionExecutionResultMessage\", \"description\": \"Function execution result message contains the output of multiple function calls.\", \"type\": \"object\", \"properties\": { \"content\": { \"items\": { \"$ref\": \"#/$defs/FunctionExecutionResult\" }, \"title\": \"Content\", \"type\": \"array\" }, \"type\": { \"const\": \"FunctionExecutionResultMessage\", \"default\": \"FunctionExecutionResultMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"$defs\": { \"FunctionExecutionResult\": { \"description\": \"Function execution result contains the output of a function call.\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ], \"title\": \"FunctionExecutionResult\", \"type\": \"object\" } }, \"required\": [ \"content\" ] } Fields: content (List[autogen_core.models._types.FunctionExecutionResult]) type (Literal['FunctionExecutionResultMessage']) field content: List[FunctionExecutionResult] [Required]# field type: Literal['FunctionExecutionResultMessage'] = 'FunctionExecutionResultMessage'# class RequestUsage(prompt_tokens: int, completion_tokens: int)[source]# Bases: object prompt_tokens: int# completion_tokens: int# pydantic model CreateResult[source]# Bases: BaseModel Create result contains the output of a model completion. Show JSON schema{ \"title\": \"CreateResult\", \"description\": \"Create result contains the output of a model completion.\", \"type\": \"object\", \"properties\": { \"finish_reason\": { \"enum\": [ \"stop\", \"length\", \"function_calls\", \"content_filter\", \"unknown\" ], \"title\": \"Finish Reason\", \"type\": \"string\" }, \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"usage\": { \"$ref\": \"#/$defs/RequestUsage\" }, \"cached\": { \"title\": \"Cached\", \"type\": \"boolean\" }, \"logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/ChatCompletionTokenLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logprobs\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" } }, \"$defs\": { \"ChatCompletionTokenLogprob\": { \"properties\": { \"token\": { \"title\": \"Token\", \"type\": \"string\" }, \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"top_logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/TopLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top Logprobs\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"token\", \"logprob\" ], \"title\": \"ChatCompletionTokenLogprob\", \"type\": \"object\" }, \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" }, \"RequestUsage\": { \"properties\": { \"prompt_tokens\": { \"title\": \"Prompt Tokens\", \"type\": \"integer\" }, \"completion_tokens\": { \"title\": \"Completion Tokens\", \"type\": \"integer\" } }, \"required\": [ \"prompt_tokens\", \"completion_tokens\" ], \"title\": \"RequestUsage\", \"type\": \"object\" }, \"TopLogprob\": { \"properties\": { \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"logprob\" ], \"title\": \"TopLogprob\", \"type\": \"object\" } }, \"required\": [ \"finish_reason\", \"content\", \"usage\", \"cached\" ] } Fields: cached (bool) content (str | List[autogen_core._types.FunctionCall]) finish_reason (Literal['stop', 'length', 'function_calls', 'content_filter', 'unknown']) logprobs (List[autogen_core.models._types.ChatCompletionTokenLogprob] | None) thought (str | None) usage (autogen_core.models._types.RequestUsage) field finish_reason: Literal['stop', 'length', 'function_calls', 'content_filter', 'unknown'] [Required]# The reason the model finished generating the completion. field content: str | List[FunctionCall] [Required]# The output of the model completion. field usage: RequestUsage [Required]# The usage of tokens in the prompt and completion. field cached: bool [Required]# Whether the completion was generated from a cached response. field logprobs: List[ChatCompletionTokenLogprob] | None = None# The logprobs of the tokens in the completion. field thought: str | None = None# The reasoning text for the completion if available. Used for reasoning models and additional text content besides function calls. class TopLogprob(logprob: float, bytes: List[int] | None = None)[source]# Bases: object logprob: float# bytes: List[int] | None = None# pydantic model ChatCompletionTokenLogprob[source]# Bases: BaseModel Show JSON schema{ \"title\": \"ChatCompletionTokenLogprob\", \"type\": \"object\", \"properties\": { \"token\": { \"title\": \"Token\", \"type\": \"string\" }, \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"top_logprobs\": { \"anyOf\": [ { \"items\": { \"$ref\": \"#/$defs/TopLogprob\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top Logprobs\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"$defs\": { \"TopLogprob\": { \"properties\": { \"logprob\": { \"title\": \"Logprob\", \"type\": \"number\" }, \"bytes\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Bytes\" } }, \"required\": [ \"logprob\" ], \"title\": \"TopLogprob\", \"type\": \"object\" } }, \"required\": [ \"token\", \"logprob\" ] } Fields: bytes (List[int] | None) logprob (float) token (str) top_logprobs (List[autogen_core.models._types.TopLogprob] | None) field token: str [Required]# field logprob: float [Required]# field top_logprobs: List[TopLogprob] | None = None# field bytes: List[int] | None = None# class ModelFamily(*args: Any, **kwargs: Any)[source]# Bases: object A model family is a group of models that share similar characteristics from a capabilities perspective. This is different to discrete supported features such as vision, function calling, and JSON output. This namespace class holds constants for the model families that AutoGen understands. Other families definitely exist and can be represented by a string, however, AutoGen will treat them as unknown. GPT_5 = 'gpt-5'# GPT_41 = 'gpt-41'# GPT_45 = 'gpt-45'# GPT_4O = 'gpt-4o'# O1 = 'o1'# O3 = 'o3'# O4 = 'o4'# GPT_4 = 'gpt-4'# GPT_35 = 'gpt-35'# R1 = 'r1'# GEMINI_1_5_FLASH = 'gemini-1.5-flash'# GEMINI_1_5_PRO = 'gemini-1.5-pro'# GEMINI_2_0_FLASH = 'gemini-2.0-flash'# GEMINI_2_5_PRO = 'gemini-2.5-pro'# GEMINI_2_5_FLASH = 'gemini-2.5-flash'# CLAUDE_3_HAIKU = 'claude-3-haiku'# CLAUDE_3_SONNET = 'claude-3-sonnet'# CLAUDE_3_OPUS = 'claude-3-opus'# CLAUDE_3_5_HAIKU = 'claude-3-5-haiku'# CLAUDE_3_5_SONNET = 'claude-3-5-sonnet'# CLAUDE_3_7_SONNET = 'claude-3-7-sonnet'# CLAUDE_4_OPUS = 'claude-4-opus'# CLAUDE_4_SONNET = 'claude-4-sonnet'# LLAMA_3_3_8B = 'llama-3.3-8b'# LLAMA_3_3_70B = 'llama-3.3-70b'# LLAMA_4_SCOUT = 'llama-4-scout'# LLAMA_4_MAVERICK = 'llama-4-maverick'# CODESRAL = 'codestral'# OPEN_CODESRAL_MAMBA = 'open-codestral-mamba'# MISTRAL = 'mistral'# MINISTRAL = 'ministral'# PIXTRAL = 'pixtral'# UNKNOWN = 'unknown'# ANY# alias of Literal[‘gpt-5’, ‘gpt-41’, ‘gpt-45’, ‘gpt-4o’, ‘o1’, ‘o3’, ‘o4’, ‘gpt-4’, ‘gpt-35’, ‘r1’, ‘gemini-1.5-flash’, ‘gemini-1.5-pro’, ‘gemini-2.0-flash’, ‘gemini-2.5-pro’, ‘gemini-2.5-flash’, ‘claude-3-haiku’, ‘claude-3-sonnet’, ‘claude-3-opus’, ‘claude-3-5-haiku’, ‘claude-3-5-sonnet’, ‘claude-3-7-sonnet’, ‘claude-4-opus’, ‘claude-4-sonnet’, ‘llama-3.3-8b’, ‘llama-3.3-70b’, ‘llama-4-scout’, ‘llama-4-maverick’, ‘codestral’, ‘open-codestral-mamba’, ‘mistral’, ‘ministral’, ‘pixtral’, ‘unknown’] static is_claude(family: str) → bool[source]# static is_gemini(family: str) → bool[source]# static is_openai(family: str) → bool[source]# static is_llama(family: str) → bool[source]# static is_mistral(family: str) → bool[source]# class ModelInfo[source]# Bases: TypedDict ModelInfo is a dictionary that contains information about a model’s properties. It is expected to be used in the model_info property of a model client. We are expecting this to grow over time as we add more features. vision: Required[bool]# True if the model supports vision, aka image input, otherwise False. function_calling: Required[bool]# True if the model supports function calling, otherwise False. json_output: Required[bool]# this is different to structured json. Type: True if the model supports json output, otherwise False. Note family: Required[Literal['gpt-5', 'gpt-41', 'gpt-45', 'gpt-4o', 'o1', 'o3', 'o4', 'gpt-4', 'gpt-35', 'r1', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-2.0-flash', 'gemini-2.5-pro', 'gemini-2.5-flash', 'claude-3-haiku', 'claude-3-sonnet', 'claude-3-opus', 'claude-3-5-haiku', 'claude-3-5-sonnet', 'claude-3-7-sonnet', 'claude-4-opus', 'claude-4-sonnet', 'llama-3.3-8b', 'llama-3.3-70b', 'llama-4-scout', 'llama-4-maverick', 'codestral', 'open-codestral-mamba', 'mistral', 'ministral', 'pixtral', 'unknown'] | str]# Model family should be one of the constants from ModelFamily or a string representing an unknown model family. structured_output: Required[bool]# True if the model supports structured output, otherwise False. This is different to json_output. multiple_system_messages: bool | None# True if the model supports multiple, non-consecutive system messages, otherwise False. validate_model_info(model_info: ModelInfo) → None[source]# Validates the model info dictionary. Raises: ValueError – If the model info dictionary is missing required fields. previous autogen_core.model_context next autogen_core.tool_agent",
      "code": "TypedDict"
    }
  ],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}