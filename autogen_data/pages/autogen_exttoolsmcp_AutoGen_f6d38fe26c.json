{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
  "title": "autogen_ext.tools.mcp — AutoGen",
  "content": "Create an MCP client session for the given server parameters.\n\nBases: ComponentBase[BaseModel], Component[McpSessionActorConfig]\n\nThe logical type of the component.\n\nalias of McpSessionActorConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nBases: McpToolAdapter[StdioServerParams], Component[StdioMcpToolAdapterConfig]\n\nAllows you to wrap an MCP tool running over STDIO and make it available to AutoGen.\n\nThis adapter enables using MCP-compatible tools that communicate over standard input/output with AutoGen agents. Common use cases include wrapping command-line tools and local services that implement the Model Context Protocol (MCP).\n\nTo use this class, you need to install mcp extra for the autogen-ext package.\n\nserver_params (StdioServerParams) – Parameters for the MCP server connection, including command to run and its arguments\n\ntool (Tool) – The MCP tool to wrap\n\nsession (ClientSession, optional) – The MCP client session to use. If not provided, a new session will be created. This is useful for testing or when you want to manage the session lifecycle yourself.\n\nSee mcp_server_tools() for examples.\n\nalias of StdioMcpToolAdapterConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nBases: StdioServerParameters\n\nParameters for connecting to an MCP server over STDIO.\n\nShow JSON schema{ \"title\": \"StdioServerParams\", \"description\": \"Parameters for connecting to an MCP server over STDIO.\", \"type\": \"object\", \"properties\": { \"command\": { \"title\": \"Command\", \"type\": \"string\" }, \"args\": { \"items\": { \"type\": \"string\" }, \"title\": \"Args\", \"type\": \"array\" }, \"env\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Env\" }, \"cwd\": { \"anyOf\": [ { \"type\": \"string\" }, { \"format\": \"path\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Cwd\" }, \"encoding\": { \"default\": \"utf-8\", \"title\": \"Encoding\", \"type\": \"string\" }, \"encoding_error_handler\": { \"default\": \"strict\", \"enum\": [ \"strict\", \"ignore\", \"replace\" ], \"title\": \"Encoding Error Handler\", \"type\": \"string\" }, \"type\": { \"const\": \"StdioServerParams\", \"default\": \"StdioServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"read_timeout_seconds\": { \"default\": 5, \"title\": \"Read Timeout Seconds\", \"type\": \"number\" } }, \"required\": [ \"command\" ] }\n\nread_timeout_seconds (float)\n\ntype (Literal['StdioServerParams'])\n\nBases: McpToolAdapter[SseServerParams], Component[SseMcpToolAdapterConfig]\n\nAllows you to wrap an MCP tool running over Server-Sent Events (SSE) and make it available to AutoGen.\n\nThis adapter enables using MCP-compatible tools that communicate over HTTP with SSE with AutoGen agents. Common use cases include integrating with remote MCP services, cloud-based tools, and web APIs that implement the Model Context Protocol (MCP).\n\nTo use this class, you need to install mcp extra for the autogen-ext package.\n\nserver_params (SseServerParameters) – Parameters for the MCP server connection, including URL, headers, and timeouts.\n\ntool (Tool) – The MCP tool to wrap.\n\nsession (ClientSession, optional) – The MCP client session to use. If not provided, it will create a new session. This is useful for testing or when you want to manage the session lifecycle yourself.\n\nUse a remote translation service that implements MCP over SSE to create tools that allow AutoGen agents to perform translations:\n\nalias of SseMcpToolAdapterConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nParameters for connecting to an MCP server over SSE.\n\nShow JSON schema{ \"title\": \"SseServerParams\", \"description\": \"Parameters for connecting to an MCP server over SSE.\", \"type\": \"object\", \"properties\": { \"type\": { \"const\": \"SseServerParams\", \"default\": \"SseServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"url\": { \"title\": \"Url\", \"type\": \"string\" }, \"headers\": { \"anyOf\": [ { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Headers\" }, \"timeout\": { \"default\": 5, \"title\": \"Timeout\", \"type\": \"number\" }, \"sse_read_timeout\": { \"default\": 300, \"title\": \"Sse Read Timeout\", \"type\": \"number\" } }, \"required\": [ \"url\" ] }\n\nheaders (dict[str, Any] | None)\n\nsse_read_timeout (float)\n\ntype (Literal['SseServerParams'])\n\nBases: McpToolAdapter[StreamableHttpServerParams], Component[StreamableHttpMcpToolAdapterConfig]\n\nAllows you to wrap an MCP tool running over Streamable HTTP and make it available to AutoGen.\n\nThis adapter enables using MCP-compatible tools that communicate over Streamable HTTP with AutoGen agents. Common use cases include integrating with remote MCP services, cloud-based tools, and web APIs that implement the Model Context Protocol (MCP).\n\nTo use this class, you need to install mcp extra for the autogen-ext package.\n\nserver_params (StreamableHttpServerParams) – Parameters for the MCP server connection, including URL, headers, and timeouts.\n\ntool (Tool) – The MCP tool to wrap.\n\nsession (ClientSession, optional) – The MCP client session to use. If not provided, it will create a new session. This is useful for testing or when you want to manage the session lifecycle yourself.\n\nUse a remote translation service that implements MCP over Streamable HTTP to create tools that allow AutoGen agents to perform translations:\n\nalias of StreamableHttpMcpToolAdapterConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nParameters for connecting to an MCP server over Streamable HTTP.\n\nShow JSON schema{ \"title\": \"StreamableHttpServerParams\", \"description\": \"Parameters for connecting to an MCP server over Streamable HTTP.\", \"type\": \"object\", \"properties\": { \"type\": { \"const\": \"StreamableHttpServerParams\", \"default\": \"StreamableHttpServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"url\": { \"title\": \"Url\", \"type\": \"string\" }, \"headers\": { \"anyOf\": [ { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Headers\" }, \"timeout\": { \"default\": 30.0, \"title\": \"Timeout\", \"type\": \"number\" }, \"sse_read_timeout\": { \"default\": 300.0, \"title\": \"Sse Read Timeout\", \"type\": \"number\" }, \"terminate_on_close\": { \"default\": true, \"title\": \"Terminate On Close\", \"type\": \"boolean\" } }, \"required\": [ \"url\" ] }\n\nheaders (dict[str, Any] | None)\n\nsse_read_timeout (float)\n\nterminate_on_close (bool)\n\ntype (Literal['StreamableHttpServerParams'])\n\nCreates a list of MCP tool adapters that can be used with AutoGen agents.\n\nOnly connect to trusted MCP servers, especially when using StdioServerParams as it executes commands in the local environment.\n\nThis factory function connects to an MCP server and returns adapters for all available tools. The adapters can be directly assigned to an AutoGen agent’s tools list.\n\nTo use this function, you need to install mcp extra for the autogen-ext package.\n\nserver_params (McpServerParams) – Connection parameters for the MCP server. Can be either StdioServerParams for command-line tools or SseServerParams and StreamableHttpServerParams for HTTP/SSE services.\n\nsession (ClientSession | None) – Optional existing session to use. This is used when you want to reuse an existing connection to the MCP server. The session will be reused when creating the MCP tool adapters.\n\nlist[StdioMcpToolAdapter | SseMcpToolAdapter | StreamableHttpMcpToolAdapter] – A list of tool adapters ready to use with AutoGen agents.\n\nLocal file system MCP service over standard I/O example:\n\nInstall the filesystem server package from npm (requires Node.js 16+ and npm).\n\nCreate an agent that can use all tools from the local filesystem MCP server.\n\nLocal fetch MCP service over standard I/O example:\n\nInstall the mcp-server-fetch package.\n\nCreate an agent that can use the fetch tool from the local MCP server.\n\nSharing an MCP client session across multiple tools:\n\nYou can create a single MCP client session and share it across multiple tools. This is sometimes required when the server maintains a session state (e.g., a browser state) that should be reused for multiple requests.\n\nThe following example show how to create a single MCP client session to a local Playwright server and share it across multiple tools.\n\nRemote MCP service over SSE example:\n\nFor more examples and detailed usage, see the samples directory in the package repository.\n\nBases: Workbench, Component[McpWorkbenchConfig]\n\nA workbench that wraps an MCP server and provides an interface to list and call tools provided by the server.\n\nOnly connect to trusted MCP servers, especially when using StdioServerParams as it executes commands in the local environment.\n\nThis workbench should be used as a context manager to ensure proper initialization and cleanup of the underlying MCP session.\n\nlist_tools, call_tool\n\nlist_resources, read_resource\n\nlist_resource_templates, read_resource_template\n\nlist_prompts, get_prompt\n\nOptional support via model_client\n\nserver_params (McpServerParams) – The parameters to connect to the MCP server. This can be either a StdioServerParams or SseServerParams.\n\ntool_overrides (Optional[Dict[str, ToolOverride]]) – Optional mapping of original tool names to override configurations for name and/or description. This allows customizing how server tools appear to consumers while maintaining the underlying tool functionality.\n\nmodel_client – Optional chat completion client to handle sampling requests from MCP servers that support the sampling capability. This allows MCP servers to request text generation from a language model during tool execution. If not provided, sampling requests will return an error.\n\nValueError – If there are conflicts in tool override names.\n\nHere is a simple example of how to use the workbench with a mcp-server-fetch server:\n\nExample of using tool overrides:\n\nExample of using the workbench with the GitHub MCP Server:\n\nExample of using the workbench with the Playwright MCP Server:\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nalias of McpWorkbenchConfig\n\nList the currently available tools in the workbench as ToolSchema objects.\n\nThe list of tools may be dynamic, and their content may change after tool execution.\n\nCall a tool in the workbench.\n\nname (str) – The name of the tool to call.\n\narguments (Mapping[str, Any] | None) – The arguments to pass to the tool. If None, the tool will be called with no arguments.\n\ncancellation_token (CancellationToken | None) – An optional cancellation token to cancel the tool execution.\n\ncall_id (str | None) – An optional identifier for the tool call, used for tracing.\n\nToolResult – The result of the tool execution.\n\nList available prompts from the MCP server.\n\nList available resources from the MCP server.\n\nList available resource templates from the MCP server.\n\nRead a resource from the MCP server.\n\nGet a prompt from the MCP server.\n\nStart the workbench and initialize any resources.\n\nThis method should be called before using the workbench.\n\nStop the workbench and release any resources.\n\nThis method should be called when the workbench is no longer needed.\n\nReset the workbench to its initialized, started state.\n\nSave the state of the workbench.\n\nThis method should be called to persist the state of the workbench.\n\nLoad the state of the workbench.\n\nstate (Mapping[str, Any]) – The state to load into the workbench.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nautogen_ext.tools.langchain\n\nautogen_ext.tools.semantic_kernel",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_ext.tools.mcp#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "{\n   \"title\": \"StdioServerParams\",\n   \"description\": \"Parameters for connecting to an MCP server over STDIO.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"command\": {\n         \"title\": \"Command\",\n         \"type\": \"string\"\n      },\n      \"args\": {\n         \"items\": {\n            \"type\": \"string\"\n         },\n         \"title\": \"Args\",\n         \"type\": \"array\"\n      },\n      \"env\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Env\"\n      },\n      \"cwd\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"format\": \"path\",\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Cwd\"\n      },\n      \"encoding\": {\n         \"default\": \"utf-8\",\n         \"title\": \"Encoding\",\n         \"type\": \"string\"\n      },\n      \"encoding_error_handler\": {\n         \"default\": \"strict\",\n         \"enum\": [\n            \"strict\",\n            \"ignore\",\n            \"replace\"\n         ],\n         \"title\": \"Encoding Error Handler\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"StdioServerParams\",\n         \"default\": \"StdioServerParams\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      },\n      \"read_timeout_seconds\": {\n         \"default\": 5,\n         \"title\": \"Read Timeout Seconds\",\n         \"type\": \"number\"\n      }\n   },\n   \"required\": [\n      \"command\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"StdioServerParams\",\n   \"description\": \"Parameters for connecting to an MCP server over STDIO.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"command\": {\n         \"title\": \"Command\",\n         \"type\": \"string\"\n      },\n      \"args\": {\n         \"items\": {\n            \"type\": \"string\"\n         },\n         \"title\": \"Args\",\n         \"type\": \"array\"\n      },\n      \"env\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Env\"\n      },\n      \"cwd\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"format\": \"path\",\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Cwd\"\n      },\n      \"encoding\": {\n         \"default\": \"utf-8\",\n         \"title\": \"Encoding\",\n         \"type\": \"string\"\n      },\n      \"encoding_error_handler\": {\n         \"default\": \"strict\",\n         \"enum\": [\n            \"strict\",\n            \"ignore\",\n            \"replace\"\n         ],\n         \"title\": \"Encoding Error Handler\",\n         \"type\": \"string\"\n      },\n      \"type\": {\n         \"const\": \"StdioServerParams\",\n         \"default\": \"StdioServerParams\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      },\n      \"read_timeout_seconds\": {\n         \"default\": 5,\n         \"title\": \"Read Timeout Seconds\",\n         \"type\": \"number\"\n      }\n   },\n   \"required\": [\n      \"command\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import SseMcpToolAdapter, SseServerParams\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Create server params for the remote MCP service\n    server_params = SseServerParams(\n        url=\"https://api.example.com/mcp\",\n        headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"},\n        timeout=30,  # Connection timeout in seconds\n    )\n\n    # Get the translation tool from the server\n    adapter = await SseMcpToolAdapter.from_server_params(server_params, \"translate\")\n\n    # Create an agent that can use the translation tool\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4\")\n    agent = AssistantAgent(\n        name=\"translator\",\n        model_client=model_client,\n        tools=[adapter],\n        system_message=\"You are a helpful translation assistant.\",\n    )\n\n    # Let the agent translate some text\n    await Console(\n        agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken())\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import SseMcpToolAdapter, SseServerParams\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Create server params for the remote MCP service\n    server_params = SseServerParams(\n        url=\"https://api.example.com/mcp\",\n        headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"},\n        timeout=30,  # Connection timeout in seconds\n    )\n\n    # Get the translation tool from the server\n    adapter = await SseMcpToolAdapter.from_server_params(server_params, \"translate\")\n\n    # Create an agent that can use the translation tool\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4\")\n    agent = AssistantAgent(\n        name=\"translator\",\n        model_client=model_client,\n        tools=[adapter],\n        system_message=\"You are a helpful translation assistant.\",\n    )\n\n    # Let the agent translate some text\n    await Console(\n        agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken())\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "{\n   \"title\": \"SseServerParams\",\n   \"description\": \"Parameters for connecting to an MCP server over SSE.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"type\": {\n         \"const\": \"SseServerParams\",\n         \"default\": \"SseServerParams\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      },\n      \"url\": {\n         \"title\": \"Url\",\n         \"type\": \"string\"\n      },\n      \"headers\": {\n         \"anyOf\": [\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Headers\"\n      },\n      \"timeout\": {\n         \"default\": 5,\n         \"title\": \"Timeout\",\n         \"type\": \"number\"\n      },\n      \"sse_read_timeout\": {\n         \"default\": 300,\n         \"title\": \"Sse Read Timeout\",\n         \"type\": \"number\"\n      }\n   },\n   \"required\": [\n      \"url\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"SseServerParams\",\n   \"description\": \"Parameters for connecting to an MCP server over SSE.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"type\": {\n         \"const\": \"SseServerParams\",\n         \"default\": \"SseServerParams\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      },\n      \"url\": {\n         \"title\": \"Url\",\n         \"type\": \"string\"\n      },\n      \"headers\": {\n         \"anyOf\": [\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Headers\"\n      },\n      \"timeout\": {\n         \"default\": 5,\n         \"title\": \"Timeout\",\n         \"type\": \"number\"\n      },\n      \"sse_read_timeout\": {\n         \"default\": 300,\n         \"title\": \"Sse Read Timeout\",\n         \"type\": \"number\"\n      }\n   },\n   \"required\": [\n      \"url\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StreamableHttpMcpToolAdapter, StreamableHttpServerParams\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Create server params for the remote MCP service\n    server_params = StreamableHttpServerParams(\n        url=\"https://api.example.com/mcp\",\n        headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"},\n        timeout=30.0,  # HTTP timeout in seconds\n        sse_read_timeout=300.0,  # SSE read timeout in seconds (5 minutes)\n        terminate_on_close=True,\n    )\n\n    # Get the translation tool from the server\n    adapter = await StreamableHttpMcpToolAdapter.from_server_params(server_params, \"translate\")\n\n    # Create an agent that can use the translation tool\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4\")\n    agent = AssistantAgent(\n        name=\"translator\",\n        model_client=model_client,\n        tools=[adapter],\n        system_message=\"You are a helpful translation assistant.\",\n    )\n\n    # Let the agent translate some text\n    await Console(\n        agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken())\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StreamableHttpMcpToolAdapter, StreamableHttpServerParams\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Create server params for the remote MCP service\n    server_params = StreamableHttpServerParams(\n        url=\"https://api.example.com/mcp\",\n        headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"},\n        timeout=30.0,  # HTTP timeout in seconds\n        sse_read_timeout=300.0,  # SSE read timeout in seconds (5 minutes)\n        terminate_on_close=True,\n    )\n\n    # Get the translation tool from the server\n    adapter = await StreamableHttpMcpToolAdapter.from_server_params(server_params, \"translate\")\n\n    # Create an agent that can use the translation tool\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4\")\n    agent = AssistantAgent(\n        name=\"translator\",\n        model_client=model_client,\n        tools=[adapter],\n        system_message=\"You are a helpful translation assistant.\",\n    )\n\n    # Let the agent translate some text\n    await Console(\n        agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken())\n    )\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "{\n   \"title\": \"StreamableHttpServerParams\",\n   \"description\": \"Parameters for connecting to an MCP server over Streamable HTTP.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"type\": {\n         \"const\": \"StreamableHttpServerParams\",\n         \"default\": \"StreamableHttpServerParams\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      },\n      \"url\": {\n         \"title\": \"Url\",\n         \"type\": \"string\"\n      },\n      \"headers\": {\n         \"anyOf\": [\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Headers\"\n      },\n      \"timeout\": {\n         \"default\": 30.0,\n         \"title\": \"Timeout\",\n         \"type\": \"number\"\n      },\n      \"sse_read_timeout\": {\n         \"default\": 300.0,\n         \"title\": \"Sse Read Timeout\",\n         \"type\": \"number\"\n      },\n      \"terminate_on_close\": {\n         \"default\": true,\n         \"title\": \"Terminate On Close\",\n         \"type\": \"boolean\"\n      }\n   },\n   \"required\": [\n      \"url\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"StreamableHttpServerParams\",\n   \"description\": \"Parameters for connecting to an MCP server over Streamable HTTP.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"type\": {\n         \"const\": \"StreamableHttpServerParams\",\n         \"default\": \"StreamableHttpServerParams\",\n         \"title\": \"Type\",\n         \"type\": \"string\"\n      },\n      \"url\": {\n         \"title\": \"Url\",\n         \"type\": \"string\"\n      },\n      \"headers\": {\n         \"anyOf\": [\n            {\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Headers\"\n      },\n      \"timeout\": {\n         \"default\": 30.0,\n         \"title\": \"Timeout\",\n         \"type\": \"number\"\n      },\n      \"sse_read_timeout\": {\n         \"default\": 300.0,\n         \"title\": \"Sse Read Timeout\",\n         \"type\": \"number\"\n      },\n      \"terminate_on_close\": {\n         \"default\": true,\n         \"title\": \"Terminate On Close\",\n         \"type\": \"boolean\"\n      }\n   },\n   \"required\": [\n      \"url\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "pip install -U \"autogen-ext[mcp]\"",
      "language": "unknown"
    },
    {
      "code": "npm install -g @modelcontextprotocol/server-filesystem",
      "language": "python"
    },
    {
      "code": "npm install -g @modelcontextprotocol/server-filesystem",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom pathlib import Path\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Setup server params for local filesystem access\n    desktop = str(Path.home() / \"Desktop\")\n    server_params = StdioServerParams(\n        command=\"npx.cmd\", args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", desktop]\n    )\n\n    # Get all available tools from the server\n    tools = await mcp_server_tools(server_params)\n\n    # Create an agent that can use all the tools\n    agent = AssistantAgent(\n        name=\"file_manager\",\n        model_client=OpenAIChatCompletionClient(model=\"gpt-4\"),\n        tools=tools,  # type: ignore\n    )\n\n    # The agent can now use any of the filesystem tools\n    await agent.run(task=\"Create a file called test.txt with some content\", cancellation_token=CancellationToken())\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom pathlib import Path\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_core import CancellationToken\n\n\nasync def main() -> None:\n    # Setup server params for local filesystem access\n    desktop = str(Path.home() / \"Desktop\")\n    server_params = StdioServerParams(\n        command=\"npx.cmd\", args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", desktop]\n    )\n\n    # Get all available tools from the server\n    tools = await mcp_server_tools(server_params)\n\n    # Create an agent that can use all the tools\n    agent = AssistantAgent(\n        name=\"file_manager\",\n        model_client=OpenAIChatCompletionClient(model=\"gpt-4\"),\n        tools=tools,  # type: ignore\n    )\n\n    # The agent can now use any of the filesystem tools\n    await agent.run(task=\"Create a file called test.txt with some content\", cancellation_token=CancellationToken())\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
      "language": "python"
    },
    {
      "code": "pip install mcp-server-fetch",
      "language": "unknown"
    },
    {
      "code": "pip install mcp-server-fetch",
      "language": "unknown"
    },
    {
      "code": "import asyncio\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n\n\nasync def main() -> None:\n    # Get the fetch tool from mcp-server-fetch.\n    fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"])\n    tools = await mcp_server_tools(fetch_mcp_server)\n\n    # Create an agent that can use the fetch tool.\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n    agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=tools, reflect_on_tool_use=True)  # type: ignore\n\n    # Let the agent fetch the content of a URL and summarize it.\n    result = await agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\")\n    print(result.messages[-1])\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n\n\nasync def main() -> None:\n    # Get the fetch tool from mcp-server-fetch.\n    fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"])\n    tools = await mcp_server_tools(fetch_mcp_server)\n\n    # Create an agent that can use the fetch tool.\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n    agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=tools, reflect_on_tool_use=True)  # type: ignore\n\n    # Let the agent fetch the content of a URL and summarize it.\n    result = await agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\")\n    print(result.messages[-1])\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.conditions import TextMentionTermination\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StdioServerParams, create_mcp_server_session, mcp_server_tools\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", parallel_tool_calls=False)  # type: ignore\n    params = StdioServerParams(\n        command=\"npx\",\n        args=[\"@playwright/mcp@latest\"],\n        read_timeout_seconds=60,\n    )\n    async with create_mcp_server_session(params) as session:\n        await session.initialize()\n        tools = await mcp_server_tools(server_params=params, session=session)\n        print(f\"Tools: {[tool.name for tool in tools]}\")\n\n        agent = AssistantAgent(\n            name=\"Assistant\",\n            model_client=model_client,\n            tools=tools,  # type: ignore\n        )\n\n        termination = TextMentionTermination(\"TERMINATE\")\n        team = RoundRobinGroupChat([agent], termination_condition=termination)\n        await Console(\n            team.run_stream(\n                task=\"Go to https://ekzhu.com/, visit the first link in the page, then tell me about the linked page.\"\n            )\n        )\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\n\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.conditions import TextMentionTermination\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import StdioServerParams, create_mcp_server_session, mcp_server_tools\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", parallel_tool_calls=False)  # type: ignore\n    params = StdioServerParams(\n        command=\"npx\",\n        args=[\"@playwright/mcp@latest\"],\n        read_timeout_seconds=60,\n    )\n    async with create_mcp_server_session(params) as session:\n        await session.initialize()\n        tools = await mcp_server_tools(server_params=params, session=session)\n        print(f\"Tools: {[tool.name for tool in tools]}\")\n\n        agent = AssistantAgent(\n            name=\"Assistant\",\n            model_client=model_client,\n            tools=tools,  # type: ignore\n        )\n\n        termination = TextMentionTermination(\"TERMINATE\")\n        team = RoundRobinGroupChat([agent], termination_condition=termination)\n        await Console(\n            team.run_stream(\n                task=\"Go to https://ekzhu.com/, visit the first link in the page, then tell me about the linked page.\"\n            )\n        )\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools\n\n\nasync def main() -> None:\n    # Setup server params for remote service\n    server_params = SseServerParams(url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer token\"})\n\n    # Get all available tools\n    tools = await mcp_server_tools(server_params)\n\n    # Create an agent with all tools\n    agent = AssistantAgent(name=\"tool_user\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools)  # type: ignore",
      "language": "python"
    },
    {
      "code": "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools\n\n\nasync def main() -> None:\n    # Setup server params for remote service\n    server_params = SseServerParams(url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer token\"})\n\n    # Get all available tools\n    tools = await mcp_server_tools(server_params)\n\n    # Create an agent with all tools\n    agent = AssistantAgent(name=\"tool_user\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools)  # type: ignore",
      "language": "python"
    },
    {
      "code": "import asyncio\n\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    params = StdioServerParams(\n        command=\"uvx\",\n        args=[\"mcp-server-fetch\"],\n        read_timeout_seconds=60,\n    )\n\n    # You can also use `start()` and `stop()` to manage the session.\n    async with McpWorkbench(server_params=params) as workbench:\n        tools = await workbench.list_tools()\n        print(tools)\n        result = await workbench.call_tool(tools[0][\"name\"], {\"url\": \"https://github.com/\"})\n        print(result)\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\n\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    params = StdioServerParams(\n        command=\"uvx\",\n        args=[\"mcp-server-fetch\"],\n        read_timeout_seconds=60,\n    )\n\n    # You can also use `start()` and `stop()` to manage the session.\n    async with McpWorkbench(server_params=params) as workbench:\n        tools = await workbench.list_tools()\n        print(tools)\n        result = await workbench.call_tool(tools[0][\"name\"], {\"url\": \"https://github.com/\"})\n        print(result)\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\nfrom autogen_core.tools import ToolOverride\n\n\nasync def main() -> None:\n    params = StdioServerParams(\n        command=\"uvx\",\n        args=[\"mcp-server-fetch\"],\n        read_timeout_seconds=60,\n    )\n\n    # Override the fetch tool's name and description\n    overrides = {\n        \"fetch\": ToolOverride(name=\"web_fetch\", description=\"Enhanced web fetching tool with better error handling\")\n    }\n\n    async with McpWorkbench(server_params=params, tool_overrides=overrides) as workbench:\n        tools = await workbench.list_tools()\n        # The tool will now appear as \"web_fetch\" with the new description\n        print(tools)\n        # Call the overridden tool\n        result = await workbench.call_tool(\"web_fetch\", {\"url\": \"https://github.com/\"})\n        print(result)\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\nfrom autogen_core.tools import ToolOverride\n\n\nasync def main() -> None:\n    params = StdioServerParams(\n        command=\"uvx\",\n        args=[\"mcp-server-fetch\"],\n        read_timeout_seconds=60,\n    )\n\n    # Override the fetch tool's name and description\n    overrides = {\n        \"fetch\": ToolOverride(name=\"web_fetch\", description=\"Enhanced web fetching tool with better error handling\")\n    }\n\n    async with McpWorkbench(server_params=params, tool_overrides=overrides) as workbench:\n        tools = await workbench.list_tools()\n        # The tool will now appear as \"web_fetch\" with the new description\n        print(tools)\n        # Call the overridden tool\n        result = await workbench.call_tool(\"web_fetch\", {\"url\": \"https://github.com/\"})\n        print(result)\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\")\n    server_params = StdioServerParams(\n        command=\"docker\",\n        args=[\n            \"run\",\n            \"-i\",\n            \"--rm\",\n            \"-e\",\n            \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n            \"ghcr.io/github/github-mcp-server\",\n        ],\n        env={\n            \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n        },\n    )\n    async with McpWorkbench(server_params) as mcp:\n        agent = AssistantAgent(\n            \"github_assistant\",\n            model_client=model_client,\n            workbench=mcp,\n            reflect_on_tool_use=True,\n            model_client_stream=True,\n        )\n        await Console(agent.run_stream(task=\"Is there a repository named Autogen\"))\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\")\n    server_params = StdioServerParams(\n        command=\"docker\",\n        args=[\n            \"run\",\n            \"-i\",\n            \"--rm\",\n            \"-e\",\n            \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n            \"ghcr.io/github/github-mcp-server\",\n        ],\n        env={\n            \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n        },\n    )\n    async with McpWorkbench(server_params) as mcp:\n        agent = AssistantAgent(\n            \"github_assistant\",\n            model_client=model_client,\n            workbench=mcp,\n            reflect_on_tool_use=True,\n            model_client_stream=True,\n        )\n        await Console(agent.run_stream(task=\"Is there a repository named Autogen\"))\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "# First run `npm install -g @playwright/mcp@latest` to install the MCP server.\nimport asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.conditions import TextMessageTermination\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\")\n    server_params = StdioServerParams(\n        command=\"npx\",\n        args=[\n            \"@playwright/mcp@latest\",\n            \"--headless\",\n        ],\n    )\n    async with McpWorkbench(server_params) as mcp:\n        agent = AssistantAgent(\n            \"web_browsing_assistant\",\n            model_client=model_client,\n            workbench=mcp,\n            model_client_stream=True,\n        )\n        team = RoundRobinGroupChat(\n            [agent],\n            termination_condition=TextMessageTermination(source=\"web_browsing_assistant\"),\n        )\n        await Console(team.run_stream(task=\"Find out how many contributors for the microsoft/autogen repository\"))\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "# First run `npm install -g @playwright/mcp@latest` to install the MCP server.\nimport asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.teams import RoundRobinGroupChat\nfrom autogen_agentchat.conditions import TextMessageTermination\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\")\n    server_params = StdioServerParams(\n        command=\"npx\",\n        args=[\n            \"@playwright/mcp@latest\",\n            \"--headless\",\n        ],\n    )\n    async with McpWorkbench(server_params) as mcp:\n        agent = AssistantAgent(\n            \"web_browsing_assistant\",\n            model_client=model_client,\n            workbench=mcp,\n            model_client_stream=True,\n        )\n        team = RoundRobinGroupChat(\n            [agent],\n            termination_condition=TextMessageTermination(source=\"web_browsing_assistant\"),\n        )\n        await Console(team.run_stream(task=\"Find out how many contributors for the microsoft/autogen repository\"))\n\n\nasyncio.run(main())",
      "language": "python"
    }
  ],
  "patterns": [
    {
      "description": "API Reference autogen_ext.tools.mcp autogen_ext.tools.mcp# create_mcp_server_session(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], sampling_callback: SamplingFnT | None = None) → AsyncGenerator[ClientSession, None][source]# Create an MCP client session for the given server parameters. class McpSessionActor(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], model_client: ChatCompletionClient | None = None)[source]# Bases: ComponentBase[BaseModel], Component[McpSessionActorConfig] component_type: ClassVar[ComponentType] = 'mcp_session_actor'# The logical type of the component. component_config_schema# alias of McpSessionActorConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.McpSessionActor'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')]# property initialize_result: InitializeResult | None# async initialize() → None[source]# async call(type: str, args: McpActorArgs | None = None) → Future[Coroutine[Any, Any, ListToolsResult] | Coroutine[Any, Any, CallToolResult] | Coroutine[Any, Any, ListPromptsResult] | Coroutine[Any, Any, ListResourcesResult] | Coroutine[Any, Any, ListResourceTemplatesResult] | Coroutine[Any, Any, ReadResourceResult] | Coroutine[Any, Any, GetPromptResult]][source]# async close() → None[source]# class StdioMcpToolAdapter(server_params: StdioServerParams, tool: Tool, session: ClientSession | None = None)[source]# Bases: McpToolAdapter[StdioServerParams], Component[StdioMcpToolAdapterConfig] Allows you to wrap an MCP tool running over STDIO and make it available to AutoGen. This adapter enables using MCP-compatible tools that communicate over standard input/output with AutoGen agents. Common use cases include wrapping command-line tools and local services that implement the Model Context Protocol (MCP). Note To use this class, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (StdioServerParams) – Parameters for the MCP server connection, including command to run and its arguments tool (Tool) – The MCP tool to wrap session (ClientSession, optional) – The MCP client session to use. If not provided, a new session will be created. This is useful for testing or when you want to manage the session lifecycle yourself. See mcp_server_tools() for examples. component_config_schema# alias of StdioMcpToolAdapterConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.StdioMcpToolAdapter'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. pydantic model StdioServerParams[source]# Bases: StdioServerParameters Parameters for connecting to an MCP server over STDIO. Show JSON schema{ \"title\": \"StdioServerParams\", \"description\": \"Parameters for connecting to an MCP server over STDIO.\", \"type\": \"object\", \"properties\": { \"command\": { \"title\": \"Command\", \"type\": \"string\" }, \"args\": { \"items\": { \"type\": \"string\" }, \"title\": \"Args\", \"type\": \"array\" }, \"env\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Env\" }, \"cwd\": { \"anyOf\": [ { \"type\": \"string\" }, { \"format\": \"path\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Cwd\" }, \"encoding\": { \"default\": \"utf-8\", \"title\": \"Encoding\", \"type\": \"string\" }, \"encoding_error_handler\": { \"default\": \"strict\", \"enum\": [ \"strict\", \"ignore\", \"replace\" ], \"title\": \"Encoding Error Handler\", \"type\": \"string\" }, \"type\": { \"const\": \"StdioServerParams\", \"default\": \"StdioServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"read_timeout_seconds\": { \"default\": 5, \"title\": \"Read Timeout Seconds\", \"type\": \"number\" } }, \"required\": [ \"command\" ] } Fields: read_timeout_seconds (float) type (Literal['StdioServerParams']) field type: Literal['StdioServerParams'] = 'StdioServerParams'# field read_timeout_seconds: float = 5# class SseMcpToolAdapter(server_params: SseServerParams, tool: Tool, session: ClientSession | None = None)[source]# Bases: McpToolAdapter[SseServerParams], Component[SseMcpToolAdapterConfig] Allows you to wrap an MCP tool running over Server-Sent Events (SSE) and make it available to AutoGen. This adapter enables using MCP-compatible tools that communicate over HTTP with SSE with AutoGen agents. Common use cases include integrating with remote MCP services, cloud-based tools, and web APIs that implement the Model Context Protocol (MCP). Note To use this class, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (SseServerParameters) – Parameters for the MCP server connection, including URL, headers, and timeouts. tool (Tool) – The MCP tool to wrap. session (ClientSession, optional) – The MCP client session to use. If not provided, it will create a new session. This is useful for testing or when you want to manage the session lifecycle yourself. Examples Use a remote translation service that implements MCP over SSE to create tools that allow AutoGen agents to perform translations: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import SseMcpToolAdapter, SseServerParams from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_core import CancellationToken async def main() -> None: # Create server params for the remote MCP service server_params = SseServerParams( url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"}, timeout=30, # Connection timeout in seconds ) # Get the translation tool from the server adapter = await SseMcpToolAdapter.from_server_params(server_params, \"translate\") # Create an agent that can use the translation tool model_client = OpenAIChatCompletionClient(model=\"gpt-4\") agent = AssistantAgent( name=\"translator\", model_client=model_client, tools=[adapter], system_message=\"You are a helpful translation assistant.\", ) # Let the agent translate some text await Console( agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken()) ) if __name__ == \"__main__\": asyncio.run(main()) component_config_schema# alias of SseMcpToolAdapterConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.SseMcpToolAdapter'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. pydantic model SseServerParams[source]# Bases: BaseModel Parameters for connecting to an MCP server over SSE. Show JSON schema{ \"title\": \"SseServerParams\", \"description\": \"Parameters for connecting to an MCP server over SSE.\", \"type\": \"object\", \"properties\": { \"type\": { \"const\": \"SseServerParams\", \"default\": \"SseServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"url\": { \"title\": \"Url\", \"type\": \"string\" }, \"headers\": { \"anyOf\": [ { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Headers\" }, \"timeout\": { \"default\": 5, \"title\": \"Timeout\", \"type\": \"number\" }, \"sse_read_timeout\": { \"default\": 300, \"title\": \"Sse Read Timeout\", \"type\": \"number\" } }, \"required\": [ \"url\" ] } Fields: headers (dict[str, Any] | None) sse_read_timeout (float) timeout (float) type (Literal['SseServerParams']) url (str) field type: Literal['SseServerParams'] = 'SseServerParams'# field url: str [Required]# field headers: dict[str, Any] | None = None# field timeout: float = 5# field sse_read_timeout: float = 300# class StreamableHttpMcpToolAdapter(server_params: StreamableHttpServerParams, tool: Tool, session: ClientSession | None = None)[source]# Bases: McpToolAdapter[StreamableHttpServerParams], Component[StreamableHttpMcpToolAdapterConfig] Allows you to wrap an MCP tool running over Streamable HTTP and make it available to AutoGen. This adapter enables using MCP-compatible tools that communicate over Streamable HTTP with AutoGen agents. Common use cases include integrating with remote MCP services, cloud-based tools, and web APIs that implement the Model Context Protocol (MCP). Note To use this class, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (StreamableHttpServerParams) – Parameters for the MCP server connection, including URL, headers, and timeouts. tool (Tool) – The MCP tool to wrap. session (ClientSession, optional) – The MCP client session to use. If not provided, it will create a new session. This is useful for testing or when you want to manage the session lifecycle yourself. Examples Use a remote translation service that implements MCP over Streamable HTTP to create tools that allow AutoGen agents to perform translations: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StreamableHttpMcpToolAdapter, StreamableHttpServerParams from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_core import CancellationToken async def main() -> None: # Create server params for the remote MCP service server_params = StreamableHttpServerParams( url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"}, timeout=30.0, # HTTP timeout in seconds sse_read_timeout=300.0, # SSE read timeout in seconds (5 minutes) terminate_on_close=True, ) # Get the translation tool from the server adapter = await StreamableHttpMcpToolAdapter.from_server_params(server_params, \"translate\") # Create an agent that can use the translation tool model_client = OpenAIChatCompletionClient(model=\"gpt-4\") agent = AssistantAgent( name=\"translator\", model_client=model_client, tools=[adapter], system_message=\"You are a helpful translation assistant.\", ) # Let the agent translate some text await Console( agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken()) ) if __name__ == \"__main__\": asyncio.run(main()) component_config_schema# alias of StreamableHttpMcpToolAdapterConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.StreamableHttpMcpToolAdapter'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. pydantic model StreamableHttpServerParams[source]# Bases: BaseModel Parameters for connecting to an MCP server over Streamable HTTP. Show JSON schema{ \"title\": \"StreamableHttpServerParams\", \"description\": \"Parameters for connecting to an MCP server over Streamable HTTP.\", \"type\": \"object\", \"properties\": { \"type\": { \"const\": \"StreamableHttpServerParams\", \"default\": \"StreamableHttpServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"url\": { \"title\": \"Url\", \"type\": \"string\" }, \"headers\": { \"anyOf\": [ { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Headers\" }, \"timeout\": { \"default\": 30.0, \"title\": \"Timeout\", \"type\": \"number\" }, \"sse_read_timeout\": { \"default\": 300.0, \"title\": \"Sse Read Timeout\", \"type\": \"number\" }, \"terminate_on_close\": { \"default\": true, \"title\": \"Terminate On Close\", \"type\": \"boolean\" } }, \"required\": [ \"url\" ] } Fields: headers (dict[str, Any] | None) sse_read_timeout (float) terminate_on_close (bool) timeout (float) type (Literal['StreamableHttpServerParams']) url (str) field type: Literal['StreamableHttpServerParams'] = 'StreamableHttpServerParams'# field url: str [Required]# field headers: dict[str, Any] | None = None# field timeout: float = 30.0# field sse_read_timeout: float = 300.0# field terminate_on_close: bool = True# async mcp_server_tools(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], session: ClientSession | None = None) → list[StdioMcpToolAdapter | SseMcpToolAdapter | StreamableHttpMcpToolAdapter][source]# Creates a list of MCP tool adapters that can be used with AutoGen agents. Warning Only connect to trusted MCP servers, especially when using StdioServerParams as it executes commands in the local environment. This factory function connects to an MCP server and returns adapters for all available tools. The adapters can be directly assigned to an AutoGen agent’s tools list. Note To use this function, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (McpServerParams) – Connection parameters for the MCP server. Can be either StdioServerParams for command-line tools or SseServerParams and StreamableHttpServerParams for HTTP/SSE services. session (ClientSession | None) – Optional existing session to use. This is used when you want to reuse an existing connection to the MCP server. The session will be reused when creating the MCP tool adapters. Returns: list[StdioMcpToolAdapter | SseMcpToolAdapter | StreamableHttpMcpToolAdapter] – A list of tool adapters ready to use with AutoGen agents. Examples Local file system MCP service over standard I/O example: Install the filesystem server package from npm (requires Node.js 16+ and npm). npm install -g @modelcontextprotocol/server-filesystem Create an agent that can use all tools from the local filesystem MCP server. import asyncio from pathlib import Path from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools from autogen_agentchat.agents import AssistantAgent from autogen_core import CancellationToken async def main() -> None: # Setup server params for local filesystem access desktop = str(Path.home() / \"Desktop\") server_params = StdioServerParams( command=\"npx.cmd\", args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", desktop] ) # Get all available tools from the server tools = await mcp_server_tools(server_params) # Create an agent that can use all the tools agent = AssistantAgent( name=\"file_manager\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools, # type: ignore ) # The agent can now use any of the filesystem tools await agent.run(task=\"Create a file called test.txt with some content\", cancellation_token=CancellationToken()) if __name__ == \"__main__\": asyncio.run(main()) Local fetch MCP service over standard I/O example: Install the mcp-server-fetch package. pip install mcp-server-fetch Create an agent that can use the fetch tool from the local MCP server. import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools async def main() -> None: # Get the fetch tool from mcp-server-fetch. fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"]) tools = await mcp_server_tools(fetch_mcp_server) # Create an agent that can use the fetch tool. model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=tools, reflect_on_tool_use=True) # type: ignore # Let the agent fetch the content of a URL and summarize it. result = await agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\") print(result.messages[-1]) asyncio.run(main()) Sharing an MCP client session across multiple tools: You can create a single MCP client session and share it across multiple tools. This is sometimes required when the server maintains a session state (e.g., a browser state) that should be reused for multiple requests. The following example show how to create a single MCP client session to a local Playwright server and share it across multiple tools. import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.conditions import TextMentionTermination from autogen_agentchat.teams import RoundRobinGroupChat from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StdioServerParams, create_mcp_server_session, mcp_server_tools async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", parallel_tool_calls=False) # type: ignore params = StdioServerParams( command=\"npx\", args=[\"@playwright/mcp@latest\"], read_timeout_seconds=60, ) async with create_mcp_server_session(params) as session: await session.initialize() tools = await mcp_server_tools(server_params=params, session=session) print(f\"Tools: {[tool.name for tool in tools]}\") agent = AssistantAgent( name=\"Assistant\", model_client=model_client, tools=tools, # type: ignore ) termination = TextMentionTermination(\"TERMINATE\") team = RoundRobinGroupChat([agent], termination_condition=termination) await Console( team.run_stream( task=\"Go to https://ekzhu.com/, visit the first link in the page, then tell me about the linked page.\" ) ) asyncio.run(main()) Remote MCP service over SSE example: from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools async def main() -> None: # Setup server params for remote service server_params = SseServerParams(url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer token\"}) # Get all available tools tools = await mcp_server_tools(server_params) # Create an agent with all tools agent = AssistantAgent(name=\"tool_user\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools) # type: ignore For more examples and detailed usage, see the samples directory in the package repository. class McpWorkbench(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], tool_overrides: Dict[str, ToolOverride] | None = None, model_client: ChatCompletionClient | None = None)[source]# Bases: Workbench, Component[McpWorkbenchConfig] A workbench that wraps an MCP server and provides an interface to list and call tools provided by the server. Warning Only connect to trusted MCP servers, especially when using StdioServerParams as it executes commands in the local environment. This workbench should be used as a context manager to ensure proper initialization and cleanup of the underlying MCP session. MCP Support# MCP Capability Supported Features Tools list_tools, call_tool Resources list_resources, read_resource ResourceTemplates list_resource_templates, read_resource_template Prompts list_prompts, get_prompt Sampling Optional support via model_client Roots not supported Ellicitation not supported Parameters: server_params (McpServerParams) – The parameters to connect to the MCP server. This can be either a StdioServerParams or SseServerParams. tool_overrides (Optional[Dict[str, ToolOverride]]) – Optional mapping of original tool names to override configurations for name and/or description. This allows customizing how server tools appear to consumers while maintaining the underlying tool functionality. model_client – Optional chat completion client to handle sampling requests from MCP servers that support the sampling capability. This allows MCP servers to request text generation from a language model during tool execution. If not provided, sampling requests will return an error. Raises: ValueError – If there are conflicts in tool override names. Examples Here is a simple example of how to use the workbench with a mcp-server-fetch server: import asyncio from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main() -> None: params = StdioServerParams( command=\"uvx\", args=[\"mcp-server-fetch\"], read_timeout_seconds=60, ) # You can also use `start()` and `stop()` to manage the session. async with McpWorkbench(server_params=params) as workbench: tools = await workbench.list_tools() print(tools) result = await workbench.call_tool(tools[0][\"name\"], {\"url\": \"https://github.com/\"}) print(result) asyncio.run(main()) Example of using tool overrides: import asyncio from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams from autogen_core.tools import ToolOverride async def main() -> None: params = StdioServerParams( command=\"uvx\", args=[\"mcp-server-fetch\"], read_timeout_seconds=60, ) # Override the fetch tool's name and description overrides = { \"fetch\": ToolOverride(name=\"web_fetch\", description=\"Enhanced web fetching tool with better error handling\") } async with McpWorkbench(server_params=params, tool_overrides=overrides) as workbench: tools = await workbench.list_tools() # The tool will now appear as \"web_fetch\" with the new description print(tools) # Call the overridden tool result = await workbench.call_tool(\"web_fetch\", {\"url\": \"https://github.com/\"}) print(result) asyncio.run(main()) Example of using the workbench with the GitHub MCP Server: import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\") server_params = StdioServerParams( command=\"docker\", args=[ \"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\", ], env={ \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", }, ) async with McpWorkbench(server_params) as mcp: agent = AssistantAgent( \"github_assistant\", model_client=model_client, workbench=mcp, reflect_on_tool_use=True, model_client_stream=True, ) await Console(agent.run_stream(task=\"Is there a repository named Autogen\")) asyncio.run(main()) Example of using the workbench with the Playwright MCP Server: # First run `npm install -g @playwright/mcp@latest` to install the MCP server. import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.teams import RoundRobinGroupChat from autogen_agentchat.conditions import TextMessageTermination from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\") server_params = StdioServerParams( command=\"npx\", args=[ \"@playwright/mcp@latest\", \"--headless\", ], ) async with McpWorkbench(server_params) as mcp: agent = AssistantAgent( \"web_browsing_assistant\", model_client=model_client, workbench=mcp, model_client_stream=True, ) team = RoundRobinGroupChat( [agent], termination_condition=TextMessageTermination(source=\"web_browsing_assistant\"), ) await Console(team.run_stream(task=\"Find out how many contributors for the microsoft/autogen repository\")) asyncio.run(main()) component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.McpWorkbench'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. component_config_schema# alias of McpWorkbenchConfig property server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')]# async list_tools() → List[ToolSchema][source]# List the currently available tools in the workbench as ToolSchema objects. The list of tools may be dynamic, and their content may change after tool execution. async call_tool(name: str, arguments: Mapping[str, Any] | None = None, cancellation_token: CancellationToken | None = None, call_id: str | None = None) → ToolResult[source]# Call a tool in the workbench. Parameters: name (str) – The name of the tool to call. arguments (Mapping[str, Any] | None) – The arguments to pass to the tool. If None, the tool will be called with no arguments. cancellation_token (CancellationToken | None) – An optional cancellation token to cancel the tool execution. call_id (str | None) – An optional identifier for the tool call, used for tracing. Returns: ToolResult – The result of the tool execution. property initialize_result: Any# async list_prompts() → ListPromptsResult[source]# List available prompts from the MCP server. async list_resources() → ListResourcesResult[source]# List available resources from the MCP server. async list_resource_templates() → ListResourceTemplatesResult[source]# List available resource templates from the MCP server. async read_resource(uri: str) → ReadResourceResult[source]# Read a resource from the MCP server. async get_prompt(name: str, arguments: Dict[str, str] | None = None) → GetPromptResult[source]# Get a prompt from the MCP server. async start() → None[source]# Start the workbench and initialize any resources. This method should be called before using the workbench. async stop() → None[source]# Stop the workbench and release any resources. This method should be called when the workbench is no longer needed. async reset() → None[source]# Reset the workbench to its initialized, started state. async save_state() → Mapping[str, Any][source]# Save the state of the workbench. This method should be called to persist the state of the workbench. async load_state(state: Mapping[str, Any]) → None[source]# Load the state of the workbench. Parameters: state (Mapping[str, Any]) – The state to load into the workbench. _to_config() → McpWorkbenchConfig[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: McpWorkbenchConfig) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. previous autogen_ext.tools.langchain next autogen_ext.tools.semantic_kernel On this page create_mcp_server_session() McpSessionActor McpSessionActor.component_type McpSessionActor.component_config_schema McpSessionActor.component_provider_override McpSessionActor.server_params McpSessionActor.initialize_result McpSessionActor.initialize() McpSessionActor.call() McpSessionActor.close() StdioMcpToolAdapter StdioMcpToolAdapter.component_config_schema StdioMcpToolAdapter.component_provider_override StdioServerParams StdioServerParams.type StdioServerParams.read_timeout_seconds SseMcpToolAdapter SseMcpToolAdapter.component_config_schema SseMcpToolAdapter.component_provider_override SseServerParams SseServerParams.type SseServerParams.url SseServerParams.headers SseServerParams.timeout SseServerParams.sse_read_timeout StreamableHttpMcpToolAdapter StreamableHttpMcpToolAdapter.component_config_schema StreamableHttpMcpToolAdapter.component_provider_override StreamableHttpServerParams StreamableHttpServerParams.type StreamableHttpServerParams.url StreamableHttpServerParams.headers StreamableHttpServerParams.timeout StreamableHttpServerParams.sse_read_timeout StreamableHttpServerParams.terminate_on_close mcp_server_tools() McpWorkbench McpWorkbench.component_provider_override McpWorkbench.component_config_schema McpWorkbench.server_params McpWorkbench.list_tools() McpWorkbench.call_tool() McpWorkbench.initialize_result McpWorkbench.list_prompts() McpWorkbench.list_resources() McpWorkbench.list_resource_templates() McpWorkbench.read_resource() McpWorkbench.get_prompt() McpWorkbench.start() McpWorkbench.stop() McpWorkbench.reset() McpWorkbench.save_state() McpWorkbench.load_state() McpWorkbench._to_config() McpWorkbench._from_config() Edit on GitHub Show Source",
      "code": "ComponentBase"
    },
    {
      "description": "API Reference autogen_ext.tools.mcp autogen_ext.tools.mcp# create_mcp_server_session(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], sampling_callback: SamplingFnT | None = None) → AsyncGenerator[ClientSession, None][source]# Create an MCP client session for the given server parameters. class McpSessionActor(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], model_client: ChatCompletionClient | None = None)[source]# Bases: ComponentBase[BaseModel], Component[McpSessionActorConfig] component_type: ClassVar[ComponentType] = 'mcp_session_actor'# The logical type of the component. component_config_schema# alias of McpSessionActorConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.McpSessionActor'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')]# property initialize_result: InitializeResult | None# async initialize() → None[source]# async call(type: str, args: McpActorArgs | None = None) → Future[Coroutine[Any, Any, ListToolsResult] | Coroutine[Any, Any, CallToolResult] | Coroutine[Any, Any, ListPromptsResult] | Coroutine[Any, Any, ListResourcesResult] | Coroutine[Any, Any, ListResourceTemplatesResult] | Coroutine[Any, Any, ReadResourceResult] | Coroutine[Any, Any, GetPromptResult]][source]# async close() → None[source]# class StdioMcpToolAdapter(server_params: StdioServerParams, tool: Tool, session: ClientSession | None = None)[source]# Bases: McpToolAdapter[StdioServerParams], Component[StdioMcpToolAdapterConfig] Allows you to wrap an MCP tool running over STDIO and make it available to AutoGen. This adapter enables using MCP-compatible tools that communicate over standard input/output with AutoGen agents. Common use cases include wrapping command-line tools and local services that implement the Model Context Protocol (MCP). Note To use this class, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (StdioServerParams) – Parameters for the MCP server connection, including command to run and its arguments tool (Tool) – The MCP tool to wrap session (ClientSession, optional) – The MCP client session to use. If not provided, a new session will be created. This is useful for testing or when you want to manage the session lifecycle yourself. See mcp_server_tools() for examples. component_config_schema# alias of StdioMcpToolAdapterConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.StdioMcpToolAdapter'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. pydantic model StdioServerParams[source]# Bases: StdioServerParameters Parameters for connecting to an MCP server over STDIO. Show JSON schema{ \"title\": \"StdioServerParams\", \"description\": \"Parameters for connecting to an MCP server over STDIO.\", \"type\": \"object\", \"properties\": { \"command\": { \"title\": \"Command\", \"type\": \"string\" }, \"args\": { \"items\": { \"type\": \"string\" }, \"title\": \"Args\", \"type\": \"array\" }, \"env\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Env\" }, \"cwd\": { \"anyOf\": [ { \"type\": \"string\" }, { \"format\": \"path\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Cwd\" }, \"encoding\": { \"default\": \"utf-8\", \"title\": \"Encoding\", \"type\": \"string\" }, \"encoding_error_handler\": { \"default\": \"strict\", \"enum\": [ \"strict\", \"ignore\", \"replace\" ], \"title\": \"Encoding Error Handler\", \"type\": \"string\" }, \"type\": { \"const\": \"StdioServerParams\", \"default\": \"StdioServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"read_timeout_seconds\": { \"default\": 5, \"title\": \"Read Timeout Seconds\", \"type\": \"number\" } }, \"required\": [ \"command\" ] } Fields: read_timeout_seconds (float) type (Literal['StdioServerParams']) field type: Literal['StdioServerParams'] = 'StdioServerParams'# field read_timeout_seconds: float = 5# class SseMcpToolAdapter(server_params: SseServerParams, tool: Tool, session: ClientSession | None = None)[source]# Bases: McpToolAdapter[SseServerParams], Component[SseMcpToolAdapterConfig] Allows you to wrap an MCP tool running over Server-Sent Events (SSE) and make it available to AutoGen. This adapter enables using MCP-compatible tools that communicate over HTTP with SSE with AutoGen agents. Common use cases include integrating with remote MCP services, cloud-based tools, and web APIs that implement the Model Context Protocol (MCP). Note To use this class, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (SseServerParameters) – Parameters for the MCP server connection, including URL, headers, and timeouts. tool (Tool) – The MCP tool to wrap. session (ClientSession, optional) – The MCP client session to use. If not provided, it will create a new session. This is useful for testing or when you want to manage the session lifecycle yourself. Examples Use a remote translation service that implements MCP over SSE to create tools that allow AutoGen agents to perform translations: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import SseMcpToolAdapter, SseServerParams from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_core import CancellationToken async def main() -> None: # Create server params for the remote MCP service server_params = SseServerParams( url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"}, timeout=30, # Connection timeout in seconds ) # Get the translation tool from the server adapter = await SseMcpToolAdapter.from_server_params(server_params, \"translate\") # Create an agent that can use the translation tool model_client = OpenAIChatCompletionClient(model=\"gpt-4\") agent = AssistantAgent( name=\"translator\", model_client=model_client, tools=[adapter], system_message=\"You are a helpful translation assistant.\", ) # Let the agent translate some text await Console( agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken()) ) if __name__ == \"__main__\": asyncio.run(main()) component_config_schema# alias of SseMcpToolAdapterConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.SseMcpToolAdapter'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. pydantic model SseServerParams[source]# Bases: BaseModel Parameters for connecting to an MCP server over SSE. Show JSON schema{ \"title\": \"SseServerParams\", \"description\": \"Parameters for connecting to an MCP server over SSE.\", \"type\": \"object\", \"properties\": { \"type\": { \"const\": \"SseServerParams\", \"default\": \"SseServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"url\": { \"title\": \"Url\", \"type\": \"string\" }, \"headers\": { \"anyOf\": [ { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Headers\" }, \"timeout\": { \"default\": 5, \"title\": \"Timeout\", \"type\": \"number\" }, \"sse_read_timeout\": { \"default\": 300, \"title\": \"Sse Read Timeout\", \"type\": \"number\" } }, \"required\": [ \"url\" ] } Fields: headers (dict[str, Any] | None) sse_read_timeout (float) timeout (float) type (Literal['SseServerParams']) url (str) field type: Literal['SseServerParams'] = 'SseServerParams'# field url: str [Required]# field headers: dict[str, Any] | None = None# field timeout: float = 5# field sse_read_timeout: float = 300# class StreamableHttpMcpToolAdapter(server_params: StreamableHttpServerParams, tool: Tool, session: ClientSession | None = None)[source]# Bases: McpToolAdapter[StreamableHttpServerParams], Component[StreamableHttpMcpToolAdapterConfig] Allows you to wrap an MCP tool running over Streamable HTTP and make it available to AutoGen. This adapter enables using MCP-compatible tools that communicate over Streamable HTTP with AutoGen agents. Common use cases include integrating with remote MCP services, cloud-based tools, and web APIs that implement the Model Context Protocol (MCP). Note To use this class, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (StreamableHttpServerParams) – Parameters for the MCP server connection, including URL, headers, and timeouts. tool (Tool) – The MCP tool to wrap. session (ClientSession, optional) – The MCP client session to use. If not provided, it will create a new session. This is useful for testing or when you want to manage the session lifecycle yourself. Examples Use a remote translation service that implements MCP over Streamable HTTP to create tools that allow AutoGen agents to perform translations: import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StreamableHttpMcpToolAdapter, StreamableHttpServerParams from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_core import CancellationToken async def main() -> None: # Create server params for the remote MCP service server_params = StreamableHttpServerParams( url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer your-api-key\", \"Content-Type\": \"application/json\"}, timeout=30.0, # HTTP timeout in seconds sse_read_timeout=300.0, # SSE read timeout in seconds (5 minutes) terminate_on_close=True, ) # Get the translation tool from the server adapter = await StreamableHttpMcpToolAdapter.from_server_params(server_params, \"translate\") # Create an agent that can use the translation tool model_client = OpenAIChatCompletionClient(model=\"gpt-4\") agent = AssistantAgent( name=\"translator\", model_client=model_client, tools=[adapter], system_message=\"You are a helpful translation assistant.\", ) # Let the agent translate some text await Console( agent.run_stream(task=\"Translate 'Hello, how are you?' to Spanish\", cancellation_token=CancellationToken()) ) if __name__ == \"__main__\": asyncio.run(main()) component_config_schema# alias of StreamableHttpMcpToolAdapterConfig component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.StreamableHttpMcpToolAdapter'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. pydantic model StreamableHttpServerParams[source]# Bases: BaseModel Parameters for connecting to an MCP server over Streamable HTTP. Show JSON schema{ \"title\": \"StreamableHttpServerParams\", \"description\": \"Parameters for connecting to an MCP server over Streamable HTTP.\", \"type\": \"object\", \"properties\": { \"type\": { \"const\": \"StreamableHttpServerParams\", \"default\": \"StreamableHttpServerParams\", \"title\": \"Type\", \"type\": \"string\" }, \"url\": { \"title\": \"Url\", \"type\": \"string\" }, \"headers\": { \"anyOf\": [ { \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Headers\" }, \"timeout\": { \"default\": 30.0, \"title\": \"Timeout\", \"type\": \"number\" }, \"sse_read_timeout\": { \"default\": 300.0, \"title\": \"Sse Read Timeout\", \"type\": \"number\" }, \"terminate_on_close\": { \"default\": true, \"title\": \"Terminate On Close\", \"type\": \"boolean\" } }, \"required\": [ \"url\" ] } Fields: headers (dict[str, Any] | None) sse_read_timeout (float) terminate_on_close (bool) timeout (float) type (Literal['StreamableHttpServerParams']) url (str) field type: Literal['StreamableHttpServerParams'] = 'StreamableHttpServerParams'# field url: str [Required]# field headers: dict[str, Any] | None = None# field timeout: float = 30.0# field sse_read_timeout: float = 300.0# field terminate_on_close: bool = True# async mcp_server_tools(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], session: ClientSession | None = None) → list[StdioMcpToolAdapter | SseMcpToolAdapter | StreamableHttpMcpToolAdapter][source]# Creates a list of MCP tool adapters that can be used with AutoGen agents. Warning Only connect to trusted MCP servers, especially when using StdioServerParams as it executes commands in the local environment. This factory function connects to an MCP server and returns adapters for all available tools. The adapters can be directly assigned to an AutoGen agent’s tools list. Note To use this function, you need to install mcp extra for the autogen-ext package. pip install -U \"autogen-ext[mcp]\" Parameters: server_params (McpServerParams) – Connection parameters for the MCP server. Can be either StdioServerParams for command-line tools or SseServerParams and StreamableHttpServerParams for HTTP/SSE services. session (ClientSession | None) – Optional existing session to use. This is used when you want to reuse an existing connection to the MCP server. The session will be reused when creating the MCP tool adapters. Returns: list[StdioMcpToolAdapter | SseMcpToolAdapter | StreamableHttpMcpToolAdapter] – A list of tool adapters ready to use with AutoGen agents. Examples Local file system MCP service over standard I/O example: Install the filesystem server package from npm (requires Node.js 16+ and npm). npm install -g @modelcontextprotocol/server-filesystem Create an agent that can use all tools from the local filesystem MCP server. import asyncio from pathlib import Path from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools from autogen_agentchat.agents import AssistantAgent from autogen_core import CancellationToken async def main() -> None: # Setup server params for local filesystem access desktop = str(Path.home() / \"Desktop\") server_params = StdioServerParams( command=\"npx.cmd\", args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", desktop] ) # Get all available tools from the server tools = await mcp_server_tools(server_params) # Create an agent that can use all the tools agent = AssistantAgent( name=\"file_manager\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools, # type: ignore ) # The agent can now use any of the filesystem tools await agent.run(task=\"Create a file called test.txt with some content\", cancellation_token=CancellationToken()) if __name__ == \"__main__\": asyncio.run(main()) Local fetch MCP service over standard I/O example: Install the mcp-server-fetch package. pip install mcp-server-fetch Create an agent that can use the fetch tool from the local MCP server. import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools async def main() -> None: # Get the fetch tool from mcp-server-fetch. fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"]) tools = await mcp_server_tools(fetch_mcp_server) # Create an agent that can use the fetch tool. model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=tools, reflect_on_tool_use=True) # type: ignore # Let the agent fetch the content of a URL and summarize it. result = await agent.run(task=\"Summarize the content of https://en.wikipedia.org/wiki/Seattle\") print(result.messages[-1]) asyncio.run(main()) Sharing an MCP client session across multiple tools: You can create a single MCP client session and share it across multiple tools. This is sometimes required when the server maintains a session state (e.g., a browser state) that should be reused for multiple requests. The following example show how to create a single MCP client session to a local Playwright server and share it across multiple tools. import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.conditions import TextMentionTermination from autogen_agentchat.teams import RoundRobinGroupChat from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import StdioServerParams, create_mcp_server_session, mcp_server_tools async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", parallel_tool_calls=False) # type: ignore params = StdioServerParams( command=\"npx\", args=[\"@playwright/mcp@latest\"], read_timeout_seconds=60, ) async with create_mcp_server_session(params) as session: await session.initialize() tools = await mcp_server_tools(server_params=params, session=session) print(f\"Tools: {[tool.name for tool in tools]}\") agent = AssistantAgent( name=\"Assistant\", model_client=model_client, tools=tools, # type: ignore ) termination = TextMentionTermination(\"TERMINATE\") team = RoundRobinGroupChat([agent], termination_condition=termination) await Console( team.run_stream( task=\"Go to https://ekzhu.com/, visit the first link in the page, then tell me about the linked page.\" ) ) asyncio.run(main()) Remote MCP service over SSE example: from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools async def main() -> None: # Setup server params for remote service server_params = SseServerParams(url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer token\"}) # Get all available tools tools = await mcp_server_tools(server_params) # Create an agent with all tools agent = AssistantAgent(name=\"tool_user\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools) # type: ignore For more examples and detailed usage, see the samples directory in the package repository. class McpWorkbench(server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')], tool_overrides: Dict[str, ToolOverride] | None = None, model_client: ChatCompletionClient | None = None)[source]# Bases: Workbench, Component[McpWorkbenchConfig] A workbench that wraps an MCP server and provides an interface to list and call tools provided by the server. Warning Only connect to trusted MCP servers, especially when using StdioServerParams as it executes commands in the local environment. This workbench should be used as a context manager to ensure proper initialization and cleanup of the underlying MCP session. MCP Support# MCP Capability Supported Features Tools list_tools, call_tool Resources list_resources, read_resource ResourceTemplates list_resource_templates, read_resource_template Prompts list_prompts, get_prompt Sampling Optional support via model_client Roots not supported Ellicitation not supported Parameters: server_params (McpServerParams) – The parameters to connect to the MCP server. This can be either a StdioServerParams or SseServerParams. tool_overrides (Optional[Dict[str, ToolOverride]]) – Optional mapping of original tool names to override configurations for name and/or description. This allows customizing how server tools appear to consumers while maintaining the underlying tool functionality. model_client – Optional chat completion client to handle sampling requests from MCP servers that support the sampling capability. This allows MCP servers to request text generation from a language model during tool execution. If not provided, sampling requests will return an error. Raises: ValueError – If there are conflicts in tool override names. Examples Here is a simple example of how to use the workbench with a mcp-server-fetch server: import asyncio from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main() -> None: params = StdioServerParams( command=\"uvx\", args=[\"mcp-server-fetch\"], read_timeout_seconds=60, ) # You can also use `start()` and `stop()` to manage the session. async with McpWorkbench(server_params=params) as workbench: tools = await workbench.list_tools() print(tools) result = await workbench.call_tool(tools[0][\"name\"], {\"url\": \"https://github.com/\"}) print(result) asyncio.run(main()) Example of using tool overrides: import asyncio from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams from autogen_core.tools import ToolOverride async def main() -> None: params = StdioServerParams( command=\"uvx\", args=[\"mcp-server-fetch\"], read_timeout_seconds=60, ) # Override the fetch tool's name and description overrides = { \"fetch\": ToolOverride(name=\"web_fetch\", description=\"Enhanced web fetching tool with better error handling\") } async with McpWorkbench(server_params=params, tool_overrides=overrides) as workbench: tools = await workbench.list_tools() # The tool will now appear as \"web_fetch\" with the new description print(tools) # Call the overridden tool result = await workbench.call_tool(\"web_fetch\", {\"url\": \"https://github.com/\"}) print(result) asyncio.run(main()) Example of using the workbench with the GitHub MCP Server: import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\") server_params = StdioServerParams( command=\"docker\", args=[ \"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\", ], env={ \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"ghp_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", }, ) async with McpWorkbench(server_params) as mcp: agent = AssistantAgent( \"github_assistant\", model_client=model_client, workbench=mcp, reflect_on_tool_use=True, model_client_stream=True, ) await Console(agent.run_stream(task=\"Is there a repository named Autogen\")) asyncio.run(main()) Example of using the workbench with the Playwright MCP Server: # First run `npm install -g @playwright/mcp@latest` to install the MCP server. import asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.teams import RoundRobinGroupChat from autogen_agentchat.conditions import TextMessageTermination from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main() -> None: model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\") server_params = StdioServerParams( command=\"npx\", args=[ \"@playwright/mcp@latest\", \"--headless\", ], ) async with McpWorkbench(server_params) as mcp: agent = AssistantAgent( \"web_browsing_assistant\", model_client=model_client, workbench=mcp, model_client_stream=True, ) team = RoundRobinGroupChat( [agent], termination_condition=TextMessageTermination(source=\"web_browsing_assistant\"), ) await Console(team.run_stream(task=\"Find out how many contributors for the microsoft/autogen repository\")) asyncio.run(main()) component_provider_override: ClassVar[str | None] = 'autogen_ext.tools.mcp.McpWorkbench'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. component_config_schema# alias of McpWorkbenchConfig property server_params: Annotated[StdioServerParams | SseServerParams | StreamableHttpServerParams, FieldInfo(annotation=NoneType, required=True, discriminator='type')]# async list_tools() → List[ToolSchema][source]# List the currently available tools in the workbench as ToolSchema objects. The list of tools may be dynamic, and their content may change after tool execution. async call_tool(name: str, arguments: Mapping[str, Any] | None = None, cancellation_token: CancellationToken | None = None, call_id: str | None = None) → ToolResult[source]# Call a tool in the workbench. Parameters: name (str) – The name of the tool to call. arguments (Mapping[str, Any] | None) – The arguments to pass to the tool. If None, the tool will be called with no arguments. cancellation_token (CancellationToken | None) – An optional cancellation token to cancel the tool execution. call_id (str | None) – An optional identifier for the tool call, used for tracing. Returns: ToolResult – The result of the tool execution. property initialize_result: Any# async list_prompts() → ListPromptsResult[source]# List available prompts from the MCP server. async list_resources() → ListResourcesResult[source]# List available resources from the MCP server. async list_resource_templates() → ListResourceTemplatesResult[source]# List available resource templates from the MCP server. async read_resource(uri: str) → ReadResourceResult[source]# Read a resource from the MCP server. async get_prompt(name: str, arguments: Dict[str, str] | None = None) → GetPromptResult[source]# Get a prompt from the MCP server. async start() → None[source]# Start the workbench and initialize any resources. This method should be called before using the workbench. async stop() → None[source]# Stop the workbench and release any resources. This method should be called when the workbench is no longer needed. async reset() → None[source]# Reset the workbench to its initialized, started state. async save_state() → Mapping[str, Any][source]# Save the state of the workbench. This method should be called to persist the state of the workbench. async load_state(state: Mapping[str, Any]) → None[source]# Load the state of the workbench. Parameters: state (Mapping[str, Any]) – The state to load into the workbench. _to_config() → McpWorkbenchConfig[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: McpWorkbenchConfig) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. previous autogen_ext.tools.langchain next autogen_ext.tools.semantic_kernel",
      "code": "ComponentBase"
    },
    {
      "description": "Local file system MCP service over standard I/O example:",
      "code": "npm install -g @modelcontextprotocol/server-filesystem"
    },
    {
      "description": "Local fetch MCP service over standard I/O example:",
      "code": "pip install mcp-server-fetch"
    },
    {
      "description": "Remote MCP service over SSE example:",
      "code": "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools\n\n\nasync def main() -> None:\n    # Setup server params for remote service\n    server_params = SseServerParams(url=\"https://api.example.com/mcp\", headers={\"Authorization\": \"Bearer token\"})\n\n    # Get all available tools\n    tools = await mcp_server_tools(server_params)\n\n    # Create an agent with all tools\n    agent = AssistantAgent(name=\"tool_user\", model_client=OpenAIChatCompletionClient(model=\"gpt-4\"), tools=tools)  # type: ignore"
    }
  ],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}