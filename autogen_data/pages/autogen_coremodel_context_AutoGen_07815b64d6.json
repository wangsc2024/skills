{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
  "title": "autogen_core.model_context — AutoGen",
  "content": "Bases: ABC, ComponentBase[BaseModel]\n\nAn abstract base class for defining the interface of a chat completion context. A chat completion context lets agents store and retrieve LLM messages. It can be implemented with different recall strategies.\n\ninitial_messages (List[LLMMessage] | None) – The initial messages.\n\nTo create a custom model context that filters out the thought field from AssistantMessage. This is useful for reasoning models like DeepSeek R1, which produces very long thought that is not needed for subsequent completions.\n\nThe logical type of the component.\n\nAdd a message to the context.\n\nShow JSON schema{ \"title\": \"ChatCompletionContextState\", \"type\": \"object\", \"properties\": { \"messages\": { \"items\": { \"discriminator\": { \"mapping\": { \"AssistantMessage\": \"#/$defs/AssistantMessage\", \"FunctionExecutionResultMessage\": \"#/$defs/FunctionExecutionResultMessage\", \"SystemMessage\": \"#/$defs/SystemMessage\", \"UserMessage\": \"#/$defs/UserMessage\" }, \"propertyName\": \"type\" }, \"oneOf\": [ { \"$ref\": \"#/$defs/SystemMessage\" }, { \"$ref\": \"#/$defs/UserMessage\" }, { \"$ref\": \"#/$defs/AssistantMessage\" }, { \"$ref\": \"#/$defs/FunctionExecutionResultMessage\" } ] }, \"title\": \"Messages\", \"type\": \"array\" } }, \"$defs\": { \"AssistantMessage\": { \"description\": \"Assistant message are sampled from the language model.\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"$ref\": \"#/$defs/FunctionCall\" }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"thought\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Thought\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"AssistantMessage\", \"default\": \"AssistantMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\", \"source\" ], \"title\": \"AssistantMessage\", \"type\": \"object\" }, \"FunctionCall\": { \"properties\": { \"id\": { \"title\": \"Id\", \"type\": \"string\" }, \"arguments\": { \"title\": \"Arguments\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" } }, \"required\": [ \"id\", \"arguments\", \"name\" ], \"title\": \"FunctionCall\", \"type\": \"object\" }, \"FunctionExecutionResult\": { \"description\": \"Function execution result contains the output of a function call.\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"call_id\": { \"title\": \"Call Id\", \"type\": \"string\" }, \"is_error\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Is Error\" } }, \"required\": [ \"content\", \"name\", \"call_id\" ], \"title\": \"FunctionExecutionResult\", \"type\": \"object\" }, \"FunctionExecutionResultMessage\": { \"description\": \"Function execution result message contains the output of multiple function calls.\", \"properties\": { \"content\": { \"items\": { \"$ref\": \"#/$defs/FunctionExecutionResult\" }, \"title\": \"Content\", \"type\": \"array\" }, \"type\": { \"const\": \"FunctionExecutionResultMessage\", \"default\": \"FunctionExecutionResultMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\" ], \"title\": \"FunctionExecutionResultMessage\", \"type\": \"object\" }, \"SystemMessage\": { \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n Open AI is moving away from using 'system' role in favor of 'developer' role.\\n See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n on the server side.\\n So, you can use `SystemMessage` for developer messages.\", \"properties\": { \"content\": { \"title\": \"Content\", \"type\": \"string\" }, \"type\": { \"const\": \"SystemMessage\", \"default\": \"SystemMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\" ], \"title\": \"SystemMessage\", \"type\": \"object\" }, \"UserMessage\": { \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\", \"properties\": { \"content\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"anyOf\": [ { \"type\": \"string\" }, {} ] }, \"type\": \"array\" } ], \"title\": \"Content\" }, \"source\": { \"title\": \"Source\", \"type\": \"string\" }, \"type\": { \"const\": \"UserMessage\", \"default\": \"UserMessage\", \"title\": \"Type\", \"type\": \"string\" } }, \"required\": [ \"content\", \"source\" ], \"title\": \"UserMessage\", \"type\": \"object\" } } }\n\nmessages (List[autogen_core.models._types.SystemMessage | autogen_core.models._types.UserMessage | autogen_core.models._types.AssistantMessage | autogen_core.models._types.FunctionExecutionResultMessage])\n\nBases: ChatCompletionContext, Component[UnboundedChatCompletionContextConfig]\n\nAn unbounded chat completion context that keeps a view of the all the messages.\n\nalias of UnboundedChatCompletionContextConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nGet at most buffer_size recent messages.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: ChatCompletionContext, Component[BufferedChatCompletionContextConfig]\n\nA buffered chat completion context that keeps a view of the last n messages, where n is the buffer size. The buffer size is set at initialization.\n\nbuffer_size (int) – The size of the buffer.\n\ninitial_messages (List[LLMMessage] | None) – The initial messages.\n\nalias of BufferedChatCompletionContextConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nGet at most buffer_size recent messages.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: ChatCompletionContext, Component[TokenLimitedChatCompletionContextConfig]\n\n(Experimental) A token based chat completion context maintains a view of the context up to a token limit.\n\nAdded in v0.4.10. This is an experimental component and may change in the future.\n\nmodel_client (ChatCompletionClient) – The model client to use for token counting. The model client must implement the count_tokens() and remaining_tokens() methods.\n\ntoken_limit (int | None) – The maximum number of tokens to keep in the context using the count_tokens() method. If None, the context will be limited by the model client using the remaining_tokens() method.\n\ntools (List[ToolSchema] | None) – A list of tool schema to use in the context.\n\ninitial_messages (List[LLMMessage] | None) – A list of initial messages to include in the context.\n\nalias of TokenLimitedChatCompletionContextConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nGet at most token_limit tokens in recent messages. If the token limit is not provided, then return as many messages as the remaining token allowed by the model client.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: ChatCompletionContext, Component[HeadAndTailChatCompletionContextConfig]\n\nA chat completion context that keeps a view of the first n and last m messages, where n is the head size and m is the tail size. The head and tail sizes are set at initialization.\n\nhead_size (int) – The size of the head.\n\ntail_size (int) – The size of the tail.\n\ninitial_messages (List[LLMMessage] | None) – The initial messages.\n\nalias of HeadAndTailChatCompletionContextConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nGet at most head_size recent messages and tail_size oldest messages.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_core.model_context#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "from typing import List\n\nfrom autogen_core.model_context import UnboundedChatCompletionContext\nfrom autogen_core.models import AssistantMessage, LLMMessage\n\n\nclass ReasoningModelContext(UnboundedChatCompletionContext):\n    \"\"\"A model context for reasoning models.\"\"\"\n\n    async def get_messages(self) -> List[LLMMessage]:\n        messages = await super().get_messages()\n        # Filter out thought field from AssistantMessage.\n        messages_out: List[LLMMessage] = []\n        for message in messages:\n            if isinstance(message, AssistantMessage):\n                message.thought = None\n            messages_out.append(message)\n        return messages_out",
      "language": "python"
    },
    {
      "code": "from typing import List\n\nfrom autogen_core.model_context import UnboundedChatCompletionContext\nfrom autogen_core.models import AssistantMessage, LLMMessage\n\n\nclass ReasoningModelContext(UnboundedChatCompletionContext):\n    \"\"\"A model context for reasoning models.\"\"\"\n\n    async def get_messages(self) -> List[LLMMessage]:\n        messages = await super().get_messages()\n        # Filter out thought field from AssistantMessage.\n        messages_out: List[LLMMessage] = []\n        for message in messages:\n            if isinstance(message, AssistantMessage):\n                message.thought = None\n            messages_out.append(message)\n        return messages_out",
      "language": "python"
    },
    {
      "code": "{\n   \"title\": \"ChatCompletionContextState\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"messages\": {\n         \"items\": {\n            \"discriminator\": {\n               \"mapping\": {\n                  \"AssistantMessage\": \"#/$defs/AssistantMessage\",\n                  \"FunctionExecutionResultMessage\": \"#/$defs/FunctionExecutionResultMessage\",\n                  \"SystemMessage\": \"#/$defs/SystemMessage\",\n                  \"UserMessage\": \"#/$defs/UserMessage\"\n               },\n               \"propertyName\": \"type\"\n            },\n            \"oneOf\": [\n               {\n                  \"$ref\": \"#/$defs/SystemMessage\"\n               },\n               {\n                  \"$ref\": \"#/$defs/UserMessage\"\n               },\n               {\n                  \"$ref\": \"#/$defs/AssistantMessage\"\n               },\n               {\n                  \"$ref\": \"#/$defs/FunctionExecutionResultMessage\"\n               }\n            ]\n         },\n         \"title\": \"Messages\",\n         \"type\": \"array\"\n      }\n   },\n   \"$defs\": {\n      \"AssistantMessage\": {\n         \"description\": \"Assistant message are sampled from the language model.\",\n         \"properties\": {\n            \"content\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"items\": {\n                        \"$ref\": \"#/$defs/FunctionCall\"\n                     },\n                     \"type\": \"array\"\n                  }\n               ],\n               \"title\": \"Content\"\n            },\n            \"thought\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Thought\"\n            },\n            \"source\": {\n               \"title\": \"Source\",\n               \"type\": \"string\"\n            },\n            \"type\": {\n               \"const\": \"AssistantMessage\",\n               \"default\": \"AssistantMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"source\"\n         ],\n         \"title\": \"AssistantMessage\",\n         \"type\": \"object\"\n      },\n      \"FunctionCall\": {\n         \"properties\": {\n            \"id\": {\n               \"title\": \"Id\",\n               \"type\": \"string\"\n            },\n            \"arguments\": {\n               \"title\": \"Arguments\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"id\",\n            \"arguments\",\n            \"name\"\n         ],\n         \"title\": \"FunctionCall\",\n         \"type\": \"object\"\n      },\n      \"FunctionExecutionResult\": {\n         \"description\": \"Function execution result contains the output of a function call.\",\n         \"properties\": {\n            \"content\": {\n               \"title\": \"Content\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"call_id\": {\n               \"title\": \"Call Id\",\n               \"type\": \"string\"\n            },\n            \"is_error\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Is Error\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"name\",\n            \"call_id\"\n         ],\n         \"title\": \"FunctionExecutionResult\",\n         \"type\": \"object\"\n      },\n      \"FunctionExecutionResultMessage\": {\n         \"description\": \"Function execution result message contains the output of multiple function calls.\",\n         \"properties\": {\n            \"content\": {\n               \"items\": {\n                  \"$ref\": \"#/$defs/FunctionExecutionResult\"\n               },\n               \"title\": \"Content\",\n               \"type\": \"array\"\n            },\n            \"type\": {\n               \"const\": \"FunctionExecutionResultMessage\",\n               \"default\": \"FunctionExecutionResultMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\"\n         ],\n         \"title\": \"FunctionExecutionResultMessage\",\n         \"type\": \"object\"\n      },\n      \"SystemMessage\": {\n         \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n    Open AI is moving away from using 'system' role in favor of 'developer' role.\\n    See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n    However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n    on the server side.\\n    So, you can use `SystemMessage` for developer messages.\",\n         \"properties\": {\n            \"content\": {\n               \"title\": \"Content\",\n               \"type\": \"string\"\n            },\n            \"type\": {\n               \"const\": \"SystemMessage\",\n               \"default\": \"SystemMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\"\n         ],\n         \"title\": \"SystemMessage\",\n         \"type\": \"object\"\n      },\n      \"UserMessage\": {\n         \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\",\n         \"properties\": {\n            \"content\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"items\": {\n                        \"anyOf\": [\n                           {\n                              \"type\": \"string\"\n                           },\n                           {}\n                        ]\n                     },\n                     \"type\": \"array\"\n                  }\n               ],\n               \"title\": \"Content\"\n            },\n            \"source\": {\n               \"title\": \"Source\",\n               \"type\": \"string\"\n            },\n            \"type\": {\n               \"const\": \"UserMessage\",\n               \"default\": \"UserMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"source\"\n         ],\n         \"title\": \"UserMessage\",\n         \"type\": \"object\"\n      }\n   }\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"ChatCompletionContextState\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"messages\": {\n         \"items\": {\n            \"discriminator\": {\n               \"mapping\": {\n                  \"AssistantMessage\": \"#/$defs/AssistantMessage\",\n                  \"FunctionExecutionResultMessage\": \"#/$defs/FunctionExecutionResultMessage\",\n                  \"SystemMessage\": \"#/$defs/SystemMessage\",\n                  \"UserMessage\": \"#/$defs/UserMessage\"\n               },\n               \"propertyName\": \"type\"\n            },\n            \"oneOf\": [\n               {\n                  \"$ref\": \"#/$defs/SystemMessage\"\n               },\n               {\n                  \"$ref\": \"#/$defs/UserMessage\"\n               },\n               {\n                  \"$ref\": \"#/$defs/AssistantMessage\"\n               },\n               {\n                  \"$ref\": \"#/$defs/FunctionExecutionResultMessage\"\n               }\n            ]\n         },\n         \"title\": \"Messages\",\n         \"type\": \"array\"\n      }\n   },\n   \"$defs\": {\n      \"AssistantMessage\": {\n         \"description\": \"Assistant message are sampled from the language model.\",\n         \"properties\": {\n            \"content\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"items\": {\n                        \"$ref\": \"#/$defs/FunctionCall\"\n                     },\n                     \"type\": \"array\"\n                  }\n               ],\n               \"title\": \"Content\"\n            },\n            \"thought\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Thought\"\n            },\n            \"source\": {\n               \"title\": \"Source\",\n               \"type\": \"string\"\n            },\n            \"type\": {\n               \"const\": \"AssistantMessage\",\n               \"default\": \"AssistantMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"source\"\n         ],\n         \"title\": \"AssistantMessage\",\n         \"type\": \"object\"\n      },\n      \"FunctionCall\": {\n         \"properties\": {\n            \"id\": {\n               \"title\": \"Id\",\n               \"type\": \"string\"\n            },\n            \"arguments\": {\n               \"title\": \"Arguments\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"id\",\n            \"arguments\",\n            \"name\"\n         ],\n         \"title\": \"FunctionCall\",\n         \"type\": \"object\"\n      },\n      \"FunctionExecutionResult\": {\n         \"description\": \"Function execution result contains the output of a function call.\",\n         \"properties\": {\n            \"content\": {\n               \"title\": \"Content\",\n               \"type\": \"string\"\n            },\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"call_id\": {\n               \"title\": \"Call Id\",\n               \"type\": \"string\"\n            },\n            \"is_error\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Is Error\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"name\",\n            \"call_id\"\n         ],\n         \"title\": \"FunctionExecutionResult\",\n         \"type\": \"object\"\n      },\n      \"FunctionExecutionResultMessage\": {\n         \"description\": \"Function execution result message contains the output of multiple function calls.\",\n         \"properties\": {\n            \"content\": {\n               \"items\": {\n                  \"$ref\": \"#/$defs/FunctionExecutionResult\"\n               },\n               \"title\": \"Content\",\n               \"type\": \"array\"\n            },\n            \"type\": {\n               \"const\": \"FunctionExecutionResultMessage\",\n               \"default\": \"FunctionExecutionResultMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\"\n         ],\n         \"title\": \"FunctionExecutionResultMessage\",\n         \"type\": \"object\"\n      },\n      \"SystemMessage\": {\n         \"description\": \"System message contains instructions for the model coming from the developer.\\n\\n.. note::\\n\\n    Open AI is moving away from using 'system' role in favor of 'developer' role.\\n    See `Model Spec <https://cdn.openai.com/spec/model-spec-2024-05-08.html#definitions>`_ for more details.\\n    However, the 'system' role is still allowed in their API and will be automatically converted to 'developer' role\\n    on the server side.\\n    So, you can use `SystemMessage` for developer messages.\",\n         \"properties\": {\n            \"content\": {\n               \"title\": \"Content\",\n               \"type\": \"string\"\n            },\n            \"type\": {\n               \"const\": \"SystemMessage\",\n               \"default\": \"SystemMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\"\n         ],\n         \"title\": \"SystemMessage\",\n         \"type\": \"object\"\n      },\n      \"UserMessage\": {\n         \"description\": \"User message contains input from end users, or a catch-all for data provided to the model.\",\n         \"properties\": {\n            \"content\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"items\": {\n                        \"anyOf\": [\n                           {\n                              \"type\": \"string\"\n                           },\n                           {}\n                        ]\n                     },\n                     \"type\": \"array\"\n                  }\n               ],\n               \"title\": \"Content\"\n            },\n            \"source\": {\n               \"title\": \"Source\",\n               \"type\": \"string\"\n            },\n            \"type\": {\n               \"const\": \"UserMessage\",\n               \"default\": \"UserMessage\",\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            }\n         },\n         \"required\": [\n            \"content\",\n            \"source\"\n         ],\n         \"title\": \"UserMessage\",\n         \"type\": \"object\"\n      }\n   }\n}",
      "language": "json"
    }
  ],
  "patterns": [],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}