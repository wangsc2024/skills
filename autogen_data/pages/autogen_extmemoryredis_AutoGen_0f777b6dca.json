{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
  "title": "autogen_ext.memory.redis — AutoGen",
  "content": "Configuration for Redis-based vector memory.\n\nThis class defines the configuration options for using Redis as a vector memory store, supporting semantic memory. It allows customization of the Redis connection, index settings, similarity search parameters, and embedding model.\n\nShow JSON schema{ \"title\": \"RedisMemoryConfig\", \"description\": \"Configuration for Redis-based vector memory.\\n\\nThis class defines the configuration options for using Redis as a vector memory store,\\nsupporting semantic memory. It allows customization of the Redis connection, index settings,\\nsimilarity search parameters, and embedding model.\", \"type\": \"object\", \"properties\": { \"redis_url\": { \"default\": \"redis://localhost:6379\", \"description\": \"url of the Redis instance\", \"title\": \"Redis Url\", \"type\": \"string\" }, \"index_name\": { \"default\": \"chat_history\", \"description\": \"Name of the Redis collection\", \"title\": \"Index Name\", \"type\": \"string\" }, \"prefix\": { \"default\": \"memory\", \"description\": \"prefix of the Redis collection\", \"title\": \"Prefix\", \"type\": \"string\" }, \"sequential\": { \"default\": false, \"description\": \"ignore semantic similarity and simply return memories in sequential order\", \"title\": \"Sequential\", \"type\": \"boolean\" }, \"distance_metric\": { \"default\": \"cosine\", \"enum\": [ \"cosine\", \"ip\", \"l2\" ], \"title\": \"Distance Metric\", \"type\": \"string\" }, \"algorithm\": { \"default\": \"flat\", \"enum\": [ \"flat\", \"hnsw\" ], \"title\": \"Algorithm\", \"type\": \"string\" }, \"top_k\": { \"default\": 10, \"description\": \"Number of results to return in queries\", \"title\": \"Top K\", \"type\": \"integer\" }, \"datatype\": { \"default\": \"float32\", \"enum\": [ \"uint8\", \"int8\", \"float16\", \"float32\", \"float64\", \"bfloat16\" ], \"title\": \"Datatype\", \"type\": \"string\" }, \"distance_threshold\": { \"default\": 0.7, \"description\": \"Minimum similarity score threshold\", \"title\": \"Distance Threshold\", \"type\": \"number\" }, \"model_name\": { \"default\": \"sentence-transformers/all-mpnet-base-v2\", \"description\": \"Embedding model name\", \"title\": \"Model Name\", \"type\": \"string\" } } }\n\nalgorithm (Literal['flat', 'hnsw'])\n\ndatatype (Literal['uint8', 'int8', 'float16', 'float32', 'float64', 'bfloat16'])\n\ndistance_metric (Literal['cosine', 'ip', 'l2'])\n\ndistance_threshold (float)\n\nurl of the Redis instance\n\nName of the Redis collection\n\nprefix of the Redis collection\n\nignore semantic similarity and simply return memories in sequential order\n\nNumber of results to return in queries\n\nMinimum similarity score threshold\n\nBases: Memory, Component[RedisMemoryConfig]\n\nStore and retrieve memory using vector similarity search powered by RedisVL.\n\nRedisMemory provides a vector-based memory implementation that uses RedisVL for storing and retrieving content based on semantic similarity or sequential order. It enhances agents with the ability to recall relevant information during conversations by leveraging vector embeddings to find similar content.\n\nThis implementation requires the RedisVL extra to be installed. Install with:\n\nAdditionally, you will need access to a Redis instance. To run a local instance of redis in docker:\n\nTo download and run Redis locally:\n\nconfig (RedisMemoryConfig | None) – Configuration for the Redis memory. If None, defaults to a RedisMemoryConfig with recommended settings.\n\nalias of RedisMemoryConfig\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nUpdate the model context with relevant memory content.\n\nThis method retrieves memory content relevant to the last message in the context and adds it as a system message. This implementation uses the last message in the context as a query to find semantically similar memories and adds them all to the context as a single system message.\n\nmodel_context (ChatCompletionContext) – The model context to update with relevant memories.\n\nUpdateContextResult – Object containing the memories that were used to update the context.\n\nAdd a memory content object to Redis.\n\nIf RedisMemoryConfig is not set to ‘sequential’, to perform semantic search over stored memories RedisMemory creates a vector embedding from the content field of a MemoryContent object. This content is assumed to be text, JSON, or Markdown, and is passed to the vector embedding model specified in RedisMemoryConfig.\n\ncontent (MemoryContent) – The memory content to store within Redis.\n\ncancellation_token (CancellationToken) – Token passed to cease operation. Not used.\n\nQuery memory content based on semantic vector similarity.\n\nRedisMemory.query() supports additional keyword arguments to improve query performance. top_k (int): The maximum number of relevant memories to include. Defaults to 10. distance_threshold (float): The maximum distance in vector space to consider a memory semantically similar when performining cosine similarity search. Defaults to 0.7. sequential (bool): Ignore semantic similarity and return the top_k most recent memories.\n\nquery (str | MemoryContent) – query to perform vector similarity search with. If a string is passed, a vector embedding is created from it with the model specified in the RedisMemoryConfig. If a MemoryContent object is passed, the content field of this object is extracted and a vector embedding is created from it with the model specified in the RedisMemoryConfig.\n\ncancellation_token (CancellationToken) – Token passed to cease operation. Not used.\n\nmemoryQueryResult – Object containing memories relevant to the provided query.\n\nClear all entries from memory, preserving the RedisMemory resources.\n\nClears all entries from memory, and cleans up Redis client, index and resources.\n\nautogen_ext.memory.mem0\n\nautogen_ext.models.anthropic",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_ext.memory.redis#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "{\n   \"title\": \"RedisMemoryConfig\",\n   \"description\": \"Configuration for Redis-based vector memory.\\n\\nThis class defines the configuration options for using Redis as a vector memory store,\\nsupporting semantic memory. It allows customization of the Redis connection, index settings,\\nsimilarity search parameters, and embedding model.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"redis_url\": {\n         \"default\": \"redis://localhost:6379\",\n         \"description\": \"url of the Redis instance\",\n         \"title\": \"Redis Url\",\n         \"type\": \"string\"\n      },\n      \"index_name\": {\n         \"default\": \"chat_history\",\n         \"description\": \"Name of the Redis collection\",\n         \"title\": \"Index Name\",\n         \"type\": \"string\"\n      },\n      \"prefix\": {\n         \"default\": \"memory\",\n         \"description\": \"prefix of the Redis collection\",\n         \"title\": \"Prefix\",\n         \"type\": \"string\"\n      },\n      \"sequential\": {\n         \"default\": false,\n         \"description\": \"ignore semantic similarity and simply return memories in sequential order\",\n         \"title\": \"Sequential\",\n         \"type\": \"boolean\"\n      },\n      \"distance_metric\": {\n         \"default\": \"cosine\",\n         \"enum\": [\n            \"cosine\",\n            \"ip\",\n            \"l2\"\n         ],\n         \"title\": \"Distance Metric\",\n         \"type\": \"string\"\n      },\n      \"algorithm\": {\n         \"default\": \"flat\",\n         \"enum\": [\n            \"flat\",\n            \"hnsw\"\n         ],\n         \"title\": \"Algorithm\",\n         \"type\": \"string\"\n      },\n      \"top_k\": {\n         \"default\": 10,\n         \"description\": \"Number of results to return in queries\",\n         \"title\": \"Top K\",\n         \"type\": \"integer\"\n      },\n      \"datatype\": {\n         \"default\": \"float32\",\n         \"enum\": [\n            \"uint8\",\n            \"int8\",\n            \"float16\",\n            \"float32\",\n            \"float64\",\n            \"bfloat16\"\n         ],\n         \"title\": \"Datatype\",\n         \"type\": \"string\"\n      },\n      \"distance_threshold\": {\n         \"default\": 0.7,\n         \"description\": \"Minimum similarity score threshold\",\n         \"title\": \"Distance Threshold\",\n         \"type\": \"number\"\n      },\n      \"model_name\": {\n         \"default\": \"sentence-transformers/all-mpnet-base-v2\",\n         \"description\": \"Embedding model name\",\n         \"title\": \"Model Name\",\n         \"type\": \"string\"\n      }\n   }\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"RedisMemoryConfig\",\n   \"description\": \"Configuration for Redis-based vector memory.\\n\\nThis class defines the configuration options for using Redis as a vector memory store,\\nsupporting semantic memory. It allows customization of the Redis connection, index settings,\\nsimilarity search parameters, and embedding model.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"redis_url\": {\n         \"default\": \"redis://localhost:6379\",\n         \"description\": \"url of the Redis instance\",\n         \"title\": \"Redis Url\",\n         \"type\": \"string\"\n      },\n      \"index_name\": {\n         \"default\": \"chat_history\",\n         \"description\": \"Name of the Redis collection\",\n         \"title\": \"Index Name\",\n         \"type\": \"string\"\n      },\n      \"prefix\": {\n         \"default\": \"memory\",\n         \"description\": \"prefix of the Redis collection\",\n         \"title\": \"Prefix\",\n         \"type\": \"string\"\n      },\n      \"sequential\": {\n         \"default\": false,\n         \"description\": \"ignore semantic similarity and simply return memories in sequential order\",\n         \"title\": \"Sequential\",\n         \"type\": \"boolean\"\n      },\n      \"distance_metric\": {\n         \"default\": \"cosine\",\n         \"enum\": [\n            \"cosine\",\n            \"ip\",\n            \"l2\"\n         ],\n         \"title\": \"Distance Metric\",\n         \"type\": \"string\"\n      },\n      \"algorithm\": {\n         \"default\": \"flat\",\n         \"enum\": [\n            \"flat\",\n            \"hnsw\"\n         ],\n         \"title\": \"Algorithm\",\n         \"type\": \"string\"\n      },\n      \"top_k\": {\n         \"default\": 10,\n         \"description\": \"Number of results to return in queries\",\n         \"title\": \"Top K\",\n         \"type\": \"integer\"\n      },\n      \"datatype\": {\n         \"default\": \"float32\",\n         \"enum\": [\n            \"uint8\",\n            \"int8\",\n            \"float16\",\n            \"float32\",\n            \"float64\",\n            \"bfloat16\"\n         ],\n         \"title\": \"Datatype\",\n         \"type\": \"string\"\n      },\n      \"distance_threshold\": {\n         \"default\": 0.7,\n         \"description\": \"Minimum similarity score threshold\",\n         \"title\": \"Distance Threshold\",\n         \"type\": \"number\"\n      },\n      \"model_name\": {\n         \"default\": \"sentence-transformers/all-mpnet-base-v2\",\n         \"description\": \"Embedding model name\",\n         \"title\": \"Model Name\",\n         \"type\": \"string\"\n      }\n   }\n}",
      "language": "json"
    },
    {
      "code": "pip install \"autogen-ext[redisvl]\"",
      "language": "unknown"
    },
    {
      "code": "pip install \"autogen-ext[redisvl]\"",
      "language": "unknown"
    },
    {
      "code": "docker run -d --name redis -p 6379:6379 redis:8",
      "language": "json"
    },
    {
      "code": "docker run -d --name redis -p 6379:6379 redis:8",
      "language": "json"
    },
    {
      "code": "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\nsudo apt-get update  > /dev/null 2>&1\nsudo apt-get install redis-server  > /dev/null 2>&1\nredis-server --daemonize yes",
      "language": "sql"
    },
    {
      "code": "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\nsudo apt-get update  > /dev/null 2>&1\nsudo apt-get install redis-server  > /dev/null 2>&1\nredis-server --daemonize yes",
      "language": "sql"
    },
    {
      "code": "from logging import WARNING, getLogger\n\nimport asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core.memory import MemoryContent, MemoryMimeType\nfrom autogen_ext.memory.redis import RedisMemory, RedisMemoryConfig\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nlogger = getLogger()\nlogger.setLevel(WARNING)\n\n\n# Define tool to use\nasync def get_weather(city: str, units: str = \"imperial\") -> str:\n    if units == \"imperial\":\n        return f\"The weather in {city} is 73 °F and Sunny.\"\n    elif units == \"metric\":\n        return f\"The weather in {city} is 23 °C and Sunny.\"\n    else:\n        return f\"Sorry, I don't know the weather in {city}.\"\n\n\nasync def main():\n    # Initailize Redis memory\n    redis_memory = RedisMemory(\n        config=RedisMemoryConfig(\n            redis_url=\"redis://localhost:6379\",\n            index_name=\"chat_history\",\n            prefix=\"memory\",\n        )\n    )\n\n    # Add user preferences to memory\n    await redis_memory.add(\n        MemoryContent(\n            content=\"The weather should be in metric units\",\n            mime_type=MemoryMimeType.TEXT,\n            metadata={\"category\": \"preferences\", \"type\": \"units\"},\n        )\n    )\n\n    await redis_memory.add(\n        MemoryContent(\n            content=\"Meal recipe must be vegan\",\n            mime_type=MemoryMimeType.TEXT,\n            metadata={\"category\": \"preferences\", \"type\": \"dietary\"},\n        )\n    )\n\n    model_client = OpenAIChatCompletionClient(\n        model=\"gpt-4o\",\n    )\n\n    # Create assistant agent with ChromaDB memory\n    assistant_agent = AssistantAgent(\n        name=\"assistant_agent\",\n        model_client=model_client,\n        tools=[get_weather],\n        memory=[redis_memory],\n    )\n\n    stream = assistant_agent.run_stream(task=\"What is the weather in New York?\")\n    await Console(stream)\n\n    await model_client.close()\n    await redis_memory.close()\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "from logging import WARNING, getLogger\n\nimport asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_core.memory import MemoryContent, MemoryMimeType\nfrom autogen_ext.memory.redis import RedisMemory, RedisMemoryConfig\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nlogger = getLogger()\nlogger.setLevel(WARNING)\n\n\n# Define tool to use\nasync def get_weather(city: str, units: str = \"imperial\") -> str:\n    if units == \"imperial\":\n        return f\"The weather in {city} is 73 °F and Sunny.\"\n    elif units == \"metric\":\n        return f\"The weather in {city} is 23 °C and Sunny.\"\n    else:\n        return f\"Sorry, I don't know the weather in {city}.\"\n\n\nasync def main():\n    # Initailize Redis memory\n    redis_memory = RedisMemory(\n        config=RedisMemoryConfig(\n            redis_url=\"redis://localhost:6379\",\n            index_name=\"chat_history\",\n            prefix=\"memory\",\n        )\n    )\n\n    # Add user preferences to memory\n    await redis_memory.add(\n        MemoryContent(\n            content=\"The weather should be in metric units\",\n            mime_type=MemoryMimeType.TEXT,\n            metadata={\"category\": \"preferences\", \"type\": \"units\"},\n        )\n    )\n\n    await redis_memory.add(\n        MemoryContent(\n            content=\"Meal recipe must be vegan\",\n            mime_type=MemoryMimeType.TEXT,\n            metadata={\"category\": \"preferences\", \"type\": \"dietary\"},\n        )\n    )\n\n    model_client = OpenAIChatCompletionClient(\n        model=\"gpt-4o\",\n    )\n\n    # Create assistant agent with ChromaDB memory\n    assistant_agent = AssistantAgent(\n        name=\"assistant_agent\",\n        model_client=model_client,\n        tools=[get_weather],\n        memory=[redis_memory],\n    )\n\n    stream = assistant_agent.run_stream(task=\"What is the weather in New York?\")\n    await Console(stream)\n\n    await model_client.close()\n    await redis_memory.close()\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "---------- TextMessage (user) ----------\nWhat is the weather in New York?\n---------- MemoryQueryEvent (assistant_agent) ----------\n[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata={'category': 'preferences', 'type': 'units'})]\n---------- ToolCallRequestEvent (assistant_agent) ----------\n[FunctionCall(id='call_tyCPvPPAV4SHWhtfpM6UMemr', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n---------- ToolCallExecutionEvent (assistant_agent) ----------\n[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_tyCPvPPAV4SHWhtfpM6UMemr', is_error=False)]\n---------- ToolCallSummaryMessage (assistant_agent) ----------\nThe weather in New York is 23 °C and Sunny.",
      "language": "json"
    },
    {
      "code": "---------- TextMessage (user) ----------\nWhat is the weather in New York?\n---------- MemoryQueryEvent (assistant_agent) ----------\n[MemoryContent(content='The weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata={'category': 'preferences', 'type': 'units'})]\n---------- ToolCallRequestEvent (assistant_agent) ----------\n[FunctionCall(id='call_tyCPvPPAV4SHWhtfpM6UMemr', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n---------- ToolCallExecutionEvent (assistant_agent) ----------\n[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_tyCPvPPAV4SHWhtfpM6UMemr', is_error=False)]\n---------- ToolCallSummaryMessage (assistant_agent) ----------\nThe weather in New York is 23 °C and Sunny.",
      "language": "json"
    }
  ],
  "patterns": [],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}