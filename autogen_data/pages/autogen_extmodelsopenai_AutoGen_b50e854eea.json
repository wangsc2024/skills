{
  "url": "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
  "title": "autogen_ext.models.openai — AutoGen",
  "content": "Bases: BaseOpenAIChatCompletionClient, Component[OpenAIClientConfigurationConfigModel]\n\nChat completion client for OpenAI hosted models.\n\nTo use this client, you must install the openai extra:\n\nYou can also use this client for OpenAI-compatible ChatCompletion endpoints. Using this client for non-OpenAI models is not tested or guaranteed.\n\nFor non-OpenAI models, please first take a look at our community extensions for additional model clients.\n\nmodel (str) – Which OpenAI model to use.\n\napi_key (optional, str) – The API key to use. Required if ‘OPENAI_API_KEY’ is not found in the environment variables.\n\norganization (optional, str) – The organization ID to use.\n\nbase_url (optional, str) – The base URL to use. Required if the model is not hosted on OpenAI.\n\ntimeout – (optional, float): The timeout for the request in seconds.\n\nmax_retries (optional, int) – The maximum number of retries to attempt.\n\nmodel_info (optional, ModelInfo) – The capabilities of the model. Required if the model name is not a valid OpenAI model.\n\nfrequency_penalty (optional, float)\n\nlogit_bias – (optional, dict[str, int]):\n\nmax_tokens (optional, int)\n\npresence_penalty (optional, float)\n\nresponse_format (optional, Dict[str, Any]) – the format of the response. Possible options are: # Text response, this is the default. {\"type\": \"text\"} # JSON response, make sure to instruct the model to return JSON. {\"type\": \"json_object\"} # Structured output response, with a pre-defined JSON schema. { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"name of the schema, must be an identifier.\", \"description\": \"description for the model.\", # You can convert a Pydantic (v2) model to JSON schema # using the `model_json_schema()` method. \"schema\": \"<the JSON schema itself>\", # Whether to enable strict schema adherence when # generating the output. If set to true, the model will # always follow the exact schema defined in the # `schema` field. Only a subset of JSON Schema is # supported when `strict` is `true`. # To learn more, read # https://platform.openai.com/docs/guides/structured-outputs. \"strict\": False, # or True }, } It is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly.\n\nthe format of the response. Possible options are:\n\nIt is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly.\n\nstop (optional, str | List[str])\n\ntemperature (optional, float)\n\ntop_p (optional, float)\n\nparallel_tool_calls (optional, bool) – Whether to allow parallel tool calls. When not set, defaults to server behavior.\n\ndefault_headers (optional, dict[str, str]) – Custom headers; useful for authentication or other custom requirements.\n\nadd_name_prefixes (optional, bool) – Whether to prepend the source value to each UserMessage content. E.g., “this is content” becomes “Reviewer said: this is content.” This can be useful for models that do not support the name field in message. Defaults to False.\n\ninclude_name_in_message (optional, bool) – Whether to include the name field in user message parameters sent to the OpenAI API. Defaults to True. Set to False for model providers that don’t support the name field (e.g., Groq).\n\nstream_options (optional, dict) – Additional options for streaming. Currently only include_usage is supported.\n\nThe following code snippet shows how to use the client with an OpenAI model:\n\nTo use the client with a non-OpenAI model, you need to provide the base URL of the model and the model info. For example, to use Ollama, you can use the following code snippet:\n\nTo use streaming mode, you can use the following code snippet:\n\nTo use structured output as well as function calling, you can use the following code snippet:\n\nTo load the client from a configuration, you can use the load_component method:\n\nTo view the full list of available configuration options, see the OpenAIClientConfigurationConfigModel class.\n\nThe logical type of the component.\n\nalias of OpenAIClientConfigurationConfigModel\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: BaseOpenAIChatCompletionClient, Component[AzureOpenAIClientConfigurationConfigModel]\n\nChat completion client for Azure OpenAI hosted models.\n\nTo use this client, you must install the azure and openai extensions:\n\nmodel (str) – Which OpenAI model to use.\n\nazure_endpoint (str) – The endpoint for the Azure model. Required for Azure models.\n\nazure_deployment (str) – Deployment name for the Azure model. Required for Azure models.\n\napi_version (str) – The API version to use. Required for Azure models.\n\nazure_ad_token (str) – The Azure AD token to use. Provide this or azure_ad_token_provider for token-based authentication.\n\nazure_ad_token_provider (optional, Callable[[], Awaitable[str]] | AzureTokenProvider) – The Azure AD token provider to use. Provide this or azure_ad_token for token-based authentication.\n\napi_key (optional, str) – The API key to use, use this if you are using key based authentication. It is optional if you are using Azure AD token based authentication or AZURE_OPENAI_API_KEY environment variable.\n\ntimeout – (optional, float): The timeout for the request in seconds.\n\nmax_retries (optional, int) – The maximum number of retries to attempt.\n\nmodel_info (optional, ModelInfo) – The capabilities of the model. Required if the model name is not a valid OpenAI model.\n\nfrequency_penalty (optional, float)\n\nlogit_bias – (optional, dict[str, int]):\n\nmax_tokens (optional, int)\n\npresence_penalty (optional, float)\n\nresponse_format (optional, Dict[str, Any]) – the format of the response. Possible options are: # Text response, this is the default. {\"type\": \"text\"} # JSON response, make sure to instruct the model to return JSON. {\"type\": \"json_object\"} # Structured output response, with a pre-defined JSON schema. { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"name of the schema, must be an identifier.\", \"description\": \"description for the model.\", # You can convert a Pydantic (v2) model to JSON schema # using the `model_json_schema()` method. \"schema\": \"<the JSON schema itself>\", # Whether to enable strict schema adherence when # generating the output. If set to true, the model will # always follow the exact schema defined in the # `schema` field. Only a subset of JSON Schema is # supported when `strict` is `true`. # To learn more, read # https://platform.openai.com/docs/guides/structured-outputs. \"strict\": False, # or True }, } It is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly.\n\nthe format of the response. Possible options are:\n\nIt is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly.\n\nstop (optional, str | List[str])\n\ntemperature (optional, float)\n\ntop_p (optional, float)\n\nparallel_tool_calls (optional, bool) – Whether to allow parallel tool calls. When not set, defaults to server behavior.\n\ndefault_headers (optional, dict[str, str]) – Custom headers; useful for authentication or other custom requirements.\n\nadd_name_prefixes (optional, bool) – Whether to prepend the source value to each UserMessage content. E.g., “this is content” becomes “Reviewer said: this is content.” This can be useful for models that do not support the name field in message. Defaults to False.\n\ninclude_name_in_message (optional, bool) – Whether to include the name field in user message parameters sent to the OpenAI API. Defaults to True. Set to False for model providers that don’t support the name field (e.g., Groq).\n\nstream_options (optional, dict) – Additional options for streaming. Currently only include_usage is supported.\n\nTo use the client, you need to provide your deployment name, Azure Cognitive Services endpoint, and api version. For authentication, you can either provide an API key or an Azure Active Directory (AAD) token credential.\n\nThe following code snippet shows how to use AAD authentication. The identity used must be assigned the Cognitive Services OpenAI User role.\n\nSee other usage examples in the OpenAIChatCompletionClient class.\n\nTo load the client that uses identity based aith from a configuration, you can use the load_component method:\n\nTo view the full list of available configuration options, see the AzureOpenAIClientConfigurationConfigModel class.\n\nRight now only DefaultAzureCredential is supported with no additional args passed to it.\n\nThe Azure OpenAI client by default sets the User-Agent header to autogen-python/{version}. To override this, you can set the variable autogen_ext.models.openai.AZURE_OPENAI_USER_AGENT environment variable to an empty string.\n\nSee here for how to use the Azure client directly or for more info.\n\nThe logical type of the component.\n\nalias of AzureOpenAIClientConfigurationConfigModel\n\nOverride the provider string for the component. This should be used to prevent internal module names being a part of the module name.\n\nDump the configuration that would be requite to create a new instance of a component matching the configuration of this instance.\n\nT – The configuration of the component.\n\nCreate a new instance of the component from a configuration object.\n\nconfig (T) – The configuration object.\n\nSelf – The new instance of the component.\n\nBases: ChatCompletionClient\n\nCreates a single response from the model.\n\nmessages (Sequence[LLMMessage]) – The messages to send to the model.\n\ntools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to [].\n\ntool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”.\n\njson_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt.\n\nextra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}.\n\ncancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None.\n\nCreateResult – The result of the model call.\n\nCreate a stream of string chunks from the model ending with a CreateResult.\n\nExtends autogen_core.models.ChatCompletionClient.create_stream() to support OpenAI API.\n\nIn streaming, the default behaviour is not return token usage counts. See: OpenAI API reference for possible args.\n\nYou can set set the include_usage flag to True or extra_create_args={“stream_options”: {“include_usage”: True}}. If both the flag and stream_options are set, but to different values, an exception will be raised. (if supported by the accessed API) to return a final chunk with usage set to a RequestUsage object with prompt and completion token counts, all preceding chunks will have usage as None. See: OpenAI API reference for stream options.\n\ntemperature (float): Controls the randomness of the output. Higher values (e.g., 0.8) make the output more random, while lower values (e.g., 0.2) make it more focused and deterministic.\n\nmax_tokens (int): The maximum number of tokens to generate in the completion.\n\ntop_p (float): An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.\n\nfrequency_penalty (float): A value between -2.0 and 2.0 that penalizes new tokens based on their existing frequency in the text so far, decreasing the likelihood of repeated phrases.\n\npresence_penalty (float): A value between -2.0 and 2.0 that penalizes new tokens based on whether they appear in the text so far, encouraging the model to talk about new topics.\n\nBases: BaseOpenAIClientConfigurationConfigModel\n\nShow JSON schema{ \"title\": \"AzureOpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"azure_endpoint\": { \"title\": \"Azure Endpoint\", \"type\": \"string\" }, \"azure_deployment\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Azure Deployment\" }, \"api_version\": { \"title\": \"Api Version\", \"type\": \"string\" }, \"azure_ad_token\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Azure Ad Token\" }, \"azure_ad_token_provider\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ComponentModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"ComponentModel\": { \"description\": \"Model class for a component. Contains all information required to instantiate a component.\", \"properties\": { \"provider\": { \"title\": \"Provider\", \"type\": \"string\" }, \"component_type\": { \"anyOf\": [ { \"enum\": [ \"model\", \"agent\", \"tool\", \"termination\", \"token_provider\", \"workbench\" ], \"type\": \"string\" }, { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Component Type\" }, \"version\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Version\" }, \"component_version\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Component Version\" }, \"description\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Description\" }, \"label\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Label\" }, \"config\": { \"title\": \"Config\", \"type\": \"object\" } }, \"required\": [ \"provider\", \"config\" ], \"title\": \"ComponentModel\", \"type\": \"object\" }, \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\", \"azure_endpoint\", \"api_version\" ] }\n\nazure_ad_token (str | None)\n\nazure_ad_token_provider (autogen_core._component_config.ComponentModel | None)\n\nazure_deployment (str | None)\n\nBases: BaseOpenAIClientConfigurationConfigModel\n\nShow JSON schema{ \"title\": \"OpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"organization\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Organization\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\" ] }\n\nbase_url (str | None)\n\norganization (str | None)\n\nBases: CreateArgumentsConfigModel\n\nShow JSON schema{ \"title\": \"BaseOpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\" ] }\n\nadd_name_prefixes (bool | None)\n\napi_key (pydantic.types.SecretStr | None)\n\ndefault_headers (Dict[str, str] | None)\n\ninclude_name_in_message (bool | None)\n\nmax_retries (int | None)\n\nmodel_capabilities (autogen_core.models._model_client.ModelCapabilities | None)\n\nmodel_info (autogen_core.models._model_client.ModelInfo | None)\n\ntimeout (float | None)\n\nShow JSON schema{ \"title\": \"CreateArgumentsConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } } }\n\nfrequency_penalty (float | None)\n\nlogit_bias (Dict[str, int] | None)\n\nmax_tokens (int | None)\n\nparallel_tool_calls (bool | None)\n\npresence_penalty (float | None)\n\nreasoning_effort (Literal['minimal', 'low', 'medium', 'high'] | None)\n\nresponse_format (autogen_ext.models.openai.config.ResponseFormat | None)\n\nstop (str | List[str] | None)\n\nstream_options (autogen_ext.models.openai.config.StreamOptions | None)\n\ntemperature (float | None)\n\nautogen_ext.models.ollama\n\nautogen_ext.models.replay",
  "headings": [
    {
      "level": "h1",
      "text": "autogen_ext.models.openai#",
      "id": ""
    }
  ],
  "code_samples": [
    {
      "code": "pip install \"autogen-ext[openai]\"",
      "language": "unknown"
    },
    {
      "code": "pip install \"autogen-ext[openai]\"",
      "language": "unknown"
    },
    {
      "code": "# Text response, this is the default.\n{\"type\": \"text\"}",
      "language": "json"
    },
    {
      "code": "# Text response, this is the default.\n{\"type\": \"text\"}",
      "language": "json"
    },
    {
      "code": "# JSON response, make sure to instruct the model to return JSON.\n{\"type\": \"json_object\"}",
      "language": "json"
    },
    {
      "code": "# JSON response, make sure to instruct the model to return JSON.\n{\"type\": \"json_object\"}",
      "language": "json"
    },
    {
      "code": "# Structured output response, with a pre-defined JSON schema.\n{\n    \"type\": \"json_schema\",\n    \"json_schema\": {\n        \"name\": \"name of the schema, must be an identifier.\",\n        \"description\": \"description for the model.\",\n        # You can convert a Pydantic (v2) model to JSON schema\n        # using the `model_json_schema()` method.\n        \"schema\": \"<the JSON schema itself>\",\n        # Whether to enable strict schema adherence when\n        # generating the output. If set to true, the model will\n        # always follow the exact schema defined in the\n        # `schema` field. Only a subset of JSON Schema is\n        # supported when `strict` is `true`.\n        # To learn more, read\n        # https://platform.openai.com/docs/guides/structured-outputs.\n        \"strict\": False,  # or True\n    },\n}",
      "language": "json"
    },
    {
      "code": "# Structured output response, with a pre-defined JSON schema.\n{\n    \"type\": \"json_schema\",\n    \"json_schema\": {\n        \"name\": \"name of the schema, must be an identifier.\",\n        \"description\": \"description for the model.\",\n        # You can convert a Pydantic (v2) model to JSON schema\n        # using the `model_json_schema()` method.\n        \"schema\": \"<the JSON schema itself>\",\n        # Whether to enable strict schema adherence when\n        # generating the output. If set to true, the model will\n        # always follow the exact schema defined in the\n        # `schema` field. Only a subset of JSON Schema is\n        # supported when `strict` is `true`.\n        # To learn more, read\n        # https://platform.openai.com/docs/guides/structured-outputs.\n        \"strict\": False,  # or True\n    },\n}",
      "language": "json"
    },
    {
      "code": "from autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_core.models import UserMessage\n\nopenai_client = OpenAIChatCompletionClient(\n    model=\"gpt-4o-2024-08-06\",\n    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY environment variable set.\n)\n\nresult = await openai_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\nprint(result)\n\n# Close the client when done.\n# await openai_client.close()",
      "language": "python"
    },
    {
      "code": "from autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_core.models import UserMessage\n\nopenai_client = OpenAIChatCompletionClient(\n    model=\"gpt-4o-2024-08-06\",\n    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY environment variable set.\n)\n\nresult = await openai_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])  # type: ignore\nprint(result)\n\n# Close the client when done.\n# await openai_client.close()",
      "language": "python"
    },
    {
      "code": "from autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_core.models import ModelFamily\n\ncustom_model_client = OpenAIChatCompletionClient(\n    model=\"deepseek-r1:1.5b\",\n    base_url=\"http://localhost:11434/v1\",\n    api_key=\"placeholder\",\n    model_info={\n        \"vision\": False,\n        \"function_calling\": False,\n        \"json_output\": False,\n        \"family\": ModelFamily.R1,\n        \"structured_output\": True,\n    },\n)\n\n# Close the client when done.\n# await custom_model_client.close()",
      "language": "json"
    },
    {
      "code": "from autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_core.models import ModelFamily\n\ncustom_model_client = OpenAIChatCompletionClient(\n    model=\"deepseek-r1:1.5b\",\n    base_url=\"http://localhost:11434/v1\",\n    api_key=\"placeholder\",\n    model_info={\n        \"vision\": False,\n        \"function_calling\": False,\n        \"json_output\": False,\n        \"family\": ModelFamily.R1,\n        \"structured_output\": True,\n    },\n)\n\n# Close the client when done.\n# await custom_model_client.close()",
      "language": "json"
    },
    {
      "code": "import asyncio\nfrom autogen_core.models import UserMessage\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n\nasync def main() -> None:\n    # Similar for AzureOpenAIChatCompletionClient.\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")  # assuming OPENAI_API_KEY is set in the environment.\n\n    messages = [UserMessage(content=\"Write a very short story about a dragon.\", source=\"user\")]\n\n    # Create a stream.\n    stream = model_client.create_stream(messages=messages)\n\n    # Iterate over the stream and print the responses.\n    print(\"Streamed responses:\")\n    async for response in stream:\n        if isinstance(response, str):\n            # A partial response is a string.\n            print(response, flush=True, end=\"\")\n        else:\n            # The last response is a CreateResult object with the complete message.\n            print(\"\\n\\n------------\\n\")\n            print(\"The complete response:\", flush=True)\n            print(response.content, flush=True)\n\n    # Close the client when done.\n    await model_client.close()\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom autogen_core.models import UserMessage\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\n\nasync def main() -> None:\n    # Similar for AzureOpenAIChatCompletionClient.\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")  # assuming OPENAI_API_KEY is set in the environment.\n\n    messages = [UserMessage(content=\"Write a very short story about a dragon.\", source=\"user\")]\n\n    # Create a stream.\n    stream = model_client.create_stream(messages=messages)\n\n    # Iterate over the stream and print the responses.\n    print(\"Streamed responses:\")\n    async for response in stream:\n        if isinstance(response, str):\n            # A partial response is a string.\n            print(response, flush=True, end=\"\")\n        else:\n            # The last response is a CreateResult object with the complete message.\n            print(\"\\n\\n------------\\n\")\n            print(\"The complete response:\", flush=True)\n            print(response.content, flush=True)\n\n    # Close the client when done.\n    await model_client.close()\n\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom typing import Literal\n\nfrom autogen_core.models import (\n    AssistantMessage,\n    FunctionExecutionResult,\n    FunctionExecutionResultMessage,\n    SystemMessage,\n    UserMessage,\n)\nfrom autogen_core.tools import FunctionTool\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom pydantic import BaseModel\n\n\n# Define the structured output format.\nclass AgentResponse(BaseModel):\n    thoughts: str\n    response: Literal[\"happy\", \"sad\", \"neutral\"]\n\n\n# Define the function to be called as a tool.\ndef sentiment_analysis(text: str) -> str:\n    \"\"\"Given a text, return the sentiment.\"\"\"\n    return \"happy\" if \"happy\" in text else \"sad\" if \"sad\" in text else \"neutral\"\n\n\n# Create a FunctionTool instance with `strict=True`,\n# which is required for structured output mode.\ntool = FunctionTool(sentiment_analysis, description=\"Sentiment Analysis\", strict=True)\n\n\nasync def main() -> None:\n    # Create an OpenAIChatCompletionClient instance.\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n\n    # Generate a response using the tool.\n    response1 = await model_client.create(\n        messages=[\n            SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"),\n            UserMessage(content=\"I am happy.\", source=\"user\"),\n        ],\n        tools=[tool],\n    )\n    print(response1.content)\n    # Should be a list of tool calls.\n    # [FunctionCall(name=\"sentiment_analysis\", arguments={\"text\": \"I am happy.\"}, ...)]\n\n    assert isinstance(response1.content, list)\n    response2 = await model_client.create(\n        messages=[\n            SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"),\n            UserMessage(content=\"I am happy.\", source=\"user\"),\n            AssistantMessage(content=response1.content, source=\"assistant\"),\n            FunctionExecutionResultMessage(\n                content=[FunctionExecutionResult(content=\"happy\", call_id=response1.content[0].id, is_error=False, name=\"sentiment_analysis\")]\n            ),\n        ],\n        # Use the structured output format.\n        json_output=AgentResponse,\n    )\n    print(response2.content)\n    # Should be a structured output.\n    # {\"thoughts\": \"The user is happy.\", \"response\": \"happy\"}\n\n    # Close the client when done.\n    await model_client.close()\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "import asyncio\nfrom typing import Literal\n\nfrom autogen_core.models import (\n    AssistantMessage,\n    FunctionExecutionResult,\n    FunctionExecutionResultMessage,\n    SystemMessage,\n    UserMessage,\n)\nfrom autogen_core.tools import FunctionTool\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom pydantic import BaseModel\n\n\n# Define the structured output format.\nclass AgentResponse(BaseModel):\n    thoughts: str\n    response: Literal[\"happy\", \"sad\", \"neutral\"]\n\n\n# Define the function to be called as a tool.\ndef sentiment_analysis(text: str) -> str:\n    \"\"\"Given a text, return the sentiment.\"\"\"\n    return \"happy\" if \"happy\" in text else \"sad\" if \"sad\" in text else \"neutral\"\n\n\n# Create a FunctionTool instance with `strict=True`,\n# which is required for structured output mode.\ntool = FunctionTool(sentiment_analysis, description=\"Sentiment Analysis\", strict=True)\n\n\nasync def main() -> None:\n    # Create an OpenAIChatCompletionClient instance.\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n\n    # Generate a response using the tool.\n    response1 = await model_client.create(\n        messages=[\n            SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"),\n            UserMessage(content=\"I am happy.\", source=\"user\"),\n        ],\n        tools=[tool],\n    )\n    print(response1.content)\n    # Should be a list of tool calls.\n    # [FunctionCall(name=\"sentiment_analysis\", arguments={\"text\": \"I am happy.\"}, ...)]\n\n    assert isinstance(response1.content, list)\n    response2 = await model_client.create(\n        messages=[\n            SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"),\n            UserMessage(content=\"I am happy.\", source=\"user\"),\n            AssistantMessage(content=response1.content, source=\"assistant\"),\n            FunctionExecutionResultMessage(\n                content=[FunctionExecutionResult(content=\"happy\", call_id=response1.content[0].id, is_error=False, name=\"sentiment_analysis\")]\n            ),\n        ],\n        # Use the structured output format.\n        json_output=AgentResponse,\n    )\n    print(response2.content)\n    # Should be a structured output.\n    # {\"thoughts\": \"The user is happy.\", \"response\": \"happy\"}\n\n    # Close the client when done.\n    await model_client.close()\n\nasyncio.run(main())",
      "language": "python"
    },
    {
      "code": "from autogen_core.models import ChatCompletionClient\n\nconfig = {\n    \"provider\": \"OpenAIChatCompletionClient\",\n    \"config\": {\"model\": \"gpt-4o\", \"api_key\": \"REPLACE_WITH_YOUR_API_KEY\"},\n}\n\nclient = ChatCompletionClient.load_component(config)",
      "language": "json"
    },
    {
      "code": "from autogen_core.models import ChatCompletionClient\n\nconfig = {\n    \"provider\": \"OpenAIChatCompletionClient\",\n    \"config\": {\"model\": \"gpt-4o\", \"api_key\": \"REPLACE_WITH_YOUR_API_KEY\"},\n}\n\nclient = ChatCompletionClient.load_component(config)",
      "language": "json"
    },
    {
      "code": "pip install \"autogen-ext[openai,azure]\"",
      "language": "unknown"
    },
    {
      "code": "pip install \"autogen-ext[openai,azure]\"",
      "language": "unknown"
    },
    {
      "code": "# Text response, this is the default.\n{\"type\": \"text\"}",
      "language": "json"
    },
    {
      "code": "# Text response, this is the default.\n{\"type\": \"text\"}",
      "language": "json"
    },
    {
      "code": "# JSON response, make sure to instruct the model to return JSON.\n{\"type\": \"json_object\"}",
      "language": "json"
    },
    {
      "code": "# JSON response, make sure to instruct the model to return JSON.\n{\"type\": \"json_object\"}",
      "language": "json"
    },
    {
      "code": "# Structured output response, with a pre-defined JSON schema.\n{\n    \"type\": \"json_schema\",\n    \"json_schema\": {\n        \"name\": \"name of the schema, must be an identifier.\",\n        \"description\": \"description for the model.\",\n        # You can convert a Pydantic (v2) model to JSON schema\n        # using the `model_json_schema()` method.\n        \"schema\": \"<the JSON schema itself>\",\n        # Whether to enable strict schema adherence when\n        # generating the output. If set to true, the model will\n        # always follow the exact schema defined in the\n        # `schema` field. Only a subset of JSON Schema is\n        # supported when `strict` is `true`.\n        # To learn more, read\n        # https://platform.openai.com/docs/guides/structured-outputs.\n        \"strict\": False,  # or True\n    },\n}",
      "language": "json"
    },
    {
      "code": "# Structured output response, with a pre-defined JSON schema.\n{\n    \"type\": \"json_schema\",\n    \"json_schema\": {\n        \"name\": \"name of the schema, must be an identifier.\",\n        \"description\": \"description for the model.\",\n        # You can convert a Pydantic (v2) model to JSON schema\n        # using the `model_json_schema()` method.\n        \"schema\": \"<the JSON schema itself>\",\n        # Whether to enable strict schema adherence when\n        # generating the output. If set to true, the model will\n        # always follow the exact schema defined in the\n        # `schema` field. Only a subset of JSON Schema is\n        # supported when `strict` is `true`.\n        # To learn more, read\n        # https://platform.openai.com/docs/guides/structured-outputs.\n        \"strict\": False,  # or True\n    },\n}",
      "language": "json"
    },
    {
      "code": "from autogen_ext.auth.azure import AzureTokenProvider\nfrom autogen_ext.models.openai import AzureOpenAIChatCompletionClient\nfrom azure.identity import DefaultAzureCredential\n\n# Create the token provider\ntoken_provider = AzureTokenProvider(\n    DefaultAzureCredential(),\n    \"https://cognitiveservices.azure.com/.default\",\n)\n\naz_model_client = AzureOpenAIChatCompletionClient(\n    azure_deployment=\"{your-azure-deployment}\",\n    model=\"{model-name, such as gpt-4o}\",\n    api_version=\"2024-06-01\",\n    azure_endpoint=\"https://{your-custom-endpoint}.openai.azure.com/\",\n    azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n    # api_key=\"sk-...\", # For key-based authentication.\n)",
      "language": "sql"
    },
    {
      "code": "from autogen_ext.auth.azure import AzureTokenProvider\nfrom autogen_ext.models.openai import AzureOpenAIChatCompletionClient\nfrom azure.identity import DefaultAzureCredential\n\n# Create the token provider\ntoken_provider = AzureTokenProvider(\n    DefaultAzureCredential(),\n    \"https://cognitiveservices.azure.com/.default\",\n)\n\naz_model_client = AzureOpenAIChatCompletionClient(\n    azure_deployment=\"{your-azure-deployment}\",\n    model=\"{model-name, such as gpt-4o}\",\n    api_version=\"2024-06-01\",\n    azure_endpoint=\"https://{your-custom-endpoint}.openai.azure.com/\",\n    azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n    # api_key=\"sk-...\", # For key-based authentication.\n)",
      "language": "sql"
    },
    {
      "code": "from autogen_core.models import ChatCompletionClient\n\nconfig = {\n    \"provider\": \"AzureOpenAIChatCompletionClient\",\n    \"config\": {\n        \"model\": \"gpt-4o-2024-05-13\",\n        \"azure_endpoint\": \"https://{your-custom-endpoint}.openai.azure.com/\",\n        \"azure_deployment\": \"{your-azure-deployment}\",\n        \"api_version\": \"2024-06-01\",\n        \"azure_ad_token_provider\": {\n            \"provider\": \"autogen_ext.auth.azure.AzureTokenProvider\",\n            \"config\": {\n                \"provider_kind\": \"DefaultAzureCredential\",\n                \"scopes\": [\"https://cognitiveservices.azure.com/.default\"],\n            },\n        },\n    },\n}\n\nclient = ChatCompletionClient.load_component(config)",
      "language": "json"
    },
    {
      "code": "from autogen_core.models import ChatCompletionClient\n\nconfig = {\n    \"provider\": \"AzureOpenAIChatCompletionClient\",\n    \"config\": {\n        \"model\": \"gpt-4o-2024-05-13\",\n        \"azure_endpoint\": \"https://{your-custom-endpoint}.openai.azure.com/\",\n        \"azure_deployment\": \"{your-azure-deployment}\",\n        \"api_version\": \"2024-06-01\",\n        \"azure_ad_token_provider\": {\n            \"provider\": \"autogen_ext.auth.azure.AzureTokenProvider\",\n            \"config\": {\n                \"provider_kind\": \"DefaultAzureCredential\",\n                \"scopes\": [\"https://cognitiveservices.azure.com/.default\"],\n            },\n        },\n    },\n}\n\nclient = ChatCompletionClient.load_component(config)",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AzureOpenAIClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"add_name_prefixes\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Add Name Prefixes\"\n      },\n      \"include_name_in_message\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Include Name In Message\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"azure_endpoint\": {\n         \"title\": \"Azure Endpoint\",\n         \"type\": \"string\"\n      },\n      \"azure_deployment\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Azure Deployment\"\n      },\n      \"api_version\": {\n         \"title\": \"Api Version\",\n         \"type\": \"string\"\n      },\n      \"azure_ad_token\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Azure Ad Token\"\n      },\n      \"azure_ad_token_provider\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ComponentModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      }\n   },\n   \"$defs\": {\n      \"ComponentModel\": {\n         \"description\": \"Model class for a component. Contains all information required to instantiate a component.\",\n         \"properties\": {\n            \"provider\": {\n               \"title\": \"Provider\",\n               \"type\": \"string\"\n            },\n            \"component_type\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"model\",\n                        \"agent\",\n                        \"tool\",\n                        \"termination\",\n                        \"token_provider\",\n                        \"workbench\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Component Type\"\n            },\n            \"version\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Version\"\n            },\n            \"component_version\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Component Version\"\n            },\n            \"description\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Description\"\n            },\n            \"label\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Label\"\n            },\n            \"config\": {\n               \"title\": \"Config\",\n               \"type\": \"object\"\n            }\n         },\n         \"required\": [\n            \"provider\",\n            \"config\"\n         ],\n         \"title\": \"ComponentModel\",\n         \"type\": \"object\"\n      },\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\",\n      \"azure_endpoint\",\n      \"api_version\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"AzureOpenAIClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"add_name_prefixes\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Add Name Prefixes\"\n      },\n      \"include_name_in_message\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Include Name In Message\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"azure_endpoint\": {\n         \"title\": \"Azure Endpoint\",\n         \"type\": \"string\"\n      },\n      \"azure_deployment\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Azure Deployment\"\n      },\n      \"api_version\": {\n         \"title\": \"Api Version\",\n         \"type\": \"string\"\n      },\n      \"azure_ad_token\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Azure Ad Token\"\n      },\n      \"azure_ad_token_provider\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ComponentModel\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      }\n   },\n   \"$defs\": {\n      \"ComponentModel\": {\n         \"description\": \"Model class for a component. Contains all information required to instantiate a component.\",\n         \"properties\": {\n            \"provider\": {\n               \"title\": \"Provider\",\n               \"type\": \"string\"\n            },\n            \"component_type\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"model\",\n                        \"agent\",\n                        \"tool\",\n                        \"termination\",\n                        \"token_provider\",\n                        \"workbench\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Component Type\"\n            },\n            \"version\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Version\"\n            },\n            \"component_version\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"integer\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Component Version\"\n            },\n            \"description\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Description\"\n            },\n            \"label\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"default\": null,\n               \"title\": \"Label\"\n            },\n            \"config\": {\n               \"title\": \"Config\",\n               \"type\": \"object\"\n            }\n         },\n         \"required\": [\n            \"provider\",\n            \"config\"\n         ],\n         \"title\": \"ComponentModel\",\n         \"type\": \"object\"\n      },\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\",\n      \"azure_endpoint\",\n      \"api_version\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"OpenAIClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"add_name_prefixes\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Add Name Prefixes\"\n      },\n      \"include_name_in_message\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Include Name In Message\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"organization\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Organization\"\n      },\n      \"base_url\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Base Url\"\n      }\n   },\n   \"$defs\": {\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"OpenAIClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"add_name_prefixes\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Add Name Prefixes\"\n      },\n      \"include_name_in_message\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Include Name In Message\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      },\n      \"organization\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Organization\"\n      },\n      \"base_url\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Base Url\"\n      }\n   },\n   \"$defs\": {\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"BaseOpenAIClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"add_name_prefixes\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Add Name Prefixes\"\n      },\n      \"include_name_in_message\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Include Name In Message\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      }\n   },\n   \"$defs\": {\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"BaseOpenAIClientConfigurationConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"type\": \"string\"\n      },\n      \"api_key\": {\n         \"anyOf\": [\n            {\n               \"format\": \"password\",\n               \"type\": \"string\",\n               \"writeOnly\": true\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Api Key\"\n      },\n      \"timeout\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Timeout\"\n      },\n      \"max_retries\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Retries\"\n      },\n      \"model_capabilities\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelCapabilities\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"model_info\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ModelInfo\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"add_name_prefixes\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Add Name Prefixes\"\n      },\n      \"include_name_in_message\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Include Name In Message\"\n      },\n      \"default_headers\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Default Headers\"\n      }\n   },\n   \"$defs\": {\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ModelCapabilities\": {\n         \"deprecated\": true,\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\"\n         ],\n         \"title\": \"ModelCapabilities\",\n         \"type\": \"object\"\n      },\n      \"ModelInfo\": {\n         \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\",\n         \"properties\": {\n            \"vision\": {\n               \"title\": \"Vision\",\n               \"type\": \"boolean\"\n            },\n            \"function_calling\": {\n               \"title\": \"Function Calling\",\n               \"type\": \"boolean\"\n            },\n            \"json_output\": {\n               \"title\": \"Json Output\",\n               \"type\": \"boolean\"\n            },\n            \"family\": {\n               \"anyOf\": [\n                  {\n                     \"enum\": [\n                        \"gpt-5\",\n                        \"gpt-41\",\n                        \"gpt-45\",\n                        \"gpt-4o\",\n                        \"o1\",\n                        \"o3\",\n                        \"o4\",\n                        \"gpt-4\",\n                        \"gpt-35\",\n                        \"r1\",\n                        \"gemini-1.5-flash\",\n                        \"gemini-1.5-pro\",\n                        \"gemini-2.0-flash\",\n                        \"gemini-2.5-pro\",\n                        \"gemini-2.5-flash\",\n                        \"claude-3-haiku\",\n                        \"claude-3-sonnet\",\n                        \"claude-3-opus\",\n                        \"claude-3-5-haiku\",\n                        \"claude-3-5-sonnet\",\n                        \"claude-3-7-sonnet\",\n                        \"claude-4-opus\",\n                        \"claude-4-sonnet\",\n                        \"llama-3.3-8b\",\n                        \"llama-3.3-70b\",\n                        \"llama-4-scout\",\n                        \"llama-4-maverick\",\n                        \"codestral\",\n                        \"open-codestral-mamba\",\n                        \"mistral\",\n                        \"ministral\",\n                        \"pixtral\",\n                        \"unknown\"\n                     ],\n                     \"type\": \"string\"\n                  },\n                  {\n                     \"type\": \"string\"\n                  }\n               ],\n               \"title\": \"Family\"\n            },\n            \"structured_output\": {\n               \"title\": \"Structured Output\",\n               \"type\": \"boolean\"\n            },\n            \"multiple_system_messages\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Multiple System Messages\"\n            }\n         },\n         \"required\": [\n            \"vision\",\n            \"function_calling\",\n            \"json_output\",\n            \"family\",\n            \"structured_output\"\n         ],\n         \"title\": \"ModelInfo\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": [\n      \"model\"\n   ]\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"CreateArgumentsConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      }\n   },\n   \"$defs\": {\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   }\n}",
      "language": "json"
    },
    {
      "code": "{\n   \"title\": \"CreateArgumentsConfigModel\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"frequency_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Frequency Penalty\"\n      },\n      \"logit_bias\": {\n         \"anyOf\": [\n            {\n               \"additionalProperties\": {\n                  \"type\": \"integer\"\n               },\n               \"type\": \"object\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Logit Bias\"\n      },\n      \"max_tokens\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Max Tokens\"\n      },\n      \"n\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"N\"\n      },\n      \"presence_penalty\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Presence Penalty\"\n      },\n      \"response_format\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/ResponseFormat\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"seed\": {\n         \"anyOf\": [\n            {\n               \"type\": \"integer\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Seed\"\n      },\n      \"stop\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"items\": {\n                  \"type\": \"string\"\n               },\n               \"type\": \"array\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Stop\"\n      },\n      \"temperature\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Temperature\"\n      },\n      \"top_p\": {\n         \"anyOf\": [\n            {\n               \"type\": \"number\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Top P\"\n      },\n      \"user\": {\n         \"anyOf\": [\n            {\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"User\"\n      },\n      \"stream_options\": {\n         \"anyOf\": [\n            {\n               \"$ref\": \"#/$defs/StreamOptions\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null\n      },\n      \"parallel_tool_calls\": {\n         \"anyOf\": [\n            {\n               \"type\": \"boolean\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Parallel Tool Calls\"\n      },\n      \"reasoning_effort\": {\n         \"anyOf\": [\n            {\n               \"enum\": [\n                  \"minimal\",\n                  \"low\",\n                  \"medium\",\n                  \"high\"\n               ],\n               \"type\": \"string\"\n            },\n            {\n               \"type\": \"null\"\n            }\n         ],\n         \"default\": null,\n         \"title\": \"Reasoning Effort\"\n      }\n   },\n   \"$defs\": {\n      \"JSONSchema\": {\n         \"properties\": {\n            \"name\": {\n               \"title\": \"Name\",\n               \"type\": \"string\"\n            },\n            \"description\": {\n               \"title\": \"Description\",\n               \"type\": \"string\"\n            },\n            \"schema\": {\n               \"title\": \"Schema\",\n               \"type\": \"object\"\n            },\n            \"strict\": {\n               \"anyOf\": [\n                  {\n                     \"type\": \"boolean\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ],\n               \"title\": \"Strict\"\n            }\n         },\n         \"required\": [\n            \"name\"\n         ],\n         \"title\": \"JSONSchema\",\n         \"type\": \"object\"\n      },\n      \"ResponseFormat\": {\n         \"properties\": {\n            \"type\": {\n               \"enum\": [\n                  \"text\",\n                  \"json_object\",\n                  \"json_schema\"\n               ],\n               \"title\": \"Type\",\n               \"type\": \"string\"\n            },\n            \"json_schema\": {\n               \"anyOf\": [\n                  {\n                     \"$ref\": \"#/$defs/JSONSchema\"\n                  },\n                  {\n                     \"type\": \"null\"\n                  }\n               ]\n            }\n         },\n         \"required\": [\n            \"type\",\n            \"json_schema\"\n         ],\n         \"title\": \"ResponseFormat\",\n         \"type\": \"object\"\n      },\n      \"StreamOptions\": {\n         \"properties\": {\n            \"include_usage\": {\n               \"title\": \"Include Usage\",\n               \"type\": \"boolean\"\n            }\n         },\n         \"required\": [\n            \"include_usage\"\n         ],\n         \"title\": \"StreamOptions\",\n         \"type\": \"object\"\n      }\n   }\n}",
      "language": "json"
    }
  ],
  "patterns": [
    {
      "description": "API Reference autogen_ext.models.openai autogen_ext.models.openai# class OpenAIChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseOpenAIChatCompletionClient, Component[OpenAIClientConfigurationConfigModel] Chat completion client for OpenAI hosted models. To use this client, you must install the openai extra: pip install \"autogen-ext[openai]\" You can also use this client for OpenAI-compatible ChatCompletion endpoints. Using this client for non-OpenAI models is not tested or guaranteed. For non-OpenAI models, please first take a look at our community extensions for additional model clients. Parameters: model (str) – Which OpenAI model to use. api_key (optional, str) – The API key to use. Required if ‘OPENAI_API_KEY’ is not found in the environment variables. organization (optional, str) – The organization ID to use. base_url (optional, str) – The base URL to use. Required if the model is not hosted on OpenAI. timeout – (optional, float): The timeout for the request in seconds. max_retries (optional, int) – The maximum number of retries to attempt. model_info (optional, ModelInfo) – The capabilities of the model. Required if the model name is not a valid OpenAI model. frequency_penalty (optional, float) logit_bias – (optional, dict[str, int]): max_tokens (optional, int) n (optional, int) presence_penalty (optional, float) response_format (optional, Dict[str, Any]) – the format of the response. Possible options are: # Text response, this is the default. {\"type\": \"text\"} # JSON response, make sure to instruct the model to return JSON. {\"type\": \"json_object\"} # Structured output response, with a pre-defined JSON schema. { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"name of the schema, must be an identifier.\", \"description\": \"description for the model.\", # You can convert a Pydantic (v2) model to JSON schema # using the `model_json_schema()` method. \"schema\": \"<the JSON schema itself>\", # Whether to enable strict schema adherence when # generating the output. If set to true, the model will # always follow the exact schema defined in the # `schema` field. Only a subset of JSON Schema is # supported when `strict` is `true`. # To learn more, read # https://platform.openai.com/docs/guides/structured-outputs. \"strict\": False, # or True }, } It is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly. seed (optional, int) stop (optional, str | List[str]) temperature (optional, float) top_p (optional, float) parallel_tool_calls (optional, bool) – Whether to allow parallel tool calls. When not set, defaults to server behavior. user (optional, str) default_headers (optional, dict[str, str]) – Custom headers; useful for authentication or other custom requirements. add_name_prefixes (optional, bool) – Whether to prepend the source value to each UserMessage content. E.g., “this is content” becomes “Reviewer said: this is content.” This can be useful for models that do not support the name field in message. Defaults to False. include_name_in_message (optional, bool) – Whether to include the name field in user message parameters sent to the OpenAI API. Defaults to True. Set to False for model providers that don’t support the name field (e.g., Groq). stream_options (optional, dict) – Additional options for streaming. Currently only include_usage is supported. Examples The following code snippet shows how to use the client with an OpenAI model: from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_core.models import UserMessage openai_client = OpenAIChatCompletionClient( model=\"gpt-4o-2024-08-06\", # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY environment variable set. ) result = await openai_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")]) # type: ignore print(result) # Close the client when done. # await openai_client.close() To use the client with a non-OpenAI model, you need to provide the base URL of the model and the model info. For example, to use Ollama, you can use the following code snippet: from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_core.models import ModelFamily custom_model_client = OpenAIChatCompletionClient( model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434/v1\", api_key=\"placeholder\", model_info={ \"vision\": False, \"function_calling\": False, \"json_output\": False, \"family\": ModelFamily.R1, \"structured_output\": True, }, ) # Close the client when done. # await custom_model_client.close() To use streaming mode, you can use the following code snippet: import asyncio from autogen_core.models import UserMessage from autogen_ext.models.openai import OpenAIChatCompletionClient async def main() -> None: # Similar for AzureOpenAIChatCompletionClient. model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") # assuming OPENAI_API_KEY is set in the environment. messages = [UserMessage(content=\"Write a very short story about a dragon.\", source=\"user\")] # Create a stream. stream = model_client.create_stream(messages=messages) # Iterate over the stream and print the responses. print(\"Streamed responses:\") async for response in stream: if isinstance(response, str): # A partial response is a string. print(response, flush=True, end=\"\") else: # The last response is a CreateResult object with the complete message. print(\"\\n\\n------------\\n\") print(\"The complete response:\", flush=True) print(response.content, flush=True) # Close the client when done. await model_client.close() asyncio.run(main()) To use structured output as well as function calling, you can use the following code snippet: import asyncio from typing import Literal from autogen_core.models import ( AssistantMessage, FunctionExecutionResult, FunctionExecutionResultMessage, SystemMessage, UserMessage, ) from autogen_core.tools import FunctionTool from autogen_ext.models.openai import OpenAIChatCompletionClient from pydantic import BaseModel # Define the structured output format. class AgentResponse(BaseModel): thoughts: str response: Literal[\"happy\", \"sad\", \"neutral\"] # Define the function to be called as a tool. def sentiment_analysis(text: str) -> str: \"\"\"Given a text, return the sentiment.\"\"\" return \"happy\" if \"happy\" in text else \"sad\" if \"sad\" in text else \"neutral\" # Create a FunctionTool instance with `strict=True`, # which is required for structured output mode. tool = FunctionTool(sentiment_analysis, description=\"Sentiment Analysis\", strict=True) async def main() -> None: # Create an OpenAIChatCompletionClient instance. model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\") # Generate a response using the tool. response1 = await model_client.create( messages=[ SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"), UserMessage(content=\"I am happy.\", source=\"user\"), ], tools=[tool], ) print(response1.content) # Should be a list of tool calls. # [FunctionCall(name=\"sentiment_analysis\", arguments={\"text\": \"I am happy.\"}, ...)] assert isinstance(response1.content, list) response2 = await model_client.create( messages=[ SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"), UserMessage(content=\"I am happy.\", source=\"user\"), AssistantMessage(content=response1.content, source=\"assistant\"), FunctionExecutionResultMessage( content=[FunctionExecutionResult(content=\"happy\", call_id=response1.content[0].id, is_error=False, name=\"sentiment_analysis\")] ), ], # Use the structured output format. json_output=AgentResponse, ) print(response2.content) # Should be a structured output. # {\"thoughts\": \"The user is happy.\", \"response\": \"happy\"} # Close the client when done. await model_client.close() asyncio.run(main()) To load the client from a configuration, you can use the load_component method: from autogen_core.models import ChatCompletionClient config = { \"provider\": \"OpenAIChatCompletionClient\", \"config\": {\"model\": \"gpt-4o\", \"api_key\": \"REPLACE_WITH_YOUR_API_KEY\"}, } client = ChatCompletionClient.load_component(config) To view the full list of available configuration options, see the OpenAIClientConfigurationConfigModel class. component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of OpenAIClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.openai.OpenAIChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → OpenAIClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: OpenAIClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class AzureOpenAIChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseOpenAIChatCompletionClient, Component[AzureOpenAIClientConfigurationConfigModel] Chat completion client for Azure OpenAI hosted models. To use this client, you must install the azure and openai extensions: pip install \"autogen-ext[openai,azure]\" Parameters: model (str) – Which OpenAI model to use. azure_endpoint (str) – The endpoint for the Azure model. Required for Azure models. azure_deployment (str) – Deployment name for the Azure model. Required for Azure models. api_version (str) – The API version to use. Required for Azure models. azure_ad_token (str) – The Azure AD token to use. Provide this or azure_ad_token_provider for token-based authentication. azure_ad_token_provider (optional, Callable[[], Awaitable[str]] | AzureTokenProvider) – The Azure AD token provider to use. Provide this or azure_ad_token for token-based authentication. api_key (optional, str) – The API key to use, use this if you are using key based authentication. It is optional if you are using Azure AD token based authentication or AZURE_OPENAI_API_KEY environment variable. timeout – (optional, float): The timeout for the request in seconds. max_retries (optional, int) – The maximum number of retries to attempt. model_info (optional, ModelInfo) – The capabilities of the model. Required if the model name is not a valid OpenAI model. frequency_penalty (optional, float) logit_bias – (optional, dict[str, int]): max_tokens (optional, int) n (optional, int) presence_penalty (optional, float) response_format (optional, Dict[str, Any]) – the format of the response. Possible options are: # Text response, this is the default. {\"type\": \"text\"} # JSON response, make sure to instruct the model to return JSON. {\"type\": \"json_object\"} # Structured output response, with a pre-defined JSON schema. { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"name of the schema, must be an identifier.\", \"description\": \"description for the model.\", # You can convert a Pydantic (v2) model to JSON schema # using the `model_json_schema()` method. \"schema\": \"<the JSON schema itself>\", # Whether to enable strict schema adherence when # generating the output. If set to true, the model will # always follow the exact schema defined in the # `schema` field. Only a subset of JSON Schema is # supported when `strict` is `true`. # To learn more, read # https://platform.openai.com/docs/guides/structured-outputs. \"strict\": False, # or True }, } It is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly. seed (optional, int) stop (optional, str | List[str]) temperature (optional, float) top_p (optional, float) parallel_tool_calls (optional, bool) – Whether to allow parallel tool calls. When not set, defaults to server behavior. user (optional, str) default_headers (optional, dict[str, str]) – Custom headers; useful for authentication or other custom requirements. add_name_prefixes (optional, bool) – Whether to prepend the source value to each UserMessage content. E.g., “this is content” becomes “Reviewer said: this is content.” This can be useful for models that do not support the name field in message. Defaults to False. include_name_in_message (optional, bool) – Whether to include the name field in user message parameters sent to the OpenAI API. Defaults to True. Set to False for model providers that don’t support the name field (e.g., Groq). stream_options (optional, dict) – Additional options for streaming. Currently only include_usage is supported. To use the client, you need to provide your deployment name, Azure Cognitive Services endpoint, and api version. For authentication, you can either provide an API key or an Azure Active Directory (AAD) token credential. The following code snippet shows how to use AAD authentication. The identity used must be assigned the Cognitive Services OpenAI User role. from autogen_ext.auth.azure import AzureTokenProvider from autogen_ext.models.openai import AzureOpenAIChatCompletionClient from azure.identity import DefaultAzureCredential # Create the token provider token_provider = AzureTokenProvider( DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\", ) az_model_client = AzureOpenAIChatCompletionClient( azure_deployment=\"{your-azure-deployment}\", model=\"{model-name, such as gpt-4o}\", api_version=\"2024-06-01\", azure_endpoint=\"https://{your-custom-endpoint}.openai.azure.com/\", azure_ad_token_provider=token_provider, # Optional if you choose key-based authentication. # api_key=\"sk-...\", # For key-based authentication. ) See other usage examples in the OpenAIChatCompletionClient class. To load the client that uses identity based aith from a configuration, you can use the load_component method: from autogen_core.models import ChatCompletionClient config = { \"provider\": \"AzureOpenAIChatCompletionClient\", \"config\": { \"model\": \"gpt-4o-2024-05-13\", \"azure_endpoint\": \"https://{your-custom-endpoint}.openai.azure.com/\", \"azure_deployment\": \"{your-azure-deployment}\", \"api_version\": \"2024-06-01\", \"azure_ad_token_provider\": { \"provider\": \"autogen_ext.auth.azure.AzureTokenProvider\", \"config\": { \"provider_kind\": \"DefaultAzureCredential\", \"scopes\": [\"https://cognitiveservices.azure.com/.default\"], }, }, }, } client = ChatCompletionClient.load_component(config) To view the full list of available configuration options, see the AzureOpenAIClientConfigurationConfigModel class. Note Right now only DefaultAzureCredential is supported with no additional args passed to it. Note The Azure OpenAI client by default sets the User-Agent header to autogen-python/{version}. To override this, you can set the variable autogen_ext.models.openai.AZURE_OPENAI_USER_AGENT environment variable to an empty string. See here for how to use the Azure client directly or for more info. component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of AzureOpenAIClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.openai.AzureOpenAIChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → AzureOpenAIClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: AzureOpenAIClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class BaseOpenAIChatCompletionClient(client: AsyncOpenAI | AsyncAzureOpenAI, *, create_args: Dict[str, Any], model_capabilities: ModelCapabilities | None = None, model_info: ModelInfo | None = None, add_name_prefixes: bool = False, include_name_in_message: bool = True)[source]# Bases: ChatCompletionClient classmethod create_from_config(config: Dict[str, Any]) → ChatCompletionClient[source]# async create(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → CreateResult[source]# Creates a single response from the model. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: CreateResult – The result of the model call. async create_stream(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None, max_consecutive_empty_chunk_tolerance: int = 0, include_usage: bool | None = None) → AsyncGenerator[str | CreateResult, None][source]# Create a stream of string chunks from the model ending with a CreateResult. Extends autogen_core.models.ChatCompletionClient.create_stream() to support OpenAI API. In streaming, the default behaviour is not return token usage counts. See: OpenAI API reference for possible args. You can set set the include_usage flag to True or extra_create_args={“stream_options”: {“include_usage”: True}}. If both the flag and stream_options are set, but to different values, an exception will be raised. (if supported by the accessed API) to return a final chunk with usage set to a RequestUsage object with prompt and completion token counts, all preceding chunks will have usage as None. See: OpenAI API reference for stream options. Other examples of supported arguments that can be included in extra_create_args: temperature (float): Controls the randomness of the output. Higher values (e.g., 0.8) make the output more random, while lower values (e.g., 0.2) make it more focused and deterministic. max_tokens (int): The maximum number of tokens to generate in the completion. top_p (float): An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. frequency_penalty (float): A value between -2.0 and 2.0 that penalizes new tokens based on their existing frequency in the text so far, decreasing the likelihood of repeated phrases. presence_penalty (float): A value between -2.0 and 2.0 that penalizes new tokens based on whether they appear in the text so far, encouraging the model to talk about new topics. async close() → None[source]# actual_usage() → RequestUsage[source]# total_usage() → RequestUsage[source]# count_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# remaining_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# property capabilities: ModelCapabilities# property model_info: ModelInfo# pydantic model AzureOpenAIClientConfigurationConfigModel[source]# Bases: BaseOpenAIClientConfigurationConfigModel Show JSON schema{ \"title\": \"AzureOpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"azure_endpoint\": { \"title\": \"Azure Endpoint\", \"type\": \"string\" }, \"azure_deployment\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Azure Deployment\" }, \"api_version\": { \"title\": \"Api Version\", \"type\": \"string\" }, \"azure_ad_token\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Azure Ad Token\" }, \"azure_ad_token_provider\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ComponentModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"ComponentModel\": { \"description\": \"Model class for a component. Contains all information required to instantiate a component.\", \"properties\": { \"provider\": { \"title\": \"Provider\", \"type\": \"string\" }, \"component_type\": { \"anyOf\": [ { \"enum\": [ \"model\", \"agent\", \"tool\", \"termination\", \"token_provider\", \"workbench\" ], \"type\": \"string\" }, { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Component Type\" }, \"version\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Version\" }, \"component_version\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Component Version\" }, \"description\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Description\" }, \"label\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Label\" }, \"config\": { \"title\": \"Config\", \"type\": \"object\" } }, \"required\": [ \"provider\", \"config\" ], \"title\": \"ComponentModel\", \"type\": \"object\" }, \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\", \"azure_endpoint\", \"api_version\" ] } Fields: api_version (str) azure_ad_token (str | None) azure_ad_token_provider (autogen_core._component_config.ComponentModel | None) azure_deployment (str | None) azure_endpoint (str) field azure_endpoint: str [Required]# field azure_deployment: str | None = None# field api_version: str [Required]# field azure_ad_token: str | None = None# field azure_ad_token_provider: ComponentModel | None = None# pydantic model OpenAIClientConfigurationConfigModel[source]# Bases: BaseOpenAIClientConfigurationConfigModel Show JSON schema{ \"title\": \"OpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"organization\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Organization\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: base_url (str | None) organization (str | None) field organization: str | None = None# field base_url: str | None = None# pydantic model BaseOpenAIClientConfigurationConfigModel[source]# Bases: CreateArgumentsConfigModel Show JSON schema{ \"title\": \"BaseOpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: add_name_prefixes (bool | None) api_key (pydantic.types.SecretStr | None) default_headers (Dict[str, str] | None) include_name_in_message (bool | None) max_retries (int | None) model (str) model_capabilities (autogen_core.models._model_client.ModelCapabilities | None) model_info (autogen_core.models._model_client.ModelInfo | None) timeout (float | None) field model: str [Required]# field api_key: SecretStr | None = None# field timeout: float | None = None# field max_retries: int | None = None# field model_capabilities: ModelCapabilities | None = None# field model_info: ModelInfo | None = None# field add_name_prefixes: bool | None = None# field include_name_in_message: bool | None = None# field default_headers: Dict[str, str] | None = None# pydantic model CreateArgumentsConfigModel[source]# Bases: BaseModel Show JSON schema{ \"title\": \"CreateArgumentsConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } } } Fields: frequency_penalty (float | None) logit_bias (Dict[str, int] | None) max_tokens (int | None) n (int | None) parallel_tool_calls (bool | None) presence_penalty (float | None) reasoning_effort (Literal['minimal', 'low', 'medium', 'high'] | None) response_format (autogen_ext.models.openai.config.ResponseFormat | None) seed (int | None) stop (str | List[str] | None) stream_options (autogen_ext.models.openai.config.StreamOptions | None) temperature (float | None) top_p (float | None) user (str | None) field frequency_penalty: float | None = None# field logit_bias: Dict[str, int] | None = None# field max_tokens: int | None = None# field n: int | None = None# field presence_penalty: float | None = None# field response_format: ResponseFormat | None = None# field seed: int | None = None# field stop: str | List[str] | None = None# field temperature: float | None = None# field top_p: float | None = None# field user: str | None = None# field stream_options: StreamOptions | None = None# field parallel_tool_calls: bool | None = None# field reasoning_effort: Literal['minimal', 'low', 'medium', 'high'] | None = None# previous autogen_ext.models.ollama next autogen_ext.models.replay On this page OpenAIChatCompletionClient OpenAIChatCompletionClient.component_type OpenAIChatCompletionClient.component_config_schema OpenAIChatCompletionClient.component_provider_override OpenAIChatCompletionClient._to_config() OpenAIChatCompletionClient._from_config() AzureOpenAIChatCompletionClient AzureOpenAIChatCompletionClient.component_type AzureOpenAIChatCompletionClient.component_config_schema AzureOpenAIChatCompletionClient.component_provider_override AzureOpenAIChatCompletionClient._to_config() AzureOpenAIChatCompletionClient._from_config() BaseOpenAIChatCompletionClient BaseOpenAIChatCompletionClient.create_from_config() BaseOpenAIChatCompletionClient.create() BaseOpenAIChatCompletionClient.create_stream() BaseOpenAIChatCompletionClient.close() BaseOpenAIChatCompletionClient.actual_usage() BaseOpenAIChatCompletionClient.total_usage() BaseOpenAIChatCompletionClient.count_tokens() BaseOpenAIChatCompletionClient.remaining_tokens() BaseOpenAIChatCompletionClient.capabilities BaseOpenAIChatCompletionClient.model_info AzureOpenAIClientConfigurationConfigModel AzureOpenAIClientConfigurationConfigModel.azure_endpoint AzureOpenAIClientConfigurationConfigModel.azure_deployment AzureOpenAIClientConfigurationConfigModel.api_version AzureOpenAIClientConfigurationConfigModel.azure_ad_token AzureOpenAIClientConfigurationConfigModel.azure_ad_token_provider OpenAIClientConfigurationConfigModel OpenAIClientConfigurationConfigModel.organization OpenAIClientConfigurationConfigModel.base_url BaseOpenAIClientConfigurationConfigModel BaseOpenAIClientConfigurationConfigModel.model BaseOpenAIClientConfigurationConfigModel.api_key BaseOpenAIClientConfigurationConfigModel.timeout BaseOpenAIClientConfigurationConfigModel.max_retries BaseOpenAIClientConfigurationConfigModel.model_capabilities BaseOpenAIClientConfigurationConfigModel.model_info BaseOpenAIClientConfigurationConfigModel.add_name_prefixes BaseOpenAIClientConfigurationConfigModel.include_name_in_message BaseOpenAIClientConfigurationConfigModel.default_headers CreateArgumentsConfigModel CreateArgumentsConfigModel.frequency_penalty CreateArgumentsConfigModel.logit_bias CreateArgumentsConfigModel.max_tokens CreateArgumentsConfigModel.n CreateArgumentsConfigModel.presence_penalty CreateArgumentsConfigModel.response_format CreateArgumentsConfigModel.seed CreateArgumentsConfigModel.stop CreateArgumentsConfigModel.temperature CreateArgumentsConfigModel.top_p CreateArgumentsConfigModel.user CreateArgumentsConfigModel.stream_options CreateArgumentsConfigModel.parallel_tool_calls CreateArgumentsConfigModel.reasoning_effort Edit on GitHub Show Source",
      "code": "BaseOpenAIChatCompletionClient"
    },
    {
      "description": "API Reference autogen_ext.models.openai autogen_ext.models.openai# class OpenAIChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseOpenAIChatCompletionClient, Component[OpenAIClientConfigurationConfigModel] Chat completion client for OpenAI hosted models. To use this client, you must install the openai extra: pip install \"autogen-ext[openai]\" You can also use this client for OpenAI-compatible ChatCompletion endpoints. Using this client for non-OpenAI models is not tested or guaranteed. For non-OpenAI models, please first take a look at our community extensions for additional model clients. Parameters: model (str) – Which OpenAI model to use. api_key (optional, str) – The API key to use. Required if ‘OPENAI_API_KEY’ is not found in the environment variables. organization (optional, str) – The organization ID to use. base_url (optional, str) – The base URL to use. Required if the model is not hosted on OpenAI. timeout – (optional, float): The timeout for the request in seconds. max_retries (optional, int) – The maximum number of retries to attempt. model_info (optional, ModelInfo) – The capabilities of the model. Required if the model name is not a valid OpenAI model. frequency_penalty (optional, float) logit_bias – (optional, dict[str, int]): max_tokens (optional, int) n (optional, int) presence_penalty (optional, float) response_format (optional, Dict[str, Any]) – the format of the response. Possible options are: # Text response, this is the default. {\"type\": \"text\"} # JSON response, make sure to instruct the model to return JSON. {\"type\": \"json_object\"} # Structured output response, with a pre-defined JSON schema. { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"name of the schema, must be an identifier.\", \"description\": \"description for the model.\", # You can convert a Pydantic (v2) model to JSON schema # using the `model_json_schema()` method. \"schema\": \"<the JSON schema itself>\", # Whether to enable strict schema adherence when # generating the output. If set to true, the model will # always follow the exact schema defined in the # `schema` field. Only a subset of JSON Schema is # supported when `strict` is `true`. # To learn more, read # https://platform.openai.com/docs/guides/structured-outputs. \"strict\": False, # or True }, } It is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly. seed (optional, int) stop (optional, str | List[str]) temperature (optional, float) top_p (optional, float) parallel_tool_calls (optional, bool) – Whether to allow parallel tool calls. When not set, defaults to server behavior. user (optional, str) default_headers (optional, dict[str, str]) – Custom headers; useful for authentication or other custom requirements. add_name_prefixes (optional, bool) – Whether to prepend the source value to each UserMessage content. E.g., “this is content” becomes “Reviewer said: this is content.” This can be useful for models that do not support the name field in message. Defaults to False. include_name_in_message (optional, bool) – Whether to include the name field in user message parameters sent to the OpenAI API. Defaults to True. Set to False for model providers that don’t support the name field (e.g., Groq). stream_options (optional, dict) – Additional options for streaming. Currently only include_usage is supported. Examples The following code snippet shows how to use the client with an OpenAI model: from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_core.models import UserMessage openai_client = OpenAIChatCompletionClient( model=\"gpt-4o-2024-08-06\", # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY environment variable set. ) result = await openai_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")]) # type: ignore print(result) # Close the client when done. # await openai_client.close() To use the client with a non-OpenAI model, you need to provide the base URL of the model and the model info. For example, to use Ollama, you can use the following code snippet: from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_core.models import ModelFamily custom_model_client = OpenAIChatCompletionClient( model=\"deepseek-r1:1.5b\", base_url=\"http://localhost:11434/v1\", api_key=\"placeholder\", model_info={ \"vision\": False, \"function_calling\": False, \"json_output\": False, \"family\": ModelFamily.R1, \"structured_output\": True, }, ) # Close the client when done. # await custom_model_client.close() To use streaming mode, you can use the following code snippet: import asyncio from autogen_core.models import UserMessage from autogen_ext.models.openai import OpenAIChatCompletionClient async def main() -> None: # Similar for AzureOpenAIChatCompletionClient. model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") # assuming OPENAI_API_KEY is set in the environment. messages = [UserMessage(content=\"Write a very short story about a dragon.\", source=\"user\")] # Create a stream. stream = model_client.create_stream(messages=messages) # Iterate over the stream and print the responses. print(\"Streamed responses:\") async for response in stream: if isinstance(response, str): # A partial response is a string. print(response, flush=True, end=\"\") else: # The last response is a CreateResult object with the complete message. print(\"\\n\\n------------\\n\") print(\"The complete response:\", flush=True) print(response.content, flush=True) # Close the client when done. await model_client.close() asyncio.run(main()) To use structured output as well as function calling, you can use the following code snippet: import asyncio from typing import Literal from autogen_core.models import ( AssistantMessage, FunctionExecutionResult, FunctionExecutionResultMessage, SystemMessage, UserMessage, ) from autogen_core.tools import FunctionTool from autogen_ext.models.openai import OpenAIChatCompletionClient from pydantic import BaseModel # Define the structured output format. class AgentResponse(BaseModel): thoughts: str response: Literal[\"happy\", \"sad\", \"neutral\"] # Define the function to be called as a tool. def sentiment_analysis(text: str) -> str: \"\"\"Given a text, return the sentiment.\"\"\" return \"happy\" if \"happy\" in text else \"sad\" if \"sad\" in text else \"neutral\" # Create a FunctionTool instance with `strict=True`, # which is required for structured output mode. tool = FunctionTool(sentiment_analysis, description=\"Sentiment Analysis\", strict=True) async def main() -> None: # Create an OpenAIChatCompletionClient instance. model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\") # Generate a response using the tool. response1 = await model_client.create( messages=[ SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"), UserMessage(content=\"I am happy.\", source=\"user\"), ], tools=[tool], ) print(response1.content) # Should be a list of tool calls. # [FunctionCall(name=\"sentiment_analysis\", arguments={\"text\": \"I am happy.\"}, ...)] assert isinstance(response1.content, list) response2 = await model_client.create( messages=[ SystemMessage(content=\"Analyze input text sentiment using the tool provided.\"), UserMessage(content=\"I am happy.\", source=\"user\"), AssistantMessage(content=response1.content, source=\"assistant\"), FunctionExecutionResultMessage( content=[FunctionExecutionResult(content=\"happy\", call_id=response1.content[0].id, is_error=False, name=\"sentiment_analysis\")] ), ], # Use the structured output format. json_output=AgentResponse, ) print(response2.content) # Should be a structured output. # {\"thoughts\": \"The user is happy.\", \"response\": \"happy\"} # Close the client when done. await model_client.close() asyncio.run(main()) To load the client from a configuration, you can use the load_component method: from autogen_core.models import ChatCompletionClient config = { \"provider\": \"OpenAIChatCompletionClient\", \"config\": {\"model\": \"gpt-4o\", \"api_key\": \"REPLACE_WITH_YOUR_API_KEY\"}, } client = ChatCompletionClient.load_component(config) To view the full list of available configuration options, see the OpenAIClientConfigurationConfigModel class. component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of OpenAIClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.openai.OpenAIChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → OpenAIClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: OpenAIClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class AzureOpenAIChatCompletionClient(**kwargs: Unpack)[source]# Bases: BaseOpenAIChatCompletionClient, Component[AzureOpenAIClientConfigurationConfigModel] Chat completion client for Azure OpenAI hosted models. To use this client, you must install the azure and openai extensions: pip install \"autogen-ext[openai,azure]\" Parameters: model (str) – Which OpenAI model to use. azure_endpoint (str) – The endpoint for the Azure model. Required for Azure models. azure_deployment (str) – Deployment name for the Azure model. Required for Azure models. api_version (str) – The API version to use. Required for Azure models. azure_ad_token (str) – The Azure AD token to use. Provide this or azure_ad_token_provider for token-based authentication. azure_ad_token_provider (optional, Callable[[], Awaitable[str]] | AzureTokenProvider) – The Azure AD token provider to use. Provide this or azure_ad_token for token-based authentication. api_key (optional, str) – The API key to use, use this if you are using key based authentication. It is optional if you are using Azure AD token based authentication or AZURE_OPENAI_API_KEY environment variable. timeout – (optional, float): The timeout for the request in seconds. max_retries (optional, int) – The maximum number of retries to attempt. model_info (optional, ModelInfo) – The capabilities of the model. Required if the model name is not a valid OpenAI model. frequency_penalty (optional, float) logit_bias – (optional, dict[str, int]): max_tokens (optional, int) n (optional, int) presence_penalty (optional, float) response_format (optional, Dict[str, Any]) – the format of the response. Possible options are: # Text response, this is the default. {\"type\": \"text\"} # JSON response, make sure to instruct the model to return JSON. {\"type\": \"json_object\"} # Structured output response, with a pre-defined JSON schema. { \"type\": \"json_schema\", \"json_schema\": { \"name\": \"name of the schema, must be an identifier.\", \"description\": \"description for the model.\", # You can convert a Pydantic (v2) model to JSON schema # using the `model_json_schema()` method. \"schema\": \"<the JSON schema itself>\", # Whether to enable strict schema adherence when # generating the output. If set to true, the model will # always follow the exact schema defined in the # `schema` field. Only a subset of JSON Schema is # supported when `strict` is `true`. # To learn more, read # https://platform.openai.com/docs/guides/structured-outputs. \"strict\": False, # or True }, } It is recommended to use the json_output parameter in create() or create_stream() methods instead of response_format for structured output. The json_output parameter is more flexible and allows you to specify a Pydantic model class directly. seed (optional, int) stop (optional, str | List[str]) temperature (optional, float) top_p (optional, float) parallel_tool_calls (optional, bool) – Whether to allow parallel tool calls. When not set, defaults to server behavior. user (optional, str) default_headers (optional, dict[str, str]) – Custom headers; useful for authentication or other custom requirements. add_name_prefixes (optional, bool) – Whether to prepend the source value to each UserMessage content. E.g., “this is content” becomes “Reviewer said: this is content.” This can be useful for models that do not support the name field in message. Defaults to False. include_name_in_message (optional, bool) – Whether to include the name field in user message parameters sent to the OpenAI API. Defaults to True. Set to False for model providers that don’t support the name field (e.g., Groq). stream_options (optional, dict) – Additional options for streaming. Currently only include_usage is supported. To use the client, you need to provide your deployment name, Azure Cognitive Services endpoint, and api version. For authentication, you can either provide an API key or an Azure Active Directory (AAD) token credential. The following code snippet shows how to use AAD authentication. The identity used must be assigned the Cognitive Services OpenAI User role. from autogen_ext.auth.azure import AzureTokenProvider from autogen_ext.models.openai import AzureOpenAIChatCompletionClient from azure.identity import DefaultAzureCredential # Create the token provider token_provider = AzureTokenProvider( DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\", ) az_model_client = AzureOpenAIChatCompletionClient( azure_deployment=\"{your-azure-deployment}\", model=\"{model-name, such as gpt-4o}\", api_version=\"2024-06-01\", azure_endpoint=\"https://{your-custom-endpoint}.openai.azure.com/\", azure_ad_token_provider=token_provider, # Optional if you choose key-based authentication. # api_key=\"sk-...\", # For key-based authentication. ) See other usage examples in the OpenAIChatCompletionClient class. To load the client that uses identity based aith from a configuration, you can use the load_component method: from autogen_core.models import ChatCompletionClient config = { \"provider\": \"AzureOpenAIChatCompletionClient\", \"config\": { \"model\": \"gpt-4o-2024-05-13\", \"azure_endpoint\": \"https://{your-custom-endpoint}.openai.azure.com/\", \"azure_deployment\": \"{your-azure-deployment}\", \"api_version\": \"2024-06-01\", \"azure_ad_token_provider\": { \"provider\": \"autogen_ext.auth.azure.AzureTokenProvider\", \"config\": { \"provider_kind\": \"DefaultAzureCredential\", \"scopes\": [\"https://cognitiveservices.azure.com/.default\"], }, }, }, } client = ChatCompletionClient.load_component(config) To view the full list of available configuration options, see the AzureOpenAIClientConfigurationConfigModel class. Note Right now only DefaultAzureCredential is supported with no additional args passed to it. Note The Azure OpenAI client by default sets the User-Agent header to autogen-python/{version}. To override this, you can set the variable autogen_ext.models.openai.AZURE_OPENAI_USER_AGENT environment variable to an empty string. See here for how to use the Azure client directly or for more info. component_type: ClassVar[ComponentType] = 'model'# The logical type of the component. component_config_schema# alias of AzureOpenAIClientConfigurationConfigModel component_provider_override: ClassVar[str | None] = 'autogen_ext.models.openai.AzureOpenAIChatCompletionClient'# Override the provider string for the component. This should be used to prevent internal module names being a part of the module name. _to_config() → AzureOpenAIClientConfigurationConfigModel[source]# Dump the configuration that would be requite to create a new instance of a component matching the configuration of this instance. Returns: T – The configuration of the component. classmethod _from_config(config: AzureOpenAIClientConfigurationConfigModel) → Self[source]# Create a new instance of the component from a configuration object. Parameters: config (T) – The configuration object. Returns: Self – The new instance of the component. class BaseOpenAIChatCompletionClient(client: AsyncOpenAI | AsyncAzureOpenAI, *, create_args: Dict[str, Any], model_capabilities: ModelCapabilities | None = None, model_info: ModelInfo | None = None, add_name_prefixes: bool = False, include_name_in_message: bool = True)[source]# Bases: ChatCompletionClient classmethod create_from_config(config: Dict[str, Any]) → ChatCompletionClient[source]# async create(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None) → CreateResult[source]# Creates a single response from the model. Parameters: messages (Sequence[LLMMessage]) – The messages to send to the model. tools (Sequence[Tool | ToolSchema], optional) – The tools to use with the model. Defaults to []. tool_choice (Tool | Literal[\"auto\", \"required\", \"none\"], optional) – A single Tool object to force the model to use, “auto” to let the model choose any available tool, “required” to force tool usage, or “none” to disable tool usage. Defaults to “auto”. json_output (Optional[bool | type[BaseModel]], optional) – Whether to use JSON mode, structured output, or neither. Defaults to None. If set to a Pydantic BaseModel type, it will be used as the output type for structured output. If set to a boolean, it will be used to determine whether to use JSON mode or not. If set to True, make sure to instruct the model to produce JSON output in the instruction or prompt. extra_create_args (Mapping[str, Any], optional) – Extra arguments to pass to the underlying client. Defaults to {}. cancellation_token (Optional[CancellationToken], optional) – A token for cancellation. Defaults to None. Returns: CreateResult – The result of the model call. async create_stream(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = [], tool_choice: Tool | Literal['auto', 'required', 'none'] = 'auto', json_output: bool | type[BaseModel] | None = None, extra_create_args: Mapping[str, Any] = {}, cancellation_token: CancellationToken | None = None, max_consecutive_empty_chunk_tolerance: int = 0, include_usage: bool | None = None) → AsyncGenerator[str | CreateResult, None][source]# Create a stream of string chunks from the model ending with a CreateResult. Extends autogen_core.models.ChatCompletionClient.create_stream() to support OpenAI API. In streaming, the default behaviour is not return token usage counts. See: OpenAI API reference for possible args. You can set set the include_usage flag to True or extra_create_args={“stream_options”: {“include_usage”: True}}. If both the flag and stream_options are set, but to different values, an exception will be raised. (if supported by the accessed API) to return a final chunk with usage set to a RequestUsage object with prompt and completion token counts, all preceding chunks will have usage as None. See: OpenAI API reference for stream options. Other examples of supported arguments that can be included in extra_create_args: temperature (float): Controls the randomness of the output. Higher values (e.g., 0.8) make the output more random, while lower values (e.g., 0.2) make it more focused and deterministic. max_tokens (int): The maximum number of tokens to generate in the completion. top_p (float): An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. frequency_penalty (float): A value between -2.0 and 2.0 that penalizes new tokens based on their existing frequency in the text so far, decreasing the likelihood of repeated phrases. presence_penalty (float): A value between -2.0 and 2.0 that penalizes new tokens based on whether they appear in the text so far, encouraging the model to talk about new topics. async close() → None[source]# actual_usage() → RequestUsage[source]# total_usage() → RequestUsage[source]# count_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# remaining_tokens(messages: Sequence[Annotated[SystemMessage | UserMessage | AssistantMessage | FunctionExecutionResultMessage, FieldInfo(annotation=NoneType, required=True, discriminator='type')]], *, tools: Sequence[Tool | ToolSchema] = []) → int[source]# property capabilities: ModelCapabilities# property model_info: ModelInfo# pydantic model AzureOpenAIClientConfigurationConfigModel[source]# Bases: BaseOpenAIClientConfigurationConfigModel Show JSON schema{ \"title\": \"AzureOpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"azure_endpoint\": { \"title\": \"Azure Endpoint\", \"type\": \"string\" }, \"azure_deployment\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Azure Deployment\" }, \"api_version\": { \"title\": \"Api Version\", \"type\": \"string\" }, \"azure_ad_token\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Azure Ad Token\" }, \"azure_ad_token_provider\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ComponentModel\" }, { \"type\": \"null\" } ], \"default\": null } }, \"$defs\": { \"ComponentModel\": { \"description\": \"Model class for a component. Contains all information required to instantiate a component.\", \"properties\": { \"provider\": { \"title\": \"Provider\", \"type\": \"string\" }, \"component_type\": { \"anyOf\": [ { \"enum\": [ \"model\", \"agent\", \"tool\", \"termination\", \"token_provider\", \"workbench\" ], \"type\": \"string\" }, { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Component Type\" }, \"version\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Version\" }, \"component_version\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Component Version\" }, \"description\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Description\" }, \"label\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Label\" }, \"config\": { \"title\": \"Config\", \"type\": \"object\" } }, \"required\": [ \"provider\", \"config\" ], \"title\": \"ComponentModel\", \"type\": \"object\" }, \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\", \"azure_endpoint\", \"api_version\" ] } Fields: api_version (str) azure_ad_token (str | None) azure_ad_token_provider (autogen_core._component_config.ComponentModel | None) azure_deployment (str | None) azure_endpoint (str) field azure_endpoint: str [Required]# field azure_deployment: str | None = None# field api_version: str [Required]# field azure_ad_token: str | None = None# field azure_ad_token_provider: ComponentModel | None = None# pydantic model OpenAIClientConfigurationConfigModel[source]# Bases: BaseOpenAIClientConfigurationConfigModel Show JSON schema{ \"title\": \"OpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" }, \"organization\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Organization\" }, \"base_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Base Url\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: base_url (str | None) organization (str | None) field organization: str | None = None# field base_url: str | None = None# pydantic model BaseOpenAIClientConfigurationConfigModel[source]# Bases: CreateArgumentsConfigModel Show JSON schema{ \"title\": \"BaseOpenAIClientConfigurationConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" }, \"model\": { \"title\": \"Model\", \"type\": \"string\" }, \"api_key\": { \"anyOf\": [ { \"format\": \"password\", \"type\": \"string\", \"writeOnly\": true }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Api Key\" }, \"timeout\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Timeout\" }, \"max_retries\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Retries\" }, \"model_capabilities\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelCapabilities\" }, { \"type\": \"null\" } ], \"default\": null }, \"model_info\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ModelInfo\" }, { \"type\": \"null\" } ], \"default\": null }, \"add_name_prefixes\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Add Name Prefixes\" }, \"include_name_in_message\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Include Name In Message\" }, \"default_headers\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"string\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Default Headers\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ModelCapabilities\": { \"deprecated\": true, \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\" ], \"title\": \"ModelCapabilities\", \"type\": \"object\" }, \"ModelInfo\": { \"description\": \"ModelInfo is a dictionary that contains information about a model's properties.\\nIt is expected to be used in the model_info property of a model client.\\n\\nWe are expecting this to grow over time as we add more features.\", \"properties\": { \"vision\": { \"title\": \"Vision\", \"type\": \"boolean\" }, \"function_calling\": { \"title\": \"Function Calling\", \"type\": \"boolean\" }, \"json_output\": { \"title\": \"Json Output\", \"type\": \"boolean\" }, \"family\": { \"anyOf\": [ { \"enum\": [ \"gpt-5\", \"gpt-41\", \"gpt-45\", \"gpt-4o\", \"o1\", \"o3\", \"o4\", \"gpt-4\", \"gpt-35\", \"r1\", \"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash\", \"claude-3-haiku\", \"claude-3-sonnet\", \"claude-3-opus\", \"claude-3-5-haiku\", \"claude-3-5-sonnet\", \"claude-3-7-sonnet\", \"claude-4-opus\", \"claude-4-sonnet\", \"llama-3.3-8b\", \"llama-3.3-70b\", \"llama-4-scout\", \"llama-4-maverick\", \"codestral\", \"open-codestral-mamba\", \"mistral\", \"ministral\", \"pixtral\", \"unknown\" ], \"type\": \"string\" }, { \"type\": \"string\" } ], \"title\": \"Family\" }, \"structured_output\": { \"title\": \"Structured Output\", \"type\": \"boolean\" }, \"multiple_system_messages\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Multiple System Messages\" } }, \"required\": [ \"vision\", \"function_calling\", \"json_output\", \"family\", \"structured_output\" ], \"title\": \"ModelInfo\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } }, \"required\": [ \"model\" ] } Fields: add_name_prefixes (bool | None) api_key (pydantic.types.SecretStr | None) default_headers (Dict[str, str] | None) include_name_in_message (bool | None) max_retries (int | None) model (str) model_capabilities (autogen_core.models._model_client.ModelCapabilities | None) model_info (autogen_core.models._model_client.ModelInfo | None) timeout (float | None) field model: str [Required]# field api_key: SecretStr | None = None# field timeout: float | None = None# field max_retries: int | None = None# field model_capabilities: ModelCapabilities | None = None# field model_info: ModelInfo | None = None# field add_name_prefixes: bool | None = None# field include_name_in_message: bool | None = None# field default_headers: Dict[str, str] | None = None# pydantic model CreateArgumentsConfigModel[source]# Bases: BaseModel Show JSON schema{ \"title\": \"CreateArgumentsConfigModel\", \"type\": \"object\", \"properties\": { \"frequency_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Frequency Penalty\" }, \"logit_bias\": { \"anyOf\": [ { \"additionalProperties\": { \"type\": \"integer\" }, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Logit Bias\" }, \"max_tokens\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Max Tokens\" }, \"n\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"N\" }, \"presence_penalty\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Presence Penalty\" }, \"response_format\": { \"anyOf\": [ { \"$ref\": \"#/$defs/ResponseFormat\" }, { \"type\": \"null\" } ], \"default\": null }, \"seed\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Seed\" }, \"stop\": { \"anyOf\": [ { \"type\": \"string\" }, { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Stop\" }, \"temperature\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Temperature\" }, \"top_p\": { \"anyOf\": [ { \"type\": \"number\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Top P\" }, \"user\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"User\" }, \"stream_options\": { \"anyOf\": [ { \"$ref\": \"#/$defs/StreamOptions\" }, { \"type\": \"null\" } ], \"default\": null }, \"parallel_tool_calls\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Parallel Tool Calls\" }, \"reasoning_effort\": { \"anyOf\": [ { \"enum\": [ \"minimal\", \"low\", \"medium\", \"high\" ], \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"title\": \"Reasoning Effort\" } }, \"$defs\": { \"JSONSchema\": { \"properties\": { \"name\": { \"title\": \"Name\", \"type\": \"string\" }, \"description\": { \"title\": \"Description\", \"type\": \"string\" }, \"schema\": { \"title\": \"Schema\", \"type\": \"object\" }, \"strict\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"title\": \"Strict\" } }, \"required\": [ \"name\" ], \"title\": \"JSONSchema\", \"type\": \"object\" }, \"ResponseFormat\": { \"properties\": { \"type\": { \"enum\": [ \"text\", \"json_object\", \"json_schema\" ], \"title\": \"Type\", \"type\": \"string\" }, \"json_schema\": { \"anyOf\": [ { \"$ref\": \"#/$defs/JSONSchema\" }, { \"type\": \"null\" } ] } }, \"required\": [ \"type\", \"json_schema\" ], \"title\": \"ResponseFormat\", \"type\": \"object\" }, \"StreamOptions\": { \"properties\": { \"include_usage\": { \"title\": \"Include Usage\", \"type\": \"boolean\" } }, \"required\": [ \"include_usage\" ], \"title\": \"StreamOptions\", \"type\": \"object\" } } } Fields: frequency_penalty (float | None) logit_bias (Dict[str, int] | None) max_tokens (int | None) n (int | None) parallel_tool_calls (bool | None) presence_penalty (float | None) reasoning_effort (Literal['minimal', 'low', 'medium', 'high'] | None) response_format (autogen_ext.models.openai.config.ResponseFormat | None) seed (int | None) stop (str | List[str] | None) stream_options (autogen_ext.models.openai.config.StreamOptions | None) temperature (float | None) top_p (float | None) user (str | None) field frequency_penalty: float | None = None# field logit_bias: Dict[str, int] | None = None# field max_tokens: int | None = None# field n: int | None = None# field presence_penalty: float | None = None# field response_format: ResponseFormat | None = None# field seed: int | None = None# field stop: str | List[str] | None = None# field temperature: float | None = None# field top_p: float | None = None# field user: str | None = None# field stream_options: StreamOptions | None = None# field parallel_tool_calls: bool | None = None# field reasoning_effort: Literal['minimal', 'low', 'medium', 'high'] | None = None# previous autogen_ext.models.ollama next autogen_ext.models.replay",
      "code": "BaseOpenAIChatCompletionClient"
    }
  ],
  "links": [
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.html",
    "https://microsoft.github.io/autogen/stable/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html",
    "https://microsoft.github.io/autogen/stable/reference/index.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.agents.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.state.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.code_executor.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.exceptions.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.logging.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.model_context.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tool_agent.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_core.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.ui.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.file_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.openai.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.auth.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.diskcache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.cache_store.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.docker_jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.jupyter.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.code_executors.local.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.canvas.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.chromadb.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.mem0.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.memory.redis.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.cache.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.llama_cpp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.replay.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.teams.magentic_one.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.azure.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.code_execution.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.graphrag.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.http.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.langchain.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.semantic_kernel.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.video_surfer.tools.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.agents.web_surfer.playwright_controller.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.experimental.task_centric_memory.utils.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.anthropic.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.azure.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.ollama.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.models.openai.config.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.agent_worker_pb2_grpc.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2.html",
    "https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.runtimes.grpc.protos.cloudevent_pb2_grpc.html"
  ]
}